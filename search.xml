<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>KV分布式事务</title>
      <link href="/2019/11/08/a15/"/>
      <url>/2019/11/08/a15/</url>
      
        <content type="html"><![CDATA[<h2 id="Percolator"><a href="#Percolator" class="headerlink" title="Percolator"></a>Percolator</h2><p><code>Percolator</code>主要使用在Bigtable系统中提供分布式事务能力，其本身的实现是利用Bigtable的单行事务能力以及在行内设置lock列来进行悲观事务。数据结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;key, version&gt;: &lt;data&gt;, &lt;lock&gt;, &lt;write&gt;</span><br></pre></td></tr></table></figure><h3 id="Transaction-Write"><a href="#Transaction-Write" class="headerlink" title="Transaction Write"></a>Transaction Write</h3><ul><li>开启事务：向集中的<code>Timestamp server oracle(TSO)</code>节点申请一个事务开始时间戳<code>t(s)</code>，并且以此时间戳做为事务id</li><li>2PC第一阶段：<code>Percolator</code>在一些Write set当中选择一行做为Primary，其他的行做为Secondaries。先对Primary做<code>prewrite</code>操作，如果成功则对其他的Secondaries做<code>prewrite</code>操作。<ul><li>Prewrite：这个操作当中有多个原子操作，被封装在一个事务当中，由Bigtable的单行事务性来保证。<ul><li>首先检查<code>write</code>是否有时间戳大于<code>t(s)</code>的版本，如果有则说明这行数据已经被新的事务提交过了，直接返回事务冲突</li><li>然后检查<code>lock</code>是否有任意版本的数据存在，如果有则说明这行资源还被别的事务持有，返回事务冲突</li><li>如果前面的操作都成功了，那么在<code>data</code>写入版本为<code>t(s)</code>的value数据</li><li>并且在<code>lock</code>中写入版本为<code>t(s)</code>值为primary位置的数据<br>在<code>prewrite</code>的第二部检查当中，发生冲突是有三种情况：</li></ul></li></ul><ul><li>获得锁的版本小于<code>t(s)</code>，该资源正在被一个事务持有</li><li>获得锁的版本小于<code>t(s)</code>，有一个老事务因为某种原因没有成功的还掉锁</li><li>获得锁的版本大于<code>t(s)</code>，该资源正在被一个事务持有<br>上述情况当中的1，3都是典型的写-写冲突，client就进行正常的backoff重试即可。而第2种情况是客户端在2PC的第二阶段发生了异常导致，这时需要rollback之前的事务来释放掉这个异常的锁。并且这里是很难区分1，2的，毕竟锁的版本都小于<code>t(s)</code>，所以需要一个附件条件锁的ttl时间，如果锁处于ttl时间内则说明是第1种情况，在ttl时间外则是第2种情况。</li></ul></li></ul><ul><li>2PC第二阶段：向集中的<code>TSO</code>节点申请一个事务提交时间戳<code>t(c)</code>，之后检查Primary的<code>lock</code>是否还存在<code>t(s)</code>版本的数据，如果不存在则说明该事务锁已经超过ttl时长，被其他的事务中断了。如果存在的话，则向<code>write</code>写入版本为<code>t(c)</code>值为<code>t(s)</code>的数据并且清掉锁，这时整个事务已经成功。最后异步的完成Secondaries写<code>write</code>并且释放锁的操作。这个阶段当中检查、写入、清锁的过程被包装在一个事务当中。</li></ul><h3 id="Transaction-Read"><a href="#Transaction-Read" class="headerlink" title="Transaction Read"></a>Transaction Read</h3><p>读事务就要简单很多，<code>Percolator</code>向集中的<code>TSO</code>节点申请一个事务开始的时间戳<code>t(s)</code>，然后检查所有的Read set中的锁，如果存在时间戳小于<code>t(s)</code>的锁：</p><ul><li>锁还处于TTL时间内，说明该资源正在被另外一个事务持有，Client进行backoff操作</li><li>锁已经超时，这时可以通过锁中记录的primary位置找到primary行的<code>write</code>列，检查是否存在锁版本的数据。如果存在则说明该事务已经成功，只是没有正常的还锁，这时将锁对应的事务进行提交，如果不存在则说明该事务2PC第二阶段出现问题，将该事务进行rollback</li></ul><p>下面是论文源码👇：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transaction</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Write</span>&#123;</span> Row row; Column: col; <span class="built_in">string</span> value;&#125;;</span><br><span class="line">    <span class="built_in">vector</span>&lt;Write&gt; writes_;</span><br><span class="line">    <span class="keyword">int</span> start_ts_;</span><br><span class="line"></span><br><span class="line">    Transaction():start_ts_(orcle.GetTimestamp()) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Set</span><span class="params">(Write w)</span> </span>&#123;writes_.push_back(w);&#125;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Get</span><span class="params">(Row row, Column c, <span class="built_in">string</span>* value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">            bigtable::Txn = bigtable::StartRowTransaction(row);</span><br><span class="line">            <span class="comment">// Check for locks that signal concurrent writes.</span></span><br><span class="line">            <span class="keyword">if</span> (T.Read(row, c+<span class="string">"locks"</span>, [<span class="number">0</span>, start_ts_])) &#123;</span><br><span class="line">                <span class="comment">// There is a pending lock; try to clean it and wait</span></span><br><span class="line">                BackoffAndMaybeCleanupLock(row, c);</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Find the latest write below our start_timestamp.</span></span><br><span class="line">        latest_write = T.Read(row, c+<span class="string">"write"</span>, [<span class="number">0</span>, start_ts_]);</span><br><span class="line">        <span class="keyword">if</span>(!latest_write.found()) <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// no data</span></span><br><span class="line">        <span class="keyword">int</span> data_ts = latest_write.start_timestamp();</span><br><span class="line">        *value = T.Read(row, c+<span class="string">"data"</span>, [data_ts, data_ts]);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// prewrite tries to lock cell w, returning false in case of conflict.</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Prewrite</span><span class="params">(Write w, Write primary)</span> </span>&#123;</span><br><span class="line">        Column c = w.col;</span><br><span class="line">        bigtable::Txn T = bigtable::StartRowTransaction(w.row);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// abort on writes after our start stimestamp ...</span></span><br><span class="line">        <span class="keyword">if</span> (T.Read(w.row, c+<span class="string">"write"</span>, [start_ts_, max])) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="comment">// ... or locks at any timestamp.</span></span><br><span class="line">        <span class="keyword">if</span> (T.Read(w.row, c+<span class="string">"lock"</span>, [<span class="number">0</span>, max])) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        T.Write(w.row, c+<span class="string">"data"</span>, start_ts_, w.value);</span><br><span class="line">        T.Write(w.row, c+<span class="string">"lock"</span>, start_ts_, </span><br><span class="line">            &#123;primary.row, primary.col&#125;);  <span class="comment">// The primary's location.</span></span><br><span class="line">        <span class="keyword">return</span> T.Commit();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Commit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Write primary = write_[<span class="number">0</span>];</span><br><span class="line">        <span class="built_in">vector</span>&lt;Write&gt; secondaries(write_.begin() + <span class="number">1</span>, write_.end());</span><br><span class="line">        <span class="keyword">if</span> (!Prewrite(primary, primary)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span> (Write w : secondaries)</span><br><span class="line">            <span class="keyword">if</span> (!Prewrite(w, primary)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> commit_ts = orcle.GetTimestamp();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Commit primary first.</span></span><br><span class="line">        Write p = primary;</span><br><span class="line">        bigtable::Txn T = bigtable::StartRowTransaction(p.row);</span><br><span class="line">        <span class="keyword">if</span> (!T.Read(p.row, p.col+<span class="string">"lock"</span>, [start_ts_, start_ts_]))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// aborted while working</span></span><br><span class="line">        T.Write(p.row, p.col+<span class="string">"write"</span>, commit_ts,</span><br><span class="line">            start_ts_); <span class="comment">// Pointer to data written at start_ts_</span></span><br><span class="line">        T.Erase(p.row, p.col+<span class="string">"lock"</span>, commit_ts);</span><br><span class="line">        <span class="keyword">if</span>(!T.Commit()) <span class="keyword">return</span> <span class="literal">false</span>;  <span class="comment">// commit point</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// Second phase: write our write records for secondary cells.</span></span><br><span class="line">        <span class="keyword">for</span> (Write w:secondaries) &#123;</span><br><span class="line">            bigtable::write(w.row, w.col+<span class="string">"write"</span>, commit_ts, start_ts_);</span><br><span class="line">            bigtable::Erase(w.row, w.col+<span class="string">"lock"</span>, commit_ts);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;; <span class="comment">// class Transaction</span></span><br></pre></td></tr></table></figure><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><ol><li>初始化Bob和Joe的账户，Bob有10元，Joe有2元<br><img src="/images/a15-1.png" alt="a15-1"></li><li>有一个事务出现，这个事务要将Bob的7元给Joe，这时获得了一个新的时间戳7，选择Bob做为primary，锁住该行写入Bob减掉7元以后的数据<br><img src="/images/a15-2.png" alt="a15-2"></li><li>将Joe选为Secondary，并指向Primary的Bob，锁住该行写入Joe加7元以后的数据<br><img src="/images/a15-3.png" alt="a15-3"></li><li>这时候2PC第一阶段完成，开始第二阶段，申请一个提交时间戳8，将时间戳7写入Bob的<code>write</code>的8版本中<br><img src="/images/a15-4.png" alt="a15-4"></li><li>将时间戳7写入Joe的<code>write</code>的8版本中<br><img src="/images/a15-5.png" alt="a15-5"></li></ol><h2 id="Percolator-in-TiDB"><a href="#Percolator-in-TiDB" class="headerlink" title="Percolator in TiDB"></a>Percolator in TiDB</h2><p>有了上面对<code>Percolator</code>的解释，我们现在很容易理解在TiDB中是如果使用<code>Percolator</code>来实现事务逻辑。首先我们来看其乐观事务的实现：<br><img src="/images/a15-6.jpg" alt="a15-6"><br>我们从图上可以看出，<code>Percolator</code>是被使用在TiDB和其下面的TiKV进行事务通信的协议。最开始的时候我很奇怪，<code>Percolator</code>的实现不是一个悲观事务模型吗？但是为什么TiDB里称其为乐观事务，是因为暴露给Client的不是底层的KV而是DB这一层，而加锁的过程被放在了Commit阶段，所以对于Client来说，这就是一个乐观事务模型。当事务开始以后，首先执行DML操作，得到Write set，然后将Write set放到<code>Percolator</code>中执行2PC，在第一阶段上锁。</p><p>下面再看看他们在这基础上修改的悲观事务模型，很巧妙：<br><img src="/images/a15-7.jpg" alt="a15-7"><br>将上锁的过程提前到开始执行<code>Percolator</code>事务之前，先对所有的Write set上一个和<code>Percolator</code>同样的锁，不过锁里面没有记录Primary的位置，而是空的，仅做占位符使用。等开始执行<code>Percolator</code>事务以后，锁会被写入正确的值。这样做的好处是，在数据真正开始发生变更之前就锁住了所有资源。不会发生回滚行为，在资源竞争密集的场景下效率大大优于乐观事务。写请求看到这个空锁直接等锁，读请求可以直接从TiKV中读取数据即可。</p><h2 id="Omid"><a href="#Omid" class="headerlink" title="Omid"></a>Omid</h2><p><code>Omid</code>主要使用在Phoenix系统中提供分布式事务能力，其本身的实现是利用Hbase的单行事务能力以及在行内设置version, commit列来进行乐观事务，数据结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Data table   &lt;key, version&gt;: &lt;value&gt; &lt;commit&gt;</span><br><span class="line">Commit table      &lt;version&gt;: &lt;commit&gt;</span><br></pre></td></tr></table></figure><h3 id="Transaction-Write-1"><a href="#Transaction-Write-1" class="headerlink" title="Transaction Write"></a>Transaction Write</h3><ul><li>开启事务：向集中的<code>Timestamp server oracle(TSO)</code>节点申请一个事务开始时间戳<code>t(s)</code>，并且以此时间戳做为事务id</li><li>2PC第一阶段：Client将Write set中的每行的修改数据写入Data table版本为<code>t(s)</code>，对应的key的<code>value</code>当中，需要注意的是这时候的<code>commit</code>均为null</li><li>2PC第二阶段：Client带上Write set和<code>t(s)</code>向<code>TSO</code>提交commit请求，<code>TSO</code>会进行冲突检查，如果检查成功则返回<code>t(c)</code>给Client，否则的话整个事务被中断。Client拿到<code>t(c)</code>以后向Commit Table发起<code>CAS(t(s), commit, null, t(c))</code>操作，如果返回<code>ABORT</code>则将事务终止，并且异步的清除Data table中之前写入的数据。如果成功，则进行Post-commit流程，将写入Commit table中的<code>t(c)</code>异步复制到Data table的版本为<code>t(s)</code>的<code>commit</code>当中。完成所有的异步复制以后进行垃圾回收，将Commit table当中的数据清除掉，完成整个事务。<ul><li>TSO如何进行冲突检查：原理非常的简单，就是检查Write set当中的每一行是否有<code>lastCommit &gt; t(s)</code>的数据，lastCommit是这一行最新的一个<code>t(c)</code>。如果有则说明在该事务执行过程当中已经有其他的事务完成，出现了写-写冲突，则中断该事务。但是要执行这个操作需要在TSO当中保存所有行的lastCommit数据才行，这个存储开销太大了，所以需要想办法优化。优化的手段也比较简单，就是维护一个LRU队列即可，只保存一定数量的行的lastCommit即可。那么不在队列当中的行的lastCommit一定小于等于队列中最小的一个lastCommit时间，这样可以检查<code>lastCommit&lt;=Smallest(lastCommit)&lt;=t(s)</code>的偏序关系，以检查冲突情况。但是由于队列中没有保存所有的数据，还是会有漏网之鱼，比如说现在队列里的<code>Smallest(lastCommit) &gt; t(s)</code>，并且要检查的行没有在队列当中，那么偏序关系就无从可知，这时候就直接将事务中断即可，也不会影响正确性。</li><li>CAS函数：这是一个在实现乐观锁当中经常会使用到的函数，<code>CAS(a,b,c,d)</code>是指比较a行b列，如果它现在的值等于c，则将其修改为d。并且这个函数需要保证原子性。在HBase当中可以使用行级事务来实现CAS函数，并保证其原子性。</li></ul></li></ul><h3 id="Transaction-Read-1"><a href="#Transaction-Read-1" class="headerlink" title="Transaction Read"></a>Transaction Read</h3><ul><li>向集中的<code>Timestamp server oracle(TSO)</code>节点申请一个事务开始时间戳<code>t(s)</code>，并且以此时间戳做为事务id</li><li>扫描所有的Read set，每一行从大版本到小版本扫描，找到第一个提交版本小于<code>t(s)</code>的value和对应的版本<code>t(s2)</code>。如果发现其<code>commit==null</code>，这时候有两种情况：<ul><li>这一次事务已经成功，只是正在进行Post-commit流程，从Commit table当中将<code>t(c)</code>复制过来</li><li>这一次事务没有成功<br>为了区分这两种情况，<code>Omid</code>会去Commit table当中检查版本<code>t(s2)</code>对应的<code>commit</code>是否有值，如果有值则说明是情况1，如果没有则说明是情况2。情况1的话很好办，继续向下遍历更小的版本。情况2的话就比较麻烦：</li><li>Client调用<code>CAS(t(s2), commit, null, ABORT)</code>来将其对应的事务设置为ABORT，这样在其重试的Commit环节会发现ABORT标志而使其事务进行中断操作</li><li>如果设置成功，还需要检查一下是否是因为读事务太慢而导致的错误中断，去Data table读<code>t(s2)</code>版本的commit，如果发现存在值<code>t(c2)</code>，并且<code>t(c2)&lt;t(s)</code>，则返回其value和版本。否则继续向下遍历更小的版本。</li></ul></li></ul><p>下面是论文源码👇：<br><img src="/images/a15-8.png" alt="a15-8"></p><p><img src="/images/a15-9.png" alt="a15-9"></p><h2 id="End"><a href="#End" class="headerlink" title="End"></a>End</h2><p>通过上文的分析我们可以看出，<code>Percolator</code>的优点是分布式的Commit table，TSO逻辑简单，缺点是锁检查时需要扫描所有Write set的锁情况，并且需要额外的存储开销来记录锁。<code>Omid</code>的优点是执行效率上优于<code>Percolator</code>，但是又多了一个中心系统Commit table。大家可以根据自己的使用场景来进行选择。</p><p>参考资料：</p><ul><li><a href="https://www.usenix.org/system/files/conference/fast17/fast17-shacham.pdf" target="_blank" rel="noopener">Omid, Reloaded: Scalable and Highly-Available Transaction Processing</a></li><li><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36726.pdf" target="_blank" rel="noopener">Large-scale Incremental Processing Using Distributed Transactions and Notifications</a></li><li><a href="http://kaiyuan.me/2019/01/19/2pc/" target="_blank" rel="noopener">基于 KV 的分布式事务方案</a></li><li><a href="https://zhuanlan.zhihu.com/p/79034576?utm_source=wechat_session&utm_medium=social&utm_oi=956566129104080896&from=singlemessage&isappinstalled=0&wechatShare=1&s_r=0" target="_blank" rel="noopener">TiDB 新特性漫谈：悲观事务</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> distributed-system </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>锁</title>
      <link href="/2019/10/18/a14/"/>
      <url>/2019/10/18/a14/</url>
      
        <content type="html"><![CDATA[<p>在很多的多线程编程场景下都会遇到多个线程对一个资源进行操作访问的情况，这种场景一旦发生就会牵扯到线程安全问题。为了保证程序的正确性，我们不得不花很大的力气去解决这些线程安全问题。在Java中解决线程安全问题的办法被分为了三种，其一是互斥同步，其二是非阻塞同步，其三是无同步方案。前两种的实现形式都是锁，第三种是通过设计模式的转变来将代码转变为不共享变量的形式，这不在这篇博客的讨论范围中。</p><h2 id="线程不安全"><a href="#线程不安全" class="headerlink" title="线程不安全"></a>线程不安全</h2><p>首先我们来分析一下线程安全问题产生的底层原因到底是什么？先看下面的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiThreadIncrease</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        race = race + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> THREAD_COUNT = <span class="number">20</span>;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[THREAD_COUNT];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREAD_COUNT; i++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                System.out.format(<span class="string">"This is %d thread.\n"</span>, Thread.currentThread().getId());</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">10000</span>; j++) &#123;</span><br><span class="line">                    increase();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">2</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(race);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先解释一个细节，因为我的代码是在Idea里跑的，所以不仅是有<code>Main thread</code>，还有一个<code>Monitor Ctrl-Break</code>的守护线程。所以代码中是<code>Thread.activeCount() &gt; 2</code>。如果直接使用<code>java</code>执行的话，这里是1即可。然后上面的代码做了一个很简单的事情，开了20个线程，每个线程做一件事情，对<code>race</code>这个变量累加10000次，最后输出。最后的结果显然不是200000，会小很多并且每次都不一样。这是为什么呢？</p><p>是因为<code>race = race + 1</code>这一行代码其实做了三件事情：</p><ul><li><ol><li>取出<code>race</code>现有的值</li></ol></li><li><ol start="2"><li>给<code>race</code>现有的值加上1</li></ol></li><li><ol start="3"><li>将更新后的值再附给<code>race</code></li></ol></li></ul><p>我们理想的状态是，每个线程顺序的做完这三件事：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">thread1.1  // race=0</span><br><span class="line">thread1.2  // race=0</span><br><span class="line">thread1.3  // race=1</span><br><span class="line">thread2.1  // race=1</span><br><span class="line">thread2.2  // race=1</span><br><span class="line">thread2.3  // race=2</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>但实际是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">thread1.1  // race=0</span><br><span class="line">thread2.1  // race=0</span><br><span class="line">thread2.2  // race=0</span><br><span class="line">thread1.2  // race=0</span><br><span class="line">thread1.3  // race=1</span><br><span class="line">thread2.3  // race=1</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>甚至更加的混乱，这就造成代码运行结果错误的现象，也就是出现了线程不安全行为。那么为了规避这样的行为，就需要引出锁的概念，悲观锁就是互斥同步的实现，乐观锁是非阻塞同步的实现。</p><h2 id="互斥同步-悲观锁"><a href="#互斥同步-悲观锁" class="headerlink" title="互斥同步 悲观锁"></a>互斥同步 悲观锁</h2><p>首先我们看看《深入理解JVM》中对互斥同步的定义，”互斥同步是常见的一种并发正确性保障手段。同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个（或者一些，使用信号量的时候）线程使用。而互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。因此，在这4个字里面，互斥是因，同步是果；互斥是方法，同步是目的。“</p><h3 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h3><p>而如何保证共享数据在同一个时刻只被一个线程使用？那么就需要在这个数据被使用之前就为期加上锁，只有获得锁的线程能够对其进行操作，而这样的锁就被称为悲观锁。在Java中，最基本的实现就是<code>synchronized</code>关键字。其实现的原理是在编译后会在同步块的前后分别形成<code>monitorenter</code>和<code>monitorexit</code>这两个字节码指令，这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。如果指明的是对象参数，那就是这个对象的reference；如果没有明确指定，那就根据<code>synchronized</code>的是实例还是类方法，去取对应的对象实例或Class对象来作为锁对象。先看下面的例子，对比一下添加<code>synchronized</code>关键字前后的字节码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NoSynchronized</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        race = race + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> NoSynchronized().increase();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过javap工具来获取字节码：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> javap -verbose -p io.talkwithkeyboard.code.NoSynchronized</span><br></pre></td></tr></table></figure><p>我们只关注<code>increase</code>方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public void increase();</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=1, args_size=1</span><br><span class="line">         0: getstatic     #2                  // Field race:I</span><br><span class="line">         3: iconst_1</span><br><span class="line">         4: iadd</span><br><span class="line">         5: putstatic     #2                  // Field race:I</span><br><span class="line">         8: return</span><br></pre></td></tr></table></figure><p>那么在添加<code>synchronized</code>关键字后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WithSynchronized</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">            race = race + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> WithSynchronized().increase();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还是只关注<code>increase</code>方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public void increase();</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=3, args_size=1</span><br><span class="line">         0: aload_0</span><br><span class="line">         1: dup</span><br><span class="line">         2: astore_1</span><br><span class="line">         3: monitorenter</span><br><span class="line">         4: getstatic     #2                  // Field race:I</span><br><span class="line">         7: iconst_1</span><br><span class="line">         8: iadd</span><br><span class="line">         9: putstatic     #2                  // Field race:I</span><br><span class="line">        12: aload_1</span><br><span class="line">        13: monitorexit</span><br><span class="line">        14: goto          22</span><br><span class="line">        17: astore_2</span><br><span class="line">        18: aload_1</span><br><span class="line">        19: monitorexit</span><br><span class="line">        20: aload_2</span><br><span class="line">        21: athrow</span><br><span class="line">        22: return</span><br></pre></td></tr></table></figure><p>字节码描述的过程是：</p><ul><li><ol start="0"><li>将类对象入栈</li></ol></li><li><ol><li>复制栈顶元素（即类对象的引用）</li></ol></li><li><ol start="2"><li>将栈顶元素（类对象）存储到局部变量表Slot 1中</li></ol></li><li><ol start="3"><li>以栈顶元素做为锁开始同步</li></ol></li><li><ol start="4"><li>取获取类的静态字段（race），将其值压入栈顶</li></ol></li><li><ol start="7"><li>int型常量1进栈</li></ol></li><li><ol start="8"><li>对操作数栈上的两个数值进行加法，结果压入栈顶</li></ol></li><li><ol start="9"><li>用栈顶元素给类的静态字段（race）赋值</li></ol></li><li><ol start="12"><li>将局部变量表Slot 1中的类对象入栈</li></ol></li><li><ol start="13"><li>退出同步</li></ol></li><li><ol start="14"><li>方法正常结束，跳转到22返回</li></ol></li><li><ol start="17"><li>从这步开始是异常路径，暂不赘述</li></ol></li></ul><p>在展示了整个<code>synchronized</code>关键字的代码流程以后，我们再深究一下<code>monitorenter</code>指令和<code>monitorexit</code>指令在机器码成面到底做了什么。为了阅读方便，我们先不展示机器码的内容，而是从虚拟机规范出发，在执行<code>monitorenter</code>指令的时，首先要尝试获取对象的锁。如果这个对象没有被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1。相应的，在执行<code>monitorexit</code>指令的时候，把锁的计数器减1，当计数器为0的时候，锁就被释放掉。</p><h3 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h3><p>以上就是锁的整个低层实现过程，在Java中其实还有更上层的锁封装能实现更多特性的锁，那就是<code>ReentrantLock</code>类，它和<code>synchronized</code>关键字一样都是悲观锁的实现。但是相比<code>synchronized</code>，增加了一些高级功能，主要是以下三点：</p><ul><li>等待可中断：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// lock() 实现</span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">acquireQueued</span><span class="params">(<span class="keyword">final</span> Node node, <span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> failed = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">boolean</span> interrupted = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                <span class="keyword">final</span> Node p = node.predecessor();</span><br><span class="line">                <span class="keyword">if</span> (p == head &amp;&amp; tryAcquire(arg)) &#123;</span><br><span class="line">                    setHead(node);</span><br><span class="line">                    p.next = <span class="keyword">null</span>; <span class="comment">// help GC</span></span><br><span class="line">                    failed = <span class="keyword">false</span>;</span><br><span class="line">                    <span class="keyword">return</span> interrupted;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (shouldParkAfterFailedAcquire(p, node) &amp;&amp;</span><br><span class="line">                    parkAndCheckInterrupt())</span><br><span class="line">                    interrupted = <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (failed)</span><br><span class="line">                cancelAcquire(node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// lockInterruptibly() 实现</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doAcquireInterruptibly</span><span class="params">(<span class="keyword">int</span> arg)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Node node = addWaiter(Node.EXCLUSIVE);</span><br><span class="line">        <span class="keyword">boolean</span> failed = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                <span class="keyword">final</span> Node p = node.predecessor();</span><br><span class="line">                <span class="keyword">if</span> (p == head &amp;&amp; tryAcquire(arg)) &#123;</span><br><span class="line">                    setHead(node);</span><br><span class="line">                    p.next = <span class="keyword">null</span>; <span class="comment">// help GC</span></span><br><span class="line">                    failed = <span class="keyword">false</span>;</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (shouldParkAfterFailedAcquire(p, node) &amp;&amp;</span><br><span class="line">                    parkAndCheckInterrupt())</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> InterruptedException();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (failed)</span><br><span class="line">                cancelAcquire(node);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>可以看到在<code>lock()</code>和<code>lockInterruptibly()</code>源码的实现中，唯一的区别是在一直等待锁的过程中，<code>lock()</code>会吞掉中断，近记录中断状态，而<code>lockInterruptibly()</code>会抛异常到上层，交给上面的业务逻辑进行处理。</p><ul><li>公平锁：多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁，而非公平锁是不能保证这一点的。<code>synchronized</code>就是非公平锁，可以通过 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> ReentrantLock lock = <span class="keyword">new</span> ReentrantLock(<span class="keyword">true</span>);</span><br></pre></td></tr></table></figure></li></ul><p>来创建公平锁。</p><ul><li>可以绑定多个条件：主要是处理生产者消费者模型，由于篇幅这里暂不赘述。</li></ul><h3 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h3><p><code>volatile</code>可以说是Java中最轻量化级的同步机制，在一定程度上也是可以当作对象的锁来进行使用的，但是在功能上还是不能完全替代被<code>synchronized</code>作用的对象。当一个变量定义为<code>volatile</code>之后，它将具备两种特性，第一是当一个线程修改了这个变量的值，新值对于其他线程来说是立即得知的，这就是可见性。第二个语义是禁止指令重排序优化。</p><p>首先介绍一下可见性是如何实现的？普通变量在被一个线程修改之后，会向主内存进行回写，只有等到主内存回写完成以后，其他的线程才能读到新的值。 而被<code>volatile</code>修饰的变量在赋值后会产生一个<code>lock addl $0x0,(%esp)</code>向寄存器中加0的空操作，这个操作能使用本CPU的Cache写入内核，并使别的CPU或者别的内核无效化Cache。相当于将工作内存中的变量拿到了主内存当中，正是因为此让<code>volatile</code>修饰的变量马上对其他线程可见。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileControl</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> <span class="keyword">boolean</span> shutdownRequested = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        shutdownRequested = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> loopCount = <span class="number">100000000</span>;</span><br><span class="line">        System.out.println(Thread.currentThread().getId() + <span class="string">":"</span> + loopCount);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; loopCount; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (shutdownRequested) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(Thread.currentThread().getId() + <span class="string">":"</span> + <span class="string">"shutdown!"</span>);</span><br><span class="line">        shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> THREAD_COUNT = <span class="number">10</span>;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[THREAD_COUNT];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREAD_COUNT; i ++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(() -&gt; <span class="keyword">new</span> VolatileControl().doWork());</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">2</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比如在这个例子当中，让每个线程都循环100000000次，在大多数情况下最后可以看到<code>shutdown!</code>只被打印了一次。但是一旦去掉<code>volatile</code>修饰以后，就会看到很多个<code>shutdown!</code>被打印出来，这就是因为很多线程在<code>shutdownRequested</code>被修改以后，都读到了老版本的值，出现了线程不安全的情况。而<code>volatile</code>从表现来看基本上达到了为<code>shutdownRequested</code>加锁的效果。但是刚才也提到了我们是在大多数情况下是只看到一次<code>shutdown!</code>，这是为什么呢？可以先看一个更加容易复现的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileIncrease</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        race = race + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> THREAD_COUNT = <span class="number">20</span>;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[THREAD_COUNT];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREAD_COUNT; i++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">10000</span>; j++) &#123;</span><br><span class="line">                    increase();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">2</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(race);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还是上面出现过的，每个线程都给<code>race</code>累加值的代码，只不过现在会用<code>volatile</code>进行修饰。<code>volatile</code>的特性又是值被修改后立即能被其他线程看见，那么这个例子就应该输出正确的结果200000，但是运行后会发现还是出现了上面提到的线程不安全的问题。那么这是不是和<code>volatile</code>的描述不符呢？我们还是输出字节码来看看：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public static void increase();</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=0, args_size=0</span><br><span class="line">         0: getstatic     #2                  // Field race:I</span><br><span class="line">         3: iconst_1</span><br><span class="line">         4: iadd</span><br><span class="line">         5: putstatic     #2                  // Field race:I</span><br><span class="line">         8: return</span><br></pre></td></tr></table></figure><p>可以看到问题是出在<code>race = race + 1</code>上面，到字节码层面上这个操作已经被拆分成了4条指令，并且不具备事务性了。<code>volatile</code>能保证的是<code>getstatic</code>能取到最新的值，但是在<code>iadd</code>操作的时候其他线程可能已经把这个值加大了。在上面的例子当中同理，在将<code>shutdownRequested</code>赋值为true的时候，可能其他线程已经赋值成功，但是当前线程不可见。所以<code>volatile</code>的作用是非常轻微的，只能够保证在取值的时候能取到最新值，当一个操作的事务性无法保证的时候，<code>volatile</code>也不能提供锁的性质。至于防止指令重拍和题目相关性不强，这里先不做赘述。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在《深入理解JVM虚拟机》中，有对<code>synchronized</code>和<code>ReentrantLock</code>进行性能对比，通过对<code>synchronized</code>的优化，性能基本上持平。并且提供因为团队会更偏向于优化原生的<code>synchronized</code>关键字，所以当两个都能使用的时候可以优先使用<code>synchronized</code>关键字，需要更高阶的功能时，再选择<code>ReentrantLock</code>。但是因为阻塞的实现方式，这两种实现都会阻塞后面其他的线程进入，而Java的线程是映射到操作系统的原生线程之上的，如果一个线程要阻塞或唤醒，都是需要操作系统从用户态切换到核心态来进行帮忙的，所以需要非常谨慎的时候，在一定情况下是可以使用<code>volatile</code>关键字来进行替代的，以提高性能。</p><h2 id="非阻塞同步-乐观锁"><a href="#非阻塞同步-乐观锁" class="headerlink" title="非阻塞同步 乐观锁"></a>非阻塞同步 乐观锁</h2><p>由于悲观锁的实现中涉及到加锁、用户态核心态切换、维护锁计数器和检查是否有被阻塞线程需要被唤醒等复杂的操作，在执行效率上大打折扣。随着硬件指令集的发展，又多了一种锁实现方案，也就是乐观锁，其主要的思想是：先进行操作，如果没有竞争则操作成功，如果有竞争，那就再采取其他的补偿措施。这种实现方式下，不需要将线程挂起，因此也称为非阻塞同步。</p><h3 id="Compare-and-Swap"><a href="#Compare-and-Swap" class="headerlink" title="Compare-and-Swap"></a>Compare-and-Swap</h3><p>乐观锁的一个实现关键是需要让“现在的值等于旧预期值时，将新预期值写入”这个操作原子化，而这也依赖于硬件指令集的发展，出现了<code>CAS(Compare-and-Swap)</code>指令来完成这个任务。CAS指令需要三个操作数，分别是内存位置V、旧的预期值A、新的预期值B。CAS指令执行时，当且仅当V符合旧的预期值A的时候，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新了V的值，都会返回V的旧值，并且上述的过程是原子性的。在JDK1.5之后，<code>sun.misc.Unsafe</code>类的<code>compareAndSwapInt()</code>和<code>compareAndSwapLong()</code>等几个操作都依靠CAS指令执行，虚拟机内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令。在更上层中的接口中，<code>AtomicInteger.incerementAndGet()</code>等使用了<code>Unsafe</code>的低层接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiThreadAtomicIncrease</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> AtomicInteger race = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        race.incrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> THREAD_COUNT = <span class="number">20</span>;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[THREAD_COUNT];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREAD_COUNT; i++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">10000</span>; j++) &#123;</span><br><span class="line">                    insert();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">2</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(race.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用乐观锁来对上面多线程累加的程序进行优化，运行程序可以看到正确的结果。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">incrementAndGet</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> unsafe.getAndAddInt(<span class="keyword">this</span>, valueOffset, <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>incrementAndGet</code>方法就是对<code>Unsafe</code>类的<code>getAndAddInt</code>方法进行了封装，而<code>getAndAddInt</code>在低层使用了和CAS类似的指令<code>Fetch-and-Increment</code>，将获取值和累加两个操作进行原子化封装。而在早期的JDK实现中，是使用CAS指令进行完成，不断尝试将比现在值大1的值写入。这个优化也是硬件指令集的进一步丰富带来的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getAndIncrement</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">int</span> current = get();</span><br><span class="line">        <span class="keyword">int</span> next = current + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (compareAndSet(current, next))</span><br><span class="line">            <span class="keyword">return</span> current;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h2><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><p>因为互斥同步对性能的消耗非常大，并且JVM团队发现大量的锁定状态只会持续很短的一段时间，这个时间远小于对CPU的用户态和内核态切换时间。所以就想出来一个办法不轻易的对线程进行阻塞，而使用忙循环（自旋）来替代。不过自旋也不是完全优于阻塞的，虽然省下了线程切换的开销，不过忙循环会占用处理器时间，所以如果锁定状态时间较短使用自旋是划算的，锁定状态时间较长就会浪费处理器资源，带来性能的消耗。因此现在的实现中，会规定一个自旋的上限，当达到上限以后就转为重锁的方式挂起线程。现在高版本的JDK中自旋是默认开启的，Java用户可以通过<code>-XX:PreBlockSpin</code>来修改自旋的次数。</p><p>并且为了进一步的提高自旋锁的性能，在JDK1.6提出了自适应的自旋锁，每次自旋的时间不固定，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态决定。如果在一个锁对象上，通过自旋的方式经常成功获得过锁，并且持有锁的进程正在运行中，那么这次自旋有较大可能获得锁，就可以等待较多的自旋次数。如果在一个锁对象上从来没有成功通过自旋获得锁，那么就直接省去自旋步骤，直接进入重锁。</p><h3 id="锁消除"><a href="#锁消除" class="headerlink" title="锁消除"></a>锁消除</h3><p>锁消除是指开发人员虽然要求一段代码块需要上锁，同步执行。但是被JVM检测到存在不可能存在共享数据竞争的锁，就会自动将其消除掉。这个检测主要依赖逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它当作栈上数据对待，认为他们是线程私有的，就不用加锁。</p><h3 id="锁粗化"><a href="#锁粗化" class="headerlink" title="锁粗化"></a>锁粗化</h3><p>很多时候我们都希望加锁的作用范围限制的尽可能的小，这样可以缩短锁状态的持续时间，让等待的线程尽快的获得锁。但是偶尔会出现一系列连续的操作都对同一个对象反复加锁和解锁，甚至加锁操作出现在循环体中的，这样频繁的进行互斥同步会极大的降低执行效率，这时候虚拟机探测到有这样一串零碎的操作都对一个对象加锁，就会把加锁的范围粗化到整个操作序列的外部，这样加锁一次就可以了。就还是用上面的例子举例，每次<code>increase</code>操作都有加锁解锁的步骤，这时就会把锁粗化到for循环的外部。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiThreadIncreaseSync</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        race = race + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> THREAD_COUNT = <span class="number">20</span>;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[THREAD_COUNT];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREAD_COUNT; i++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">10000</span>; j++) &#123;</span><br><span class="line">                    increase();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">2</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(race);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>轻量级锁的优化方向是使用CAS代替互斥量的开销，并且依据经验“对于绝大多数的锁，在整个同步周期内都是不存在竞争的”，假设没有竞争那么CAS操作就避免了互斥量的开销，但是如果存在竞争，轻量锁最终会膨胀为重量锁，不仅有互斥量的开销，还多了CAS操作。在HotSpot虚拟机中，对象头由两部分组成，一部分是非固定数据结构的，用来储存对象自身的运行时数据，如哈希值，GC分带年龄等数据，官方称为”Mark word”；另一部分用于储存指向方法区对象类型数据的指针，这一部分先不关注。而“Mark word”就是锁实现的关键，我们以32位的HotSpot举例，32bit的”Mark word”中除了2bit用于存储锁标志位外，其他的30bit所保存的内容都根据锁状态发生变化：</p><ul><li>当处于未锁定（标志位为01）时，29bit存储了对象哈希值、对象分代年龄等</li><li>需要加锁时，先检查是否处于未锁定状态，如果是，在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储当前锁对象”Mark word”的拷贝</li><li>使用CAS操作将其余30bit更新为指向锁记录的指针<ul><li>这些动作成功了，改变标志位（00是轻量级锁），这个线程就拥有了该对象的锁</li><li>如果失败了，虚拟机会检查对象的Mark word是否指向当前线程，如果是则说明当前线程已经获得锁，则直接进入同步块执行。否则这个锁对象已经被其他的线程抢占了。这时候轻量锁膨胀为重量锁，标志位改为10，Mark word指向重量锁，后面的线程进入阻塞状态。</li></ul></li><li>当执行完同步块，使用CAS操作将对象当前的Mark word与之前存储的老Mark word拷贝进行交换，完成解锁。</li></ul><h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>偏向锁的优化方向是在不存在竞争时直接去掉同步原语，当锁对象第一次被线程获取的时候，虚拟机会将标志位改为01，即偏向模式，同时使用CAS操作把获取到的锁的线程ID记录在Mark word之中，如果操作成功，这个线程就拥有了该对象的锁。之后当持有偏向锁的线程进入同步块的时候，虚拟机不需要做任何操作，而在轻量锁中，还是需要尝试检查锁定状态，以及对象的Mark word是否指向自己。当有其他线程尝试获取锁的时候，偏向锁就膨胀为轻量锁。偏向锁可以提高带有同步但无竞争的程序性能，但是如果程序中大多数的锁总是被多个不同的线程访问，那偏向模式就是多余的。可以通过<code>-XX:-UseBiasedLocking</code>来进行禁止。</p><p><img src="/images/a-14-1.jpg" alt="a-14-1"></p><h2 id="End"><a href="#End" class="headerlink" title="End"></a>End</h2><p>参考资料：《深入理解Java虚拟机》</p>]]></content>
      
      
      
        <tags>
            
            <tag> distributed-system </tag>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch优化思路</title>
      <link href="/2019/09/28/a6/"/>
      <url>/2019/09/28/a6/</url>
      
        <content type="html"><![CDATA[<blockquote><p>于9月25日，参加云栖大会elasticsearch专场后对阿里云的优化思路进行整理总结。行文分为两个部分，一个部分是对原生elasticsearch的解决方案进行大致介绍，再对阿里云的优化进行整理。</p></blockquote><h2 id="原生架构"><a href="#原生架构" class="headerlink" title="原生架构"></a>原生架构</h2><p>在elasticsearch当中<code>index</code>是大家最熟悉的组织结构，它就像传统nosql数据库中的collection，组织着一批有相同数据结构的数据。当一个<code>index</code>中的数据量越来越大，就会很自然的将<code>index</code>进行分片，分到多个shard当中。这样通过水平扩展就能解决数据膨胀的问题，然后同时也引入了副本来提高整个集群的可用性。所以有两个<code>index</code>，每个<code>index</code>有3个shard，每个shard有2个replica的集群就是下面这个样子👇：<br><img src="/images/a6-1.png" alt="a6-1"><br>index A有3个shard：<code>A1</code>、<code>A2</code>、<code>A3</code>，<code>A1’</code>是<code>A1</code>的副本，以此类推。</p><p>在这样的架构中，如果想向index A中写入文档，会先通过路由算法分配到一个primary所在的节点（比如<code>A1</code>）进行写入，完成以后会到该primary的副本<code>A1’</code>中进行写入，完成以后再返回成功。可以看出这样的流程中有几个瓶颈所在：</p><ul><li>如果副本的数量一旦较多，写请求的延时就会成倍增长</li><li>副本会保存一份完整的数据，所以集群的存储成本也在成倍地增长</li><li>如果副本数量超过了分片数量，会出现有节点只是用来做副本的情况，只能被读，浪费了资源</li><li>当主节点出现故障时，会从新在副本当中选举主节点，并新启动一个节点，从新的主节点当中全量拷贝数据。全量拷贝的延时较长，在这一段时间内新副本节点是不可用的，所有的流量会打到主节点和其他副本节点上，可能出现性能问题</li></ul><h2 id="优化架构"><a href="#优化架构" class="headerlink" title="优化架构"></a>优化架构</h2><p>先来看阿里云的架构图👇：<br><img src="/images/a6-2.png" alt="a6-2"><br>使用了计算与存储分离的架构，通过底层的云储存来提供共享存储。这样主副之间的数据只用存在一个地方即可，而节点上只提供计算能力，由云存储来提供数据的多副本机制以保证数据的可靠性。如果要完整的理解上面这张图，我们需要再介绍一些概念：</p><p>在elasticsearch中，一个shard是由多个segment组成的，并对应一个translog文件。那么当写入一个文档时，会先在translong中进行相应的记录，并将其写入到primary节点的buffer当中。然后在primary节点上是有一个每秒执行一次的<code>refresh</code>操作，该操作会把buffer当中的所有document写入到内存中的一个新的segment当中，这时候文档变成了可被检索的状态，所以一个segment实际就是一个倒排索引。最后会有一个<code>flush</code>操作，该操作也会把buffer中的数据写入到一个新的segment中，并进一步将内存中的所有segment冲洗到硬盘上，并清空该shard上的translog。</p><p>在对整个索引过程解释了一遍以后就可以清晰的理解上图，NFS表示阿里云提供的分布式云存储。当一个index请求进来的时候，primary节点会先在translog中添加一条记录，并将该文档写入buffer当中。每隔一段时间，primary节点会进行refresh操作将buffer中的所有数据写入到nfs的refresh segment中进行保存。然后会由 <code>nrt segment synchronizer</code>进程定期的复制refresh segment中的数据到临时目录当中。最后会由<code>flush</code>操作，将refresh segment中的数据写入到commit segment中，并删除refresh segment，临时目录，以及translog。而读请求如果从primary节点读会读到refresh segment + commit segment的内容，如果从replica中读会读到临时目录 + commit segment的内容。</p><p>这种架构解决了原生架构的一些问题：</p><ul><li>降低了写请求的延时，因为现在的refresh segment到临时目录的复制没有通过网络传输，直接是同一文件系统中的复制，所以大大降低了主备延时。（据阿里所说从分钟级降低到了毫秒级，但是原生架构也没有分钟级这么夸张吧…）</li><li>commit segment只会保存一份，所以不会因为副本数量过多而导致集群的存储成本上升</li><li>因为计算与存储分离，当出现主节点故障需要主副切换时，不需要长时间的拷贝全量数据，一个新的副节点启动以后，只要指向原来的临时目录即可</li></ul><p>但是也引入了一些新的问题：</p><ul><li>由于现在是共享内存，所以refresh操作多了传输成本，并且在NFS的速度也低于原本机内存中的速度，所以这里的成本有提高。不过应该是小于主从复制的性能提升。</li><li>引入了一些传统共享内存型分布式的问题，比如脑裂，双写等。不过在PPT中也看到阿里也实现了IO fencing来避免主从切换时带来的双写问题。</li></ul><p>下面再简单介绍一下演讲中讲到的主从复制的优化，下面是给出的示意图👇：<br><img src="/images/a6-3.png" alt="a6-3"><br>阿里说是使用了luence-replicator框架进行实现，我现在还没仔细阅读，有兴趣的可以看看<a href="http://shaierera.blogspot.com/2013/05/the-replicator.html" target="_blank" rel="noopener">Code Reduction: The Replicator</a><br>所以我下面的解释主要基于他们的演讲以及一些猜测：<br>在主从复制过程当中，主节点会定时的对meta进行快照，比如生成了图中的snapshot4，然后对它增加引用计数，再发送给从节点。从节点会和自己的快照进行比对，找到落后了多少个版本。将缺少的segment复制到临时目录当中，复制完成以后就可以通知primary节点复制结束，从而减少同步前从节点快照版本的引用计数，删除引用计数为0的文件。</p><p>其中还提到了一些针对segment merge的优化，那么还是先介绍一些什么是segment merge：<br>因为每秒都会进行<code>refresh</code>操作，生成一个小的segment文件，这些小的文件对内存的利用率是非常低的，而且每次query请求来的时候都会轮训这些小的segment文件，所以文件数量越多性能越差。elasticsearch会在后台进行异步的合并操作，从小的segment合并成大的segment，并且在合并阶段处理文件的删除和更新。</p><p>那么优化的部分是什么呢？就是在合并成大的segment以后会立即进行<code>flush</code>操作，来保证大的segment不会出现在主从复制当中。从而进一步的对主从复制进行提速。</p><h2 id="优化索引速度"><a href="#优化索引速度" class="headerlink" title="优化索引速度"></a>优化索引速度</h2><h3 id="离线"><a href="#离线" class="headerlink" title="离线"></a>离线</h3><p>离线全量写入一直是一个痛点问题，传统解决办法是维护两个elasticsearch集群，正常使用A集群，然后收集A集群的translog，并将全量快照写入B集群，完成以后回放translog，保证两边数据一致。完成后从A集群切到B集群，这样的维护成本是非常高的，并且全量快照写入的时间又非常的长。</p><p>阿里云针对这个点进行的优化是取消了translog，使用blink checkpoint天生的at least once的语义来保证故障恢复，相当于减少了一半的写工作量。但是这样相当于在elasticsearch外面套上了一个blink，并且需要和外部的blink进行通信，系统复杂度又上升了一个等级（不过反正也是云服务，又不要我们自己做DBA）。第二个是在segment合并上增加了一个limit，只有合并后达到一定的大小才会<code>flush</code>到磁盘当中，这样可以减少磁盘里的小segment再被读入到内存中进行反复的合并，减小IO次数。</p><p>前两个我觉得都是较小的优化，第三个优化比较大，如下图👇：<br><img src="/images/a6-4.png" alt="a6-4"><br>优化的核心点是利用更高的并发提前计算好索引，直接让线上的elasticsearch集群来load索引。具体怎么做的呢，就是利用blink的流计算能力来取代client node的计算数据分片能力，然后模拟process，build，merge三个操作并将其分布式化，让这三个操作都可以进行水平扩展，让索引能力可以随着计算资源的提升而提升。原来如果想提高索引的计算能力，是需要对elasticsearch集群的资源进行拓展，但是现在将索引计算的步骤分离了出来，转变成了一个经典分布式计算框架能解决的问题。最后放到OSS当中，让线上的模型进行load。类似的优化之前也有人已经尝试过，有兴趣可以看看<a href="https://elasticsearch.cn/slides/217#page=5" target="_blank" rel="noopener">基于Hadoop快速构建离线elasticsearch索引</a></p><h3 id="在线"><a href="#在线" class="headerlink" title="在线"></a>在线</h3><p>在线增量导入的优化也是将client node路由计算的能力放到了blink上，因为他们发现在大数据增量导入的时候，瓶颈出现在了CPU上，所以将计算部分外移，并且blink可以更好的进行针对计算的弹性升缩。</p><p>参考材料：<br><a href="https://zhuanlan.zhihu.com/p/33375126" target="_blank" rel="noopener">从Elasticsearch来看分布式系统架构设计 - 知乎</a><br><a href="https://blog.csdn.net/laoyang360/article/details/84727820" target="_blank" rel="noopener">Elasticsearch写入原理深入详解 - 铭毅天下（公众号同名） - CSDN博客</a><br><a href="https://blog.csdn.net/lsgqjh/article/details/83022206" target="_blank" rel="noopener">Elasticsearch 之 commit point | Segment | refresh | flush 索引分片内部原理 - 舒哥的blog - CSDN博客</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> distributed-system </tag>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RATE LIMIT FOR MONGOSPARK WRITER</title>
      <link href="/2019/05/11/a5/"/>
      <url>/2019/05/11/a5/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近迁移数据库的时候发现了一个问题，相信也是很多 MongoDB 使用者都会遇到的问题。我在使用 MongoSpark 批量的写入数据的时候会造成严重的数据库抖动。主要的原因是现在大多 MongoDB 的配置都是 replica set 模式，这样写操作只会到 Master 节点上，写操作就会成为整个系统的瓶颈，大量的写操作会使 Master 节点的读操作变慢，并且会让 secondary 节点同步速度变慢，从而出现从 secondary 节点上读到老数据的问题。</p><p>而通过对 MongoDB 进行 shard 是一个代价非常昂贵且只能线性提高写吞吐的方法，非常的不经济实惠。所以我们也只能牺牲速率来保证线上服务的稳定。所以解决方案就是在 MongoSpark 中添加上写限速功能。</p><h2 id="Guava-RateLimiter"><a href="#Guava-RateLimiter" class="headerlink" title="Guava.RateLimiter"></a>Guava.RateLimiter</h2><p>选择的限速器是 Guava 提供的令牌桶。算法的原理很简单，会定时的向桶中放置令牌，服务只有获得令牌以后才能进行后续的操作，比如希望对一个服务进行每秒10次的限速，那么每秒中就会向桶中放置10个令牌。而获取的方式有两种，一种是阻塞等待令牌或者取不到令牌直接返回失败。</p><p>那么下面就简单的介绍一下API，主要是分两个动作，创建桶和获取令牌：</p><p><strong>创建令牌桶</strong> </p><ul><li><code>RateLimiter create(double permitsPerSecond)</code>: 根据一个稳定的速率创建令牌桶，也就是每秒插入 permitsPerSecond 个令牌。</li><li><code>RateLimiter create(double permitsPerSecond, long warmupPeriod, TimeUnit unit)</code>: 通过一个预热时间段达到稳定的速率创建令牌桶，在 warmupPeriod 这段时间内每秒令牌数量平稳的爬升至 permitsPerSecond，而后保持稳定。这里的速率也是值每秒插入 permitsPerSecond 个令牌。</li></ul><p><strong>获取令牌</strong></p><ul><li><code>void acquire()</code>: 获取一个令牌，会一直阻塞等待直到拿到。</li><li><code>void acquire(int permits)</code>: 获取 permits 个令牌，会一直阻塞等到直到全部拿到。</li><li><code>boolean tryAcquire()</code>: 获取一个令牌，成功则返回 true，失败直接返回 false。</li><li><code>boolean tryAcquire(long timeout, TimeUnit unit)</code>: 获取一个令牌，成功则返回 true，没有足够的令牌时等到 timeout 时间，如果还没有则返回 false。</li><li><code>boolean tryAcquire(int permits)</code>: 获取 permits 个令牌，成功则返回 true，失败直接返回 false。</li><li><code>boolean tryAcquire(int permits, long timeout, TimeUnit unit)</code>: 获取 permits 个令牌，成功则返回 true，没有足够的令牌时等到 timeout 时间，如果还没有则返回 false。</li></ul><p>通过上面的API可以很灵活的对 RateLimiter 进行使用，但是在阅读源码的过程中，我也发现了 Guava 的实现中有一个不尽如人意的地方。那就是限制能力只能在每秒多少个令牌桶，但是我想实现将少一秒的剩余令牌留给下一秒继续用，也就是几秒甚至更高时间单位的限流是不行的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Bursty</span> <span class="keyword">extends</span> <span class="title">RateLimiter</span> </span>&#123;</span><br><span class="line">    Bursty(RateLimiter.SleepingTicker ticker) &#123;</span><br><span class="line">        <span class="keyword">super</span>(ticker, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">doSetRate</span><span class="params">(<span class="keyword">double</span> permitsPerSecond, <span class="keyword">double</span> stableIntervalMicros)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span> oldMaxPermits = <span class="keyword">this</span>.maxPermits;</span><br><span class="line">        <span class="keyword">this</span>.maxPermits = permitsPerSecond;</span><br><span class="line">        <span class="keyword">this</span>.storedPermits = oldMaxPermits == <span class="number">0.0</span>D ? <span class="number">0.0</span>D : <span class="keyword">this</span>.storedPermits * <span class="keyword">this</span>.maxPermits / oldMaxPermits;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">storedPermitsToWaitTime</span><span class="params">(<span class="keyword">double</span> storedPermits, <span class="keyword">double</span> permitsToTake)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0L</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的代码中，<code>Bursty</code> 就是始终保持平稳速率的令牌桶类，其中 <code>maxPermits</code> 是桶中最多有多少的令牌，<code>storedPermits</code> 是现在桶中的令牌个数。可以看到<code>maxPermits</code> 始终等于 <code>permitsPerSecond</code>，是不能乘上时间系数的，并且在重新设置 <code>maxPermits</code> 后会按照比例缩放之前的桶中令牌数量。</p><h2 id="MongoSpark-save"><a href="#MongoSpark-save" class="headerlink" title="MongoSpark.save"></a>MongoSpark.save</h2><p><code>save()</code> 方法是我们需要修改的主要方法，但是在 MongoSpark 中又存在多种的 save 方法，我们需要分别为这些 save 方法加上限流功能，或者你已经很明确将使用的函数。</p><p>在这之前，我们需要做一些准备工作，既然要限流，那我们肯定需要一个参数来控制流速，而在 MongoSpark 中是有一个配置类供我们设置参数的，我们需要修改一下 <code>WriteConfig</code> 这个类。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Write Configuration for writes to MongoDB</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param databaseName       the database name</span></span><br><span class="line"><span class="comment"> * @param collectionName     the collection name</span></span><br><span class="line"><span class="comment"> * @param connectionString   the optional connection string used in the creation of this configuration.</span></span><br><span class="line"><span class="comment"> * @param replaceDocument    replaces the whole document, when saving a Dataset that contains an `_id` field.</span></span><br><span class="line"><span class="comment"> *                           If false only updates / sets the fields declared in the Dataset.</span></span><br><span class="line"><span class="comment"> * @param maxBatchSize       the maxBatchSize when performing a bulk update/insert. Defaults to 512.</span></span><br><span class="line"><span class="comment"> * @param localThreshold     the local threshold in milliseconds used when choosing among multiple MongoDB servers to send a request.</span></span><br><span class="line"><span class="comment"> *                           Only servers whose ping time is less than or equal to the server with the fastest ping time plus the local</span></span><br><span class="line"><span class="comment"> *                           threshold will be chosen.</span></span><br><span class="line"><span class="comment"> * @param writeConcernConfig the write concern configuration</span></span><br><span class="line"><span class="comment"> * @param shardKey           an optional shardKey in extended json form: `"&#123;key: 1, key2: 1&#125;"`. Used when upserting DataSets in sharded clusters.</span></span><br><span class="line"><span class="comment"> * @param forceInsert        if true forces the writes to be inserts, even if a Dataset contains an `_id` field. Default `false`.</span></span><br><span class="line"><span class="comment"> * @param ordered            configures the bulk operation ordered property. Defaults to true.</span></span><br><span class="line"><span class="comment"> * @param secondLatch        the maxBatchSize when performing a bulk update/insert per second per partition.</span></span><br><span class="line"><span class="comment"> * @since 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">WriteConfig</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    databaseName:       <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    collectionName:     <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    connectionString:   <span class="type">Option</span>[<span class="type">String</span>]     = <span class="type">None</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    replaceDocument:    <span class="type">Boolean</span>            = <span class="type">WriteConfig</span>.<span class="type">DefaultReplaceDocument</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    maxBatchSize:       <span class="type">Int</span>                = <span class="type">WriteConfig</span>.<span class="type">DefaultMaxBatchSize</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    localThreshold:     <span class="type">Int</span>                = <span class="type">MongoSharedConfig</span>.<span class="type">DefaultLocalThreshold</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    writeConcernConfig: <span class="type">WriteConcernConfig</span> = <span class="type">WriteConcernConfig</span>.<span class="type">Default</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    shardKey:           <span class="type">Option</span>[<span class="type">String</span>]     = <span class="type">None</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    forceInsert:        <span class="type">Boolean</span>            = <span class="type">WriteConfig</span>.<span class="type">DefaultForceInsert</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    ordered:            <span class="type">Boolean</span>            = <span class="type">WriteConfig</span>.<span class="type">DefautOrdered</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    secondLatch:        <span class="type">Option</span>[<span class="type">Int</span>]        = <span class="type">None</span></span></span></span><br><span class="line"><span class="class"><span class="params"></span>) <span class="keyword">extends</span> <span class="title">MongoCollectionConfig</span> <span class="keyword">with</span> <span class="title">MongoClassConfig</span> </span>&#123;</span><br><span class="line">  require(maxBatchSize &gt;= <span class="number">1</span>, <span class="string">s"maxBatchSize (<span class="subst">$maxBatchSize</span>) must be greater or equal to 1"</span>)</span><br><span class="line">  require(localThreshold &gt;= <span class="number">0</span>, <span class="string">s"localThreshold (<span class="subst">$localThreshold</span>) must be greater or equal to 0"</span>)</span><br><span class="line">  require(<span class="type">Try</span>(connectionString.map(uri =&gt; <span class="keyword">new</span> <span class="type">ConnectionString</span>(uri))).isSuccess, <span class="string">s"Invalid uri: '<span class="subst">$&#123;connectionString.get&#125;</span>'"</span>)</span><br><span class="line">  require(<span class="type">Try</span>(shardKey.map(json =&gt; <span class="type">BsonDocument</span>.parse(json))).isSuccess, <span class="string">s"Invalid shardKey: '<span class="subst">$&#123;shardKey.get&#125;</span>'"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">Self</span> </span>= <span class="type">WriteConfig</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">withOption</span></span>(key: <span class="type">String</span>, value: <span class="type">String</span>): <span class="type">WriteConfig</span> = <span class="type">WriteConfig</span>(<span class="keyword">this</span>.asOptions + (key -&gt; value))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">withOptions</span></span>(options: collection.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">WriteConfig</span> = <span class="type">WriteConfig</span>(options, <span class="type">Some</span>(<span class="keyword">this</span>))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">asOptions</span></span>: collection.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> options = mutable.<span class="type">Map</span>(<span class="string">"database"</span> -&gt; databaseName, <span class="string">"collection"</span> -&gt; collectionName,</span><br><span class="line">      <span class="type">WriteConfig</span>.replaceDocumentProperty -&gt; replaceDocument.toString,</span><br><span class="line">      <span class="type">WriteConfig</span>.localThresholdProperty -&gt; localThreshold.toString,</span><br><span class="line">      <span class="type">WriteConfig</span>.forceInsertProperty -&gt; forceInsert.toString) ++ writeConcernConfig.asOptions</span><br><span class="line">    connectionString.map(uri =&gt; options += (<span class="type">WriteConfig</span>.mongoURIProperty -&gt; uri))</span><br><span class="line">    shardKey.map(json =&gt; options += (<span class="type">WriteConfig</span>.shardKeyProperty -&gt; json))</span><br><span class="line">    secondLatch.map(number =&gt; options += (<span class="type">WriteConfig</span>.secondLatchProperty -&gt; number.toString))</span><br><span class="line">    options.toMap</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">withOptions</span></span>(options: util.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">WriteConfig</span> = withOptions(options.asScala)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">asJavaOptions</span></span>: util.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = asOptions.asJava</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * The `WriteConcern` that this config represents</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @return the WriteConcern</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">writeConcern</span></span>: <span class="type">WriteConcern</span> = writeConcernConfig.writeConcern</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是修改以后的 <code>WriteConfig</code> 类代码，我们添加上了一个 <code>secondLatch</code> 的参数作为流速控制参数。在使用的时候可以：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> writeConfig = <span class="keyword">new</span> <span class="type">WriteConfig</span>(conf.mongoDatabase, conf.mongoCollection)</span><br><span class="line">  .withOption(<span class="type">WriteConfig</span>.replaceDocumentProperty, conf.replaceDocument.toString)</span><br><span class="line">  .withOption(<span class="type">WriteConfig</span>.mongoURIProperty, conf.mongoUri)</span><br><span class="line">  .withOption(<span class="type">WriteConfig</span>.secondLatchProperty, conf.secondLatch.toString)</span><br></pre></td></tr></table></figure><p>通过 <code>withOption()</code> 的方法设定 <code>secondLatch</code> 参数，然后我们跟踪一下上面的 <code>withOption()</code> 方法的实现，是通过一个 <code>WriteConfig(options: util.Map[String, String])</code> 的构造函数进行了构造。所以也需要修改这个函数的实现：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(options: collection.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>], <span class="keyword">default</span>: <span class="type">Option</span>[<span class="type">WriteConfig</span>]): <span class="type">WriteConfig</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanedOptions = stripPrefix(options)</span><br><span class="line">  <span class="keyword">val</span> cachedConnectionString = connectionString(cleanedOptions)</span><br><span class="line">  <span class="keyword">val</span> defaultDatabase = <span class="keyword">default</span>.map(conf =&gt; conf.databaseName).orElse(<span class="type">Option</span>(cachedConnectionString.getDatabase))</span><br><span class="line">  <span class="keyword">val</span> defaultCollection = <span class="keyword">default</span>.map(conf =&gt; conf.collectionName).orElse(<span class="type">Option</span>(cachedConnectionString.getCollection))</span><br><span class="line"></span><br><span class="line">  <span class="type">WriteConfig</span>(</span><br><span class="line">    databaseName = databaseName(databaseNameProperty, cleanedOptions, defaultDatabase),</span><br><span class="line">    collectionName = collectionName(collectionNameProperty, cleanedOptions, defaultCollection),</span><br><span class="line">    connectionString = cleanedOptions.get(mongoURIProperty).orElse(<span class="keyword">default</span>.flatMap(conf =&gt; conf.connectionString)),</span><br><span class="line">    replaceDocument = getBoolean(cleanedOptions.get(replaceDocumentProperty), <span class="keyword">default</span>.map(conf =&gt; conf.replaceDocument),</span><br><span class="line">      defaultValue = <span class="type">DefaultReplaceDocument</span>),</span><br><span class="line">    maxBatchSize = getInt(cleanedOptions.get(maxBatchSizeProperty), <span class="keyword">default</span>.map(conf =&gt; conf.maxBatchSize),</span><br><span class="line">      <span class="type">DefaultMaxBatchSize</span>),</span><br><span class="line">    localThreshold = getInt(cleanedOptions.get(localThresholdProperty), <span class="keyword">default</span>.map(conf =&gt; conf.localThreshold),</span><br><span class="line">      <span class="type">MongoSharedConfig</span>.<span class="type">DefaultLocalThreshold</span>),</span><br><span class="line">    writeConcernConfig = <span class="type">WriteConcernConfig</span>(cleanedOptions, <span class="keyword">default</span>.map(writeConf =&gt; writeConf.writeConcernConfig)),</span><br><span class="line">    shardKey = cleanedOptions.get(shardKeyProperty).orElse(<span class="keyword">default</span>.flatMap(conf =&gt; conf.shardKey).orElse(<span class="type">None</span>)),</span><br><span class="line">    forceInsert = getBoolean(cleanedOptions.get(forceInsertProperty), <span class="keyword">default</span>.map(conf =&gt; conf.forceInsert),</span><br><span class="line">      defaultValue = <span class="type">DefaultForceInsert</span>),</span><br><span class="line">    ordered = getBoolean(cleanedOptions.get(orderedProperty), <span class="keyword">default</span>.map(conf =&gt; conf.ordered), <span class="type">DefautOrdered</span>),</span><br><span class="line">  <span class="comment">// 流速控制参数</span></span><br><span class="line">    secondLatch = cleanedOptions</span><br><span class="line">      .get(secondLatchProperty).orElse(<span class="keyword">default</span>.flatMap(conf =&gt; <span class="type">Try</span>(conf.secondLatch.toString).toOption).orElse(<span class="type">None</span>))</span><br><span class="line">      .flatMap(s =&gt; <span class="type">Try</span>(s.toInt).toOption)</span><br><span class="line">  )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这个构造函数调用的是一个要传递所有参数的构造函数进行构造的，所以我们还需要实现这样一个传递所有参数的构造函数，然后加上：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">secondLatch = cleanedOptions</span><br><span class="line">      .get(secondLatchProperty).orElse(<span class="keyword">default</span>.flatMap(conf =&gt; <span class="type">Try</span>(conf.secondLatch.toString).toOption).orElse(<span class="type">None</span>))</span><br><span class="line">      .flatMap(s =&gt; <span class="type">Try</span>(s.toInt).toOption)</span><br></pre></td></tr></table></figure><p>由于 <code>options</code> 的 value 都是字符串，所以这边需要转一下 <code>Int</code>，传递所有参数的构造函数如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Creates a WriteConfig</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * @param databaseName      the database name</span></span><br><span class="line"><span class="comment">  * @param collectionName    the collection name</span></span><br><span class="line"><span class="comment">  * @param connectionString  the optional connection string used in the creation of this configuration</span></span><br><span class="line"><span class="comment">  * @param replaceDocument   replaces the whole document, when saving a Dataset that contains an `_id` field.</span></span><br><span class="line"><span class="comment">  *                          If false only updates / sets the fields declared in the Dataset.</span></span><br><span class="line"><span class="comment">  * @param maxBatchSize      the maxBatchSize when performing a bulk update/insert. Defaults to 512.</span></span><br><span class="line"><span class="comment">  * @param localThreshold    the local threshold in milliseconds used when choosing among multiple MongoDB servers to send a request.</span></span><br><span class="line"><span class="comment">  *                          Only servers whose ping time is less than or equal to the server with the fastest ping time plus the local</span></span><br><span class="line"><span class="comment">  *                          threshold will be chosen.</span></span><br><span class="line"><span class="comment">  * @param writeConcern      the WriteConcern to use</span></span><br><span class="line"><span class="comment">  * @param shardKey          an optional shardKey in extended form: `"&#123;key: 1, key2: 1&#125;"`. Used when upserting DataSets in sharded clusters.</span></span><br><span class="line"><span class="comment">  * @param forceInsert       if true forces the writes to be inserts, even if a Dataset contains an `_id` field. Default `false`.</span></span><br><span class="line"><span class="comment">  * @param ordered           configures if the bulk operation is ordered property.</span></span><br><span class="line"><span class="comment">  * @param secondLatch       the maxBatchSize when performing a bulk update/insert per second per partition.</span></span><br><span class="line"><span class="comment">  * @return the write config</span></span><br><span class="line"><span class="comment">  * @since jike-1.0.0</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(databaseName: <span class="type">String</span>, collectionName: <span class="type">String</span>, connectionString: <span class="type">Option</span>[<span class="type">String</span>], replaceDocument: <span class="type">Boolean</span>, maxBatchSize: <span class="type">Int</span>,</span><br><span class="line">          localThreshold: <span class="type">Int</span>, writeConcern: <span class="type">WriteConcern</span>, shardKey: <span class="type">Option</span>[<span class="type">String</span>], forceInsert: <span class="type">Boolean</span>, ordered: <span class="type">Boolean</span>, secondLatch: <span class="type">Option</span>[<span class="type">Int</span>]): <span class="type">WriteConfig</span> = &#123;</span><br><span class="line">  apply(databaseName, collectionName, connectionString, replaceDocument, maxBatchSize, localThreshold, <span class="type">WriteConcernConfig</span>(writeConcern),</span><br><span class="line">    shardKey, forceInsert, ordered, secondLatch)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 <code>case class</code> 提供的默认构造函数进行构造，至此我们就能愉快的对包含 <code>secondLatch</code> 字段的 <code>WriteConfig</code> 进行构造了。</p><h3 id="Save-Method"><a href="#Save-Method" class="headerlink" title="Save Method"></a>Save Method</h3><p>然后我们就需要分别对多个 <code>save()</code> 添加限速器，原理都大同小异，就是在 <code>foreachPartition</code> 的函数中构建令牌桶，然后在 <code>foreach</code> 的写Mongodb 函数之前进行阻塞的令牌获取，这里就展示常用的 Datasets 和 RDD 类型 save 方法的修改：</p><p><strong>save[D] (dataset: Dataset[D]): Unit</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Save data to MongoDB</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * '''Note:''' If the dataFrame contains an `_id` field the data will upserted and replace any existing documents in the collection.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param dataset the dataset to save to MongoDB</span></span><br><span class="line"><span class="comment"> * @param writeConfig the writeConfig</span></span><br><span class="line"><span class="comment"> * @tparam D</span></span><br><span class="line"><span class="comment"> * @since 1.1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span></span>[<span class="type">D</span>](dataset: <span class="type">Dataset</span>[<span class="type">D</span>], writeConfig: <span class="type">WriteConfig</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> mongoConnector = <span class="type">MongoConnector</span>(writeConfig.asOptions)</span><br><span class="line">  <span class="keyword">val</span> dataSet = dataset.toDF()</span><br><span class="line">  <span class="keyword">val</span> mapper = rowToDocumentMapper(dataSet.schema)</span><br><span class="line">  <span class="keyword">val</span> documentRdd: <span class="type">RDD</span>[<span class="type">BsonDocument</span>] = dataSet.rdd.map(row =&gt; mapper(row))</span><br><span class="line">  <span class="keyword">val</span> fieldNames = dataset.schema.fieldNames.toList</span><br><span class="line">  <span class="keyword">val</span> queryKeyList = <span class="type">BsonDocument</span>.parse(writeConfig.shardKey.getOrElse(<span class="string">"&#123;_id: 1&#125;"</span>)).keySet().asScala.toList</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (writeConfig.forceInsert || !queryKeyList.forall(fieldNames.contains(_))) &#123;</span><br><span class="line">    <span class="type">MongoSpark</span>.save(documentRdd, writeConfig)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    documentRdd.foreachPartition(iter =&gt; <span class="keyword">if</span> (iter.nonEmpty) &#123;</span><br><span class="line"><span class="comment">// **INIT RateLimiter</span></span><br><span class="line">      <span class="keyword">var</span> rateLimiter: <span class="type">Option</span>[<span class="type">RateLimiter</span>] = <span class="type">None</span></span><br><span class="line">      <span class="keyword">if</span> (writeConfig.secondLatch.isDefined) &#123;</span><br><span class="line">        <span class="comment">// If secondLatch &lt; maxBatchSize, it will destroy rate limit rule.</span></span><br><span class="line">        <span class="keyword">val</span> permitSize = <span class="keyword">if</span> (writeConfig.secondLatch.get &gt;= writeConfig.maxBatchSize) (writeConfig.secondLatch.get / writeConfig.maxBatchSize).floor <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        rateLimiter = <span class="type">Option</span>.apply(<span class="type">RateLimiter</span>.create(permitSize))</span><br><span class="line">      &#125;</span><br><span class="line">      mongoConnector.withCollectionDo(writeConfig, &#123; collection: <span class="type">MongoCollection</span>[<span class="type">BsonDocument</span>] =&gt;</span><br><span class="line">        iter.grouped(writeConfig.maxBatchSize).foreach(batch =&gt; &#123;</span><br><span class="line"><span class="comment">// **Acquire</span></span><br><span class="line">          <span class="keyword">if</span> (rateLimiter.isDefined) &#123;</span><br><span class="line">            rateLimiter.get.acquire(<span class="number">1</span>)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">val</span> requests = batch.map(doc =&gt;</span><br><span class="line">            <span class="keyword">if</span> (queryKeyList.forall(doc.containsKey(_))) &#123;</span><br><span class="line">              <span class="keyword">val</span> queryDocument = <span class="keyword">new</span> <span class="type">BsonDocument</span>()</span><br><span class="line">              queryKeyList.foreach(key =&gt; queryDocument.append(key, doc.get(key)))</span><br><span class="line">              <span class="keyword">if</span> (writeConfig.replaceDocument) &#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="type">ReplaceOneModel</span>[<span class="type">BsonDocument</span>](queryDocument, doc, <span class="keyword">new</span> <span class="type">ReplaceOptions</span>().upsert(<span class="literal">true</span>))</span><br><span class="line">              &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                queryDocument.keySet().asScala.foreach(doc.remove(_))</span><br><span class="line">                <span class="keyword">new</span> <span class="type">UpdateOneModel</span>[<span class="type">BsonDocument</span>](queryDocument, <span class="keyword">new</span> <span class="type">BsonDocument</span>(<span class="string">"$set"</span>, doc), <span class="keyword">new</span> <span class="type">UpdateOptions</span>().upsert(<span class="literal">true</span>))</span><br><span class="line">              &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              <span class="keyword">new</span> <span class="type">InsertOneModel</span>[<span class="type">BsonDocument</span>](doc)</span><br><span class="line">            &#125;)</span><br><span class="line">          collection.bulkWrite(requests.toList.asJava, <span class="keyword">new</span> <span class="type">BulkWriteOptions</span>().ordered(writeConfig.ordered))</span><br><span class="line">        &#125;)</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>save[D: ClassTag] (rdd: RDD[D]): Unit</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Save data to MongoDB</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param rdd the RDD data to save to MongoDB</span></span><br><span class="line"><span class="comment"> * @param writeConfig the writeConfig</span></span><br><span class="line"><span class="comment"> * @tparam D the type of the data in the RDD</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span></span>[<span class="type">D</span>: <span class="type">ClassTag</span>](rdd: <span class="type">RDD</span>[<span class="type">D</span>], writeConfig: <span class="type">WriteConfig</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> mongoConnector = <span class="type">MongoConnector</span>(writeConfig.asOptions)</span><br><span class="line">  rdd.foreachPartition(iter =&gt; <span class="keyword">if</span> (iter.nonEmpty) &#123;</span><br><span class="line">    <span class="comment">// **INIT RateLimiter</span></span><br><span class="line">    <span class="keyword">var</span> rateLimiter: <span class="type">Option</span>[<span class="type">RateLimiter</span>] = <span class="type">None</span></span><br><span class="line">    <span class="keyword">if</span> (writeConfig.secondLatch.isDefined) &#123;</span><br><span class="line">      <span class="comment">// If secondLatch &lt; maxBatchSize, it will destroy rate limit rule.</span></span><br><span class="line">      <span class="keyword">val</span> permitSize = <span class="keyword">if</span> (writeConfig.secondLatch.get &gt;= writeConfig.maxBatchSize) (writeConfig.secondLatch.get / writeConfig.maxBatchSize).floor <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">      rateLimiter = <span class="type">Option</span>.apply(<span class="type">RateLimiter</span>.create(permitSize))</span><br><span class="line">    &#125;</span><br><span class="line">    mongoConnector.withCollectionDo(writeConfig, &#123; collection: <span class="type">MongoCollection</span>[<span class="type">D</span>] =&gt;</span><br><span class="line">      iter.grouped(writeConfig.maxBatchSize).foreach(batch =&gt; &#123;</span><br><span class="line">  <span class="comment">// **Acquire</span></span><br><span class="line">        <span class="keyword">if</span> (rateLimiter.isDefined) &#123;</span><br><span class="line">          rateLimiter.get.acquire(<span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        collection.insertMany(</span><br><span class="line">          batch.toList.asJava,</span><br><span class="line">          <span class="keyword">new</span> <span class="type">InsertManyOptions</span>().ordered(writeConfig.ordered)</span><br><span class="line">        )</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需要注意的是不要在 Driver 上去初始化 <code>RateLimiter</code>，还要注意与 WriteConfig 中已存在的 <code>maxBatchSize</code> 参数的关系。</p><p>到这里就能愉快的进行限速了。</p>]]></content>
      
      
      
        <tags>
            
            <tag> mongodb </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FROM BIGTABLE TO DRUID</title>
      <link href="/2019/04/06/a13/"/>
      <url>/2019/04/06/a13/</url>
      
        <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>最近在学习 <code>Druid</code>，索性整理了一下从 Google 的 BigTable 论文衍生出的这一系列数据产品架构思路。该文章中通过对 BigTable 文章的介绍到 Hbase 再到 Druid，读者会发现这三者非常的相似，但是又由于不同的使用场景而做了其他的优化。由于作者也是初学者，所以多是对网上文章的整理汇总，也算初有脉络，但是总的来说还是一篇纸上谈兵的文章，仅作为对学习的记录。之后应该会在分布式系统上有更多的实战文章。</p><h1 id="BigTable"><a href="#BigTable" class="headerlink" title="BigTable"></a>BigTable</h1><p><code>Bigtable</code> 是一个分布式的结构化数据存储系统，它被设计用来处理海量数据。</p><p>这是论文开篇的概括，也作为这篇博客的开始吧。</p><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(row: string, column: string, time: int64) -&gt; string</span><br></pre></td></tr></table></figure><p><img src="/images/a-13-1.png" alt="a-13-1"></p><p>整个 <code>BigTable</code> 的数据模型可以看作是一个很简单的映射，分别是 row，cloumn，time 到一个具体数据的映射。如上图是一个简单的例子，行名是一个反向 URL。contents 列族存放的是网页的内容，anchor 列族存放引用该网页的锚链接文本。 CNN 的主页被 Sports Illustrator 和 MY-look 的主页引用，因此该行包含了名为 <code>anchor:cnnsi.com</code> 和 <code>anchhor:my.look.ca</code> 的列。每个锚链接只有一个版本，而 contents 列则有三个版本，分别由时间戳 t3，t5 和 t6 标识，最新的时间戳会放在最前面。</p><h2 id="架构组件"><a href="#架构组件" class="headerlink" title="架构组件"></a>架构组件</h2><p>这整个系统当中主要有三部分的组件，分别是 Master 服务器，Tablet 服务器和 Chubby 服务器构成。在后面对其他框架的介绍当中，会发现基础架构有很高的相似性。</p><h3 id="Master-服务器（控制者）"><a href="#Master-服务器（控制者）" class="headerlink" title="Master 服务器（控制者）"></a>Master 服务器（控制者）</h3><p>主要工作：</p><ul><li>为 Tablet 服务器分配 Tablets。</li><li>检测新加入的或者过期失效的 Tablet 服务器。</li><li>对 Tablet 服务器进行负载均衡、以及对保存在 GFS 上的文件进行垃圾收集。</li><li>除此之外，它还处理对模 式的相关修改操作，例如建立表和列族。</li></ul><h3 id="Tablet-服务器（工作者）"><a href="#Tablet-服务器（工作者）" class="headerlink" title="Tablet 服务器（工作者）"></a>Tablet 服务器（工作者）</h3><p>主要工作：管理一个 Tablet 的集合（通常每个服务器有大约数十个至上千个 Tablet）。每个 Tablet 服务器负责处理它所加载的 Tablet 的读写操作，以及在 Tablets 过大时，对其进行分割。</p><h3 id="Chubby（协调者）"><a href="#Chubby（协调者）" class="headerlink" title="Chubby（协调者）"></a>Chubby（协调者）</h3><p>在说 <code>Chubby</code> 之前想插入一个小话题，到底是什么是 <code>分布式一致性问题(Distributed consensus problem)</code> 。其实在接触分布式系统开始这个问题基本上在每一篇分布式系统的文章中都会被提及，但是在感性的认识下，我发现自己很难用简洁的语言进行概括，所以去查阅了一些文章，有一段是我很认同的简介描述：</p><p>在一个分布式系统中，有一组的 Process，他们需要确定一个 Value。于是每个 Process 都提出一个 Value， 一致性就是指只有其中的一个 Value 能够被选中作为最后确定的值，并且当这个值被选出来后，所有的 Process 都需要被通知到。</p><p>表面上看，这个问题很容易解决。比如设置一个server，所有的process都 向这个server提交一个Value，这个server可以通过一个简单的规则来挑选出一个Value（例如最先到达的Value被选中），然后由这个 server通知所有的Process。但是在分布式系统中，就会有各种的问题发生，例如，这个server崩溃了怎么办，所以我们可能需要有几台 server共同决定。还有，Process提交Value的时间都不一样，网络传输过程中由于延迟这些Value到达server的顺序也都没有保证。</p><p>有一个很具象的例子：</p><p>在Google File System(GFS) 中，有很多的server，这些server需要选举其中的一台作为master server。这其实是一个很典型的consensus问题，Value就是master server的地址。GFS就是用Chubby来解决的这个问题，所有的server通过Chubby提供的通信协议到Chubby server上创建同一个文件，当然，最终只有一个server能够获准创建这个文件，这个server就成为了master，它会在这个文件中写入自己 的地址，这样其它的server通过读取这个文件就能知道被选出的master的地址。</p><p>对应于 <code>Chubby</code> 就会有一个众所周知的开源项目 <code>Zookeeper</code>，两者从作用到架构上都非常的相似。但是又存在一些差别，文章后面会简单叙述一下两者的不同，不过可以类比 <code>Zookeeper</code> 来理解 <code>Chubby</code>。</p><p>前面说了这么多，那 <code>Chubby</code> 到底是一个什么服务。首先它是一个分布式的文件系统，可以提供机制使得 client 可以在 Chubby service 上创建文件和执行一些文件的基本操作。从更高一点的语义层面上。Chubby 是一个分布式的锁系统，“锁” 就是文件，加锁操作就是创建文件成功的那个 server 抢占到了 “锁”。用户通过打开、关闭和读取文件，获取共享锁或者独占锁；并且通过通信机制，向用户发送更新信息。</p><h3 id="Tablet（数据聚合单位）"><a href="#Tablet（数据聚合单位）" class="headerlink" title="Tablet（数据聚合单位）"></a>Tablet（数据聚合单位）</h3><h4 id="INDEX"><a href="#INDEX" class="headerlink" title="INDEX"></a>INDEX</h4><p><img src="/images/a-13-2.png" alt="a-13-2"></p><p>Index 是一个三层的B树，由于 Root tablet 不会分裂，所以永远是三层。真正的 Tablet 位置信息存储在第三层每一个行关键字下，而第二层只是对第三层的索引。Root tablet 储存在 Chubby 中。在客户端会缓存 Tablet 的位置信息，如果客户端没有缓存或者发现它的缓存地址不正确，就在树状的存储结构中递归的查询 Tablet 位置信息。如果客户端缓存是空的，那么需要三次寻址。如果是过期了则需要6次，3次是在缓存中寻找，3次是更新缓存。</p><h4 id="分配"><a href="#分配" class="headerlink" title="分配"></a>分配</h4><p>在任何一个时刻，一个Tablet 只能分配给一个Tablet服务器。Master服务器记录了当前有哪些活跃的 Tablet 服务器、哪些 Tablet 分配给了哪些 Tablet 服务器、哪些 Tablet 还没有被分配。当一个 Tablet 还没有被分配、 并且刚好有一个 Tablet 服务器有足够的空闲空间装载该 Tablet 时，Master 服务器会给这个 Tablet 服务器发送一个装载请求，把 Tablet 分配给这个服务器。</p><p>BigTable 使用 Chubby 跟踪记录 Tablet 服务器的状态。当一个 Tablet 服务器启动时，它在 Chubby 的一个 指定目录下建立一个有唯一性名字的文件，并且获取该文件的独占锁。Master 服务器实时监控着这个目录（服务器目录），因此 Master 服务器能够知道有新的 Tablet 服务器加入了。如果 Tablet 服务器丢失了 Chubby 上的独占锁，比如由于网络断开导致 Tablet 服务器和 Chubby 的会话丢失 — 它就停止对 Tablet 提供服务。（Chubby 提供了一种高效的机制，利用这种机制，Tablet 服务器能够在不增加网络负担的情况下知道它是否 还持有锁）。只要文件还存在，Tablet 服务器就会试图重新获得对该文件的独占锁；如果文件不存在了，那么 Tablet 服务器就不能再提供服务了，它会自行退出。</p><h4 id="冲写"><a href="#冲写" class="headerlink" title="冲写"></a>冲写</h4><p>在 BigTable 中一次写操作会先被记录在日志文件当中，然后被记入 <code>memtable</code> 中。这里 <code>memtable</code> 实际上就是一个写缓存，随着写操作的执行，<code>memtable</code> 的大小不断增加。当 <code>memtable</code> 的尺寸到达一个门限值的时候，这个 <code>memtable</code> 就会被冻结，然后创建一个新的 <code>memtable</code>；被冻结住 <code>memtable</code> 会被转换成 SSTable，然后写入 GFS。这个过程被称为 <code>Minor Compaction</code>， 它有两个目的：收缩 Tablet 服务器使用的内存，以及在服务器灾难恢复过程中，减少必须从 提交日志里读取的数据量。在 Compaction 过程中，正在进行的读写操作仍能继续。</p><p>而每一次 Minor Compaction 都会创建一个新的 SSTable。如果 Minor Compaction 过程不停滞的持续进行下去，读操作可能需要合并来自多个 SSTable 的更新。通过定期在后台执行 Tablet 的合并，来限制这类文件的数量，加速存储使用率和读速度，这个过程被称为 <code>Merging Compaction</code>。</p><p>这两个步骤在 BIGTABLE 系统中非常的重要，这也是在读写分离架构中，得以优化读写效率的根本，在后面其他系统的设计当中能也能看到类似的优化设计。</p><h4 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h4><p>Tablet 是逻辑层面的存储单元，而实际的存储单元是 SSTable，SSTable 是一个持久化的、排序的、不可更改的 Map 结构，而 Map 是一个 key-value 映射的数据结构，key 和 value 的值都是任意的 Byte 串。可以对 SSTable 进行如下的操作：查询与一个 key 值相关的 value，或者遍历某个 key 值范围内的所有的 key-value 对。从内 部看，SSTable 是一系列的数据块（通常每个块的大小是 64KB，这个大小是可以配置的）。SSTable 使用块索 引（通常存储在 SSTable 的最后）来定位数据块；在打开 SSTable 的时候，索引被加载到内存，来提高查询、读取效率。</p><h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><h2 id="HMaster"><a href="#HMaster" class="headerlink" title="HMaster"></a>HMaster</h2><p>没有单点故障问题，启动多个 HMaster，通过 Zookeeper 的 Master Election 机制保证同时只有一个 HMaster 处于 Active，其他处于热备份的状态，定期从 Active 的 Master 同步其最新状态。</p><p>主要作用：</p><ul><li>管理 HReigonServer，实现其负载均衡<ul><li>启动时HRegion的分配，以及负载均衡和修复时 HRegion 的重新分配</li><li>监控集群中所有 HRegionServer 的状态（通过 Heartbeat 和监听 Zookeeper 中的状态）</li></ul></li><li>管理和分配 HRegion</li><li>实现 DDL 操作 (Data Defintion Language, namespace 和 table 的增删改，column family的增删改等)</li><li>管理 namespace 和 table 的元数据</li><li>权限控制</li></ul><h2 id="HRegionServer（工作者"><a href="#HRegionServer（工作者" class="headerlink" title="HRegionServer（工作者)"></a>HRegionServer（工作者)</h2><p>HRegionServer一般和DataNode在同一台机器上运行，实现数据的本地性。</p><p>存放和管理本地HRegion。<br>读写HDFS，管理Table中的数据。<br>Client直接通过HRegionServer读写数据<br>可以发现 HRegionServer 的作用与 BigTable 中 Tablet 服务器的作用几乎一摸一样，下面介绍更多它内部的机制：</p><h3 id="WAL（WRITE-AHEAD-LOG）"><a href="#WAL（WRITE-AHEAD-LOG）" class="headerlink" title="WAL（WRITE AHEAD LOG）"></a>WAL（WRITE AHEAD LOG）</h3><p>所有的写操作都会保证将数据写入 LOG 文件以后，才会真正更新 MemStore（写缓存），最后写入 HFile 中。采用这种模式，可以保证HRegionServer宕机后，我们依然可以从该Log文件中读取数据，Replay所有的操作，而不至于数据丢失。这个Log文件会定期Roll出新的文件而删除旧的文件(那些已持久化到HFile中的Log可以删除)。</p><h3 id="BLOCKCACHE（读缓存）"><a href="#BLOCKCACHE（读缓存）" class="headerlink" title="BLOCKCACHE（读缓存）"></a>BLOCKCACHE（读缓存）</h3><p>基于分空间局部性和时间局部性原理，将数据预读取到内存中，以提升读性能。HBase 提供了两种 BlockCache 的实现，默认是 on-heap LRUBlockCache 和 BucketCache(off-heap)。通常BucketCache的性能要差于LruBlockCache，然而由于GC的影响，LruBlockCache的延迟会变的不稳定，而BucketCache由于是自己管理BlockCache，而不需要GC，因而它的延迟通常比较稳定，这也是有些时候需要选用BucketCache的原因。在 BlockCache 101 - Nick Dimiduk 中更加详细的对比。</p><h3 id="HSTORE（最小单位）"><a href="#HSTORE（最小单位）" class="headerlink" title="HSTORE（最小单位）"></a>HSTORE（最小单位）</h3><p><img src="/images/a-13-3.png" alt="a-13-3"></p><p>一个Table可以有一个或多个Region，他们可以在一个相同的HRegionServer上，也可以分布在不同的HRegionServer上，一个HRegionServer可以有多个HRegion，他们分别属于不同的Table。HRegion由多个Store(HStore)构成，每个HStore对应了一个Table在这个HRegion中的一个Column Family，即每个Column Family就是一个集中的存储单元，因而最好将具有相近IO特性的Column存储在一个Column Famil。</p><h4 id="MEMSTORE（写缓存）"><a href="#MEMSTORE（写缓存）" class="headerlink" title="MEMSTORE（写缓存）"></a>MEMSTORE（写缓存）</h4><p>所有数据的写在完成WAL日志写后，会 写入MemStore中，由MemStore根据一定的算法将数据Flush到地层HDFS文件中(HFile)，通常每个HRegion中的每个 Column Family有一个自己的MemStore。</p><ul><li>每一次Put/Delete请求都是先写入到MemStore中，当MemStore满后会Flush成一个新的StoreFile(底层实现是HFile)，即一个HStore(Column Family)可以有0个或多个StoreFile(HFile)。有以下三种情况可以触发MemStore的Flush动作，需要注意的是MEMSTORE的最小FLUSH单元是HREGION而不是单个MEMSTORE。</li><li>当一个HRegion中的所有MemStore的大小总和超过了size。当前 HRegion 下的所有 MemStore 进行 flush。</li><li>当全局MemStore的大小总和超过了size，当前 HRegionServer 下的所有 MemStore 进行 flush.</li><li>当前HRegionServer中WAL的大小超过了size，当前 HRegionServer 下的所有 MemStore 进行 flush。依照时间先后顺序，直到 WAL 少于 size。</li></ul><h3 id="HFILE"><a href="#HFILE" class="headerlink" title="HFILE"></a>HFILE</h3><p>用于存储HBase的数据。</p><h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><p>在产品定位上，Zookeeper 是一个 <code>Distributed process coordinator</code> 而 Chubby 是一个 <code>Distributed lock service</code>。而高一致性与它的使用场景密切相关，由于 Chubby 主要处理少量的写更多的读操作的场景，提供粗力度的锁，所以是需要缓存的。而如果需要进行一次数据更新，Chubby 会先保证所有的缓存都进行更新以后才宣布这次更新完成。而这样的缓存机制在 Zookeeper 中是不存在的，所以当你在 Zookeeper 中进行数据更新，更新作用到 A 副本上，但是没来得及同步到 B 副本上是，就会出现 AB 副本数据不一致的情况。</p><p>而开源有开源的好处，在 Zookeeper 客户端上有 Apache 项目 <code>Curator</code> 进行了高度的封装，提供了这样的缓存机制，提升了 Zookeeper 的一致性等级。所以使用 Zookeeper 加上 Curator 的话是等于 Chubby 的。</p><p>下面再介绍一下它是如何在 HBase 中的作用：</p><ul><li>在HMaster和HRegionServer连接到ZooKeeper后创建Ephemeral节点，并使用Heartbeat机制维持这个节点的存活状态，如果某个Ephemeral节点实效，则HMaster会收到通知，并做相应的处理。<br>协调多个热备份的 HMaster 节点，通过监听 <code>/hbase/master</code> 来确认 Active Master 节点的状态，如果节点消失，则得到通知，并将自己转为 Activer HMaster。</li><li>Hbase 使用 RowKey 将表水平切割成多个 HRegion，每个 HRegion 都记录了它的 StartKey 和 EndKey，且有序。HRegion 由 HMaster 分配到相应的 HRegionServer 中，然后由 HRegionServer 复杂 HRegion 的启动和管理，和 Client 的通信，负责数据的读（使用 HDFS）。每个 HRegionServer 可以同时管理1000个左右的 HRegion。现在很多的分布式存储都使用这种横向切割，列式存储的方式。</li></ul><h2 id="HRegion（数据聚合单位"><a href="#HRegion（数据聚合单位" class="headerlink" title="HRegion（数据聚合单位)"></a>HRegion（数据聚合单位)</h2><p>Hbase 使用 RowKey 将表水平切割成多个 HRegion，每个 HRegion 都记录了它的 StartKey 和 EndKey，且有序。HRegion 由 HMaster 分配到相应的 HRegionServer 中，然后由 HRegionServer 复杂 HRegion 的启动和管理，和 Client 的通信，负责数据的读（使用 HDFS）。每个 HRegionServer 可以同时管理1000个左右的 HRegion。现在很多的分布式存储都使用这种横向切割，列式存储的方式。</p><p>INDEX</p><p><img src="/images/a-13-4.jpg" alt="a-13-4"></p><p>可以发现这张图和 BigTable 的 Tablet 索引图几乎一摸一样，不过有趣的是在 0.96 以后，HBase 觉得自己不需要这么大的地址空间，并以每次查询多一次寻址的代价。所以改为了两层结构，并且也保证了 <code>META Table</code> 像之前的 Root table 一样是不可切割的，保证这棵 B 树永远只有两层结构。同样提供客户端缓存。</p><h1 id="Druid"><a href="#Druid" class="headerlink" title="Druid"></a>Druid</h1><h2 id="底层模型的演进"><a href="#底层模型的演进" class="headerlink" title="底层模型的演进"></a>底层模型的演进</h2><p>在中插一个小话题，说说数据存储系统底层模型的一个演进之路。从最开始的平衡树到 B+ 树再到 LSM树：</p><ul><li><p>平衡树缺点：树高为 log2(N)，对于索引树来说树高越高，意味着查找所要的花费的访问次数越多，查询效率越低。（常数代价高）况且主存从磁盘读数据一般以页为单位，每次访问磁盘读取多个扇区的数据（大约4kb），远大于单个二叉树节点的值，造成了不必要的查询浪费。</p></li><li><p>B+ tree 缺点：叶子节点慢慢分裂，可能导致逻辑上原本连续的数据实际上存放在不同的物理磁盘块位置上，在做范围查询的时候会导致较高的 IO，影响性能。</p></li><li><p>LSM-tree 特点：在磁盘的访问中，顺序访问的速度是远大于随机访问的速度。而 LSM-tree 正是顺应了这个特点，保证数据的有序性以将一个请求转化为顺序的磁盘访问。在 LSM-tree 中同时使用两部分类树的结构来存储数据，并同时提供查询。其中一部分数据存放在内存中，负责接受新的数据插入更新以及读请求，并直接在内存中对数据进行排序。另外一部分存放在硬盘上，它们是由存放在内存中的 c0 树冲写到磁盘而成，主要提供读，特点是有序且不可别更改。再通过 WAL 原则来容灾恢复，使用 bloom filter 来快速判断数据的存在性。而其更适合插入操作远多于数据更新删除操作与读操作的场景。</p></li></ul><p>Druid 在架构上借鉴了 LSM-tree 的思想，但是也因为使用场景的关系有一些取舍。由于不支持数据修改，所以直接去掉了 WAL 原则。数据直接进入内存的堆区，到达条件后冲写到硬盘上形成一个数据块，同时实时节点又会立即将新生成的数据块加载到非堆区。会周期性的堆 Segment split 进行合并，合并好的会立即被实时节点上传到数据文件存储库中，随后协调节点会指导一个历史节点去文件存储库，将新生成的 Segment 下载到其本地磁盘中。当历史节点成功加载到 Segment 后，会通过协调服务在集群中声明其从此刻开始负责提供该 Segment 的查询。实时节点收到该声明后就不再提供 Segment 的查询服务。</p><h2 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h2><h3 id="实时节点（工作者-内存读写）"><a href="#实时节点（工作者-内存读写）" class="headerlink" title="实时节点（工作者 内存读写）"></a>实时节点（工作者 内存读写）</h3><p>主要负责即时摄入实时数据，以及生成 Segment 数据文件。如 Kafka 的消费，可以开多个节点对多个 Partition 进行同时消费，在 Zookeeper 上记录 partition offset，保证 at least one。</p><p><img src="/images/a-13-5.png" alt="a-13-5"></p><p>上图是实时节点的数据流图，可以看到实时数据会先被写入堆内存当中。在写到一定数量以后，会形成一个 <code>Segement split</code> 持久化保存到硬盘中，且堆内存能保证 <code>Segement split</code> 内部的有序性。而一个 <code>Segement split</code> 马上会被从硬盘里读取到非堆内存中，而此时堆内存中相同的数据会被清理掉。一个查询请求会同时到堆内存和非堆内存里查询数据再进行拼接以后进行返回。</p><h3 id="协调节点（历史节点的控制者）"><a href="#协调节点（历史节点的控制者）" class="headerlink" title="协调节点（历史节点的控制者）"></a>协调节点（历史节点的控制者）</h3><p>负责历史节点的数据负载均衡，以及通过规则管理数据的生命周期。Druid 通过对每个 DataSource 设置的规则来加载或丢弃具体的数据文件，以管理数据生命周期。在历史节点推出系统的时候，协调节点还没有把其身上携带的 Segment 负载到其他节点身上的时候，会出现短暂的数据无法访问。而Druid 允许通过 创建 Segment 的副本来解决该问题。</p><h3 id="历史节点（工作者-读）"><a href="#历史节点（工作者-读）" class="headerlink" title="历史节点（工作者 读）"></a>历史节点（工作者 读）</h3><p>历史节点负责加载已经生成好的数据文件以提供查询，并且由协调节点来进行负载均衡。历史节点在启动的时候，首先检查自己的本地缓存中已经存在的 Segment 数据文件，然后从 DeepStorage 中下载属于自己但目前不在自己本地磁盘的 Segment 数据。无论是何种查询，历史节点都会将相关的 Segment 先加入到自己的内存中，然后提供查询服务。</p><p>历史节点的查询速度与其内存空间大小和所负责的Segment 数据文件大小之比成正比。Druid 对历史节点进行分层，可以根据数据温度来协调数据的存储位置。</p><p>通过 Zookeeper 来协调高可用和高拓展性，新的历史节点被添加后，会通过 Zookeeper 被协调节点发现，然后协调节点将会自动分配相关的 Segment 给它。原有的历史节点被移除的时候，同样会被协调节点发现。</p><h3 id="查询节点（工作者）"><a href="#查询节点（工作者）" class="headerlink" title="查询节点（工作者）"></a>查询节点（工作者）</h3><p>对外提供查询服务，从历史节点和事实节点查询数据，合并后回传。提供缓存机制，使用多个查询节点来防止单点故障，使用 Nginx 来做负载均衡。保证每个查询节点在对同一个请求相应的时候返回相同的结果。</p><h3 id="Segment（数据聚合单位）"><a href="#Segment（数据聚合单位）" class="headerlink" title="Segment（数据聚合单位）"></a>Segment（数据聚合单位）</h3><p><img src="/images/a-13-6.jpeg" alt="a-13-6"></p><h3 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h3><p><img src="/images/a-13-7.png" alt="a-13-7"></p><p>实线是数据请求的流向，虚线是实时数据的流向。</p><p>实时数据会先进入实时节点的堆内存，在堆内存的大小达到一定的数量以后，会形成 <code>Segment split</code> 冲写到硬盘里，同时这个 <code>Segement split</code> 会被加载到非堆内存中以供访问。并且会提供周期性的 <code>Merging Compaction</code>，由几个小的 <code>Segment split</code> 合成一个 Segement，并存入到存储节点中。存储完成以后会告之协调节点，由协调节点进行负载均衡，决定把这个 Segement 交给一个历史节点，之后这个历史节点会声明对这个 Segement 的查询提供服务，而实时节点收到这个消息以后就不再对这个 Segement 的查询提供服务了，并清理掉相关数据。</p><p>一个请求进入系统以后会先到查询节点，查询节点再通过现在各节点对数据的负责情况，分别到实时节点和历史节点上进行查询，最后将结果合并进行返回。并且在查询节点上会提供各等级的缓存，历史节点则提供 Block cache。</p><h2 id="End"><a href="#End" class="headerlink" title="End"></a>End</h2><p>相信你在阅读以后能明显的感受到三个系统的相似与区别，并对这种分布式架构有个大体上的理解。本篇博客大部分内容都是对现有文章的整理，汇总。所以最后感谢这些文章及其作者：</p><ul><li><a href="http://blog.bizcloudsoft.com/wp-content/uploads/Google-Bigtable%E4%B8%AD%E6%96%87%E7%89%88_1.0.pdf" target="_blank" rel="noopener">BigTable 翻译版</a> </li><li><a href="http://static.usenix.org/event/osdi06/tech/chang/chang.pdf" target="_blank" rel="noopener">BigTable 原版</a> </li><li><a href="https://www.microsoft.com/en-us/research/uploads/prod/2016/12/paxos-simple-Copy.pdf" target="_blank" rel="noopener">Paxos Made Simple</a> </li><li><a href="https://blog.csdn.net/historyasamirror/article/details/3870168" target="_blank" rel="noopener">Google利器之Chubby</a> </li><li><a href="http://www.blogjava.net/DLevin/archive/2015/08/22/426877.html?opt=admin" target="_blank" rel="noopener">深入HBase架构解析（一） - 上善若水</a> </li></ul><ul><li><a href="http://www.n10k.com/blog/blockcache-101/" target="_blank" rel="noopener">BlockCache 101 - Nick Dimiduk</a> </li><li><a href="http://xudifsd.org/blog/2016/06/chubby-zookeeper-different-consistency-level/" target="_blank" rel="noopener">chubby &amp; zookeeper: different consistency level</a> </li><li><a href="http://www.cnblogs.com/yangecnu/p/Introduction-CQRS.html" target="_blank" rel="noopener">浅谈命令查询职责分离(CQRS)模式 - yangecnu</a> </li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> distributed-system </tag>
            
            <tag> hbase </tag>
            
            <tag> druid </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>STORM中OOM引发的思考</title>
      <link href="/2019/03/17/a4/"/>
      <url>/2019/03/17/a4/</url>
      
        <content type="html"><![CDATA[<h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>最近一次在实现需求的时候发现 Storm 中的一个 Bolt 出现了 OOM 导致的长时间 GC 问题。最后虽然通过 review 新更新的代码找到了问题，但是深究其中还是有一些别的收获，所以在这里进行记录。</p><p>在 review 新更新的代码之后发现，我将 <code>JedisPool</code> 的实例化写到了 <code>execute</code> 中而不是 <code>prepare</code> 中，所以 Storm 每次执行 <code>execute</code> 的时候都会重新实例化 <code>JedisPool</code> 并且也没有显式的进行 <code>close</code>。</p><p>虽然这个问题只是因为疏忽导致的，但是也让我对两个大问题进行了思考。一个是对于 Storm 中资源冲突的问题应该如何去发现、定位、处理，第二个是 Storm 中 Component 的生命周期。下面会讨论这两个问题。</p><h2 id="Storm中的资源冲突"><a href="#Storm中的资源冲突" class="headerlink" title="Storm中的资源冲突"></a>Storm中的资源冲突</h2><p><img src="/images/a4-1.png" alt="a4-1"></p><p>要解决 Storm 中的资源冲突，那么需要先了解 Storm 中的资源分配。一个集群由一个 nimbus 节点和多个工作节点组成，每个工作节点由一个 <code>Supervisor</code> 管理着多个 <code>Worker process</code>，每个 <code>Worker process</code> 对应着一个 <code>JVM</code>，在其中有多个 <code>Executor thread</code>。每个 <code>Executor thread</code> 中可能存在多个 <code>Task</code>。而 <code>Task</code> 则是一个 bolt 或者 spout 的实例。</p><p>在此基础上，可以把资源竞争从所属结构从小到大划分为：</p><ul><li><code>Worker process</code> 中的内存冲突</li><li><code>Worker process</code> 的冲突</li><li>工作节点上的内存冲突</li><li>工作节点上的 CPU 冲突</li><li>工作节点上的网络 I/O 冲突</li><li>工作节点上的磁盘 I/O 冲突</li></ul><h3 id="Worker-process-中的内存冲突"><a href="#Worker-process-中的内存冲突" class="headerlink" title="Worker process 中的内存冲突"></a>Worker process 中的内存冲突</h3><p>首先这类冲突实际上是 JVM 中的内存占用过多，表现为 <code>out-of-memory</code> 或者进入长时间的垃圾回收，并且这类冲突会在 UI 上暴露出来。而解决办法无非是：</p><ul><li>减少一个 <code>Worker process</code> 中的 <code>Executor thread</code> 个数<ul><li>保证 <code>Executor thread</code> 数量不变的情况下加大 <code>Worker process</code> 数量</li><li>保证 <code>Worker process</code> 数量不变的情况下减少 <code>Executor thread</code> 数量</li></ul></li><li>提高给 JVM 分配的内存：在 <code>storm.yaml</code> 中 <code>worker.childopts</code> 属性是 JVM 相关的参数，可以通过设定 <code>-Xms</code> 和 <code>-Xmx</code> 来进行修改。</li></ul><p>而观察任务的 GC 日志是最直接也是最长用到来解决问题的途径，在 <code>storm.yaml</code> 的 <code>worker.childopts</code> 中可以对 JVM 的 GC 日志进行配置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">worker.childopts: &quot;&quot;-XX +PrintGCTimeStamps  </span><br><span class="line">-XX: +PrintGCDetails</span><br><span class="line">-Xloggc: /opt/storm/worker-%ID%-jvm-gc.log</span><br><span class="line">-XX: +UseGCLogFileRotation</span><br><span class="line">-XX: NumberOfGCLogFiles=5</span><br><span class="line">-XX: GCLogFileSize=1M</span><br><span class="line">-XX: +PrintGCDateStamps</span><br><span class="line">-XX: +PrintGCApplicationStoppedTime</span><br><span class="line">-XX: +PrintGCApplicationConsurrentTime&quot;</span><br></pre></td></tr></table></figure><ul><li><code>-XX +PrintGCTimeStamps</code>: 打印垃圾回收的时间戳</li><li><code>-XX: +PrintGCDetails</code>: 打印额外的 GC 细节</li><li><code>-Xloggc: /opt/storm/worker-%ID%-jvm-gc.log</code>: 为每个工作进程分别创建日志文件</li><li><code>-XX: +UseGCLogFileRotation</code>: 对 GC 日志文件使用日志转储</li><li><code>-XX: NumberOfGCLogFiles=5</code>: 设置日志的分割个数</li><li><code>-XX: GCLogFileSize=1M</code>: 设置日志的分割大小</li><li><code>-XX: +PrintGCDateStamps</code>: 打印垃圾回收的日期和时间信息</li><li><code>-XX: +PrintGCApplicationStoppedTime</code>: 打印应用程序停止时 GC 启动时间（时间在安全点内）</li><li><code>-XX: +PrintGCApplicationConsurrentTime</code>: 打印 GC 执行期间程序启动的时间（时间不在安全点内）</li></ul><h3 id="Worker-process-的冲突"><a href="#Worker-process-的冲突" class="headerlink" title="Worker process 的冲突"></a>Worker process 的冲突</h3><p>这是由于需要的 Worker process 数量超过了集群中的数量，可以通过扩展集群，或者增加每个工作节点的 Worker process 数量来解决。也可以对减少集群里一些任务的 Worker process 占用来解决。</p><p>在 <code>storm.yaml</code> 的 <code>supervisor.slots.ports</code> 配置项可以配置一个工作节点的 Worker process 数量，每一个端口对应一个进程。添加添加、删除端口就能进行控制。</p><h3 id="工作节点上的内存冲突"><a href="#工作节点上的内存冲突" class="headerlink" title="工作节点上的内存冲突"></a>工作节点上的内存冲突</h3><p>因为工作节点的内存需要支撑 <code>Supervisor process</code>， 操作系统，多个 <code>Worker process</code> 和其他的一些进程。如果工作节点在内存上发生了使用冲突，工作节点将开启进程间的内存调度（swapping），会造成有较高的延时发生。可以通过 <code>sar</code> 命令来进行监控：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> sar -S 1 3</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">表示每隔1秒输出3条内存的活动信息，主要需要关注 `kbswpused` 和 `%swpused` 数据。`kbswpused` 是使用中的交换空间内存(KB) ，`%swpused` 是使用中的交换空间内存百分比。如果这两个值大于0则说明系统中存在内存交换。</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>## 工作节点上的 CPU 冲突</span><br><span class="line">和上一个情况类似，也是因为对 CPU 的使用超过了节点所能提供的而造成的。也可以使用 `sar` 命令来进行监控：</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line"><span class="meta">$</span> sar -u 1 3</span><br></pre></td></tr></table></figure><p>主要需要关注 <code>%idle</code>，即在系统没有任何磁盘 I/O 请求空闲CPU时间百分比，如果值偏低。再到 <code>%user</code>，<code>%nice</code>， <code>%system</code> 中去找事应用层面上的问题还是系统层面的问题。</p><h3 id="工作节点上的-I-O-冲突"><a href="#工作节点上的-I-O-冲突" class="headerlink" title="工作节点上的 I/O 冲突"></a>工作节点上的 I/O 冲突</h3><p>同样可以使用 <code>sar</code> 命令来进行监控：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> sar -u 1 3</span><br></pre></td></tr></table></figure><p>只是现在需要关注的值是 <code>%iowait</code>，CPU 时间空闲的百分比，在此期间系统将执行 I/O 请求。如果这个值约为 10.00，那么大概率出现因 I/O 冲突导致的性能问题，如果大于 25.00，一定面临比较严重的 I/O 冲突。</p><p>然后要做的就是定位问题是在网络 I/O 还是磁盘 I/O，可以先通过下面的方法检查网络 I/O。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// 获取进程id</span><br><span class="line"><span class="meta">$</span> ps aux | grep MY_TOPOLOGY_NAME</span><br><span class="line">stormuser 12345 .....</span><br><span class="line"></span><br><span class="line">// 获取端口</span><br><span class="line"><span class="meta">$</span> netstat -antup | grep "12345/"</span><br><span class="line">tcp6       0      0 xx.xx.xx.xx: 12345        xx.xx.xx.xx:42474       ESTABLISHED 4576/java</span><br><span class="line"></span><br><span class="line">// 查看限制</span><br><span class="line"><span class="meta">$</span> cat /proc/12345/limits</span><br><span class="line"></span><br><span class="line">// 查看该端口的稳定的连接tcp连接</span><br><span class="line"><span class="meta">$</span> netstat -na | grep "tcp6" | grep "4576" | grep "ESTABLISHED" | wc -l</span><br></pre></td></tr></table></figure><p>检查 <code>Max open files</code> 一行， soft limit 和 hard limit 的值，如果已经到达设置的极限值，那么就会发生网络 I/O 冲突。然后可以使用 iotop 来观察是否发生了磁盘 I/O。</p><p>主要观察 USER 为 storm 的进程， <code>DISK READ</code> ，<code>DISK WRITE</code>，<code>IO&gt;</code> 即每秒该进程读取的字节数，每秒该进程写入的字节数，每秒 I/O 调用百分比。如果其中一个值较高就说明相关的任务出现了磁盘 I/O 冲突。</p><p><strong>该章节主要参考《Storm应用实践》</strong></p><h2 id="Component-生命周期"><a href="#Component-生命周期" class="headerlink" title="Component 生命周期"></a>Component 生命周期</h2><p>这里可以先参考一下 Nathan on 自己的回答： <a href="https://groups.google.com/forum/#!msg/storm-user/com4JfU9aJ4/zImseAoiH2IJ" target="_blank" rel="noopener">The lifecycle of a bolt or spout</a></p><p>可以看到 <code>prepare</code> 仅仅只会被 worker 在开始的时候执行一次，但是 <code>execute</code> 会在每次有 tuple 进入的时候都被调用。也就是说如果我有一个 Bolt 定义了3个 worker，每个 worker 都有3个 executer。那么总共是有9个 task，也就是说 <code>prepare</code> 会被调用9次，而 <code>execute</code> 就会被无限调用。</p><p>所以我们一些连接和静态变量的初始化工作放到 <code>prepare</code> 中去完成会更加的实惠。但是由于每个 worker 对应一个单独的 JVM 进程，一个 JVM 进程中会有多个 executor 线程，所以就会有多个 task 同时执行 <code>prepare</code> 的操作。<br>那么一些连接的创建是需要线程安全的环境，线程安全的单例写法这里不赘述。</p>]]></content>
      
      
      
        <tags>
            
            <tag> distributed-system </tag>
            
            <tag> storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式轮询系统</title>
      <link href="/2018/11/16/a3/"/>
      <url>/2018/11/16/a3/</url>
      
        <content type="html"><![CDATA[<p>最近需要实现的一个场景是对于社区里的每条动态进行多次的检测和评估，暂且不论检测和评估的具体功能，统称为「计算」。</p><p>而这些计算由其他同事提供现成的接口，但是由于其具体功能的差异这些计算有些依赖了外部接口，并且可能依赖外部的长延时接口，例如视频分析。所以这里从计算的实现上将其划分为「瞬时计算」和「长时计算」，而对于上层使用方来说是需要构造出一种使用协议来同时兼容两种类型。而这样的三层结构中是有两次网络传输过程，更需要一种足够健壮的重试策略。并且在动态流量基数较大，峰值与谷值差异较大的情况下，横向扩容能力也非常的重要。</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>第一次讨论的方案是 「push模型」，多方使用我暴露的接口，在完成数据消费计算之后推送到我的服务中进行下游逻辑。这种方案有几个弊端，第一是多方需要实现消费 Kafka 的逻辑并且需要管理 Kafka offset，保证在事故不会导致数据丢失。第二是网络传输导致的重试逻辑复杂，需要接入第二个重试队列，或者提供重试接口，这样数据流的流向就从单向变为双向，增加了之后的维护和排查成本。但是这种方案还是有一个好处，因为计算方是接触数据的第一层，所以在计算方内部出现错误引起的重试或者报错机制实现其他非常简单。</p><p>在否定以后转换为 「pull模型」，多方暴露接口让我进行统一的调用，仅由我方消费 Kafka 并统一维护状态和提供重试策略。但是在实现细节上还是有两种方案可供选择，一种是以「动态为单位」，一种是以「计算为单位」。动态为单位是说，主线程消费 Kafka，然后交由下游异步或多线程方式调用多个接口，全部成功后算作一个动态计算完成。计算为单位是说，多个线程各自使用独立的 group id 消费 Kafka 并维护重试队列，然后在线程内进行接口调用。两种方式的区别是一个计算失败之后的 block 代价不同，第一种方案会 block 整个动态，第二种方案只会 block 动态的一个计算。并且由于计算之间的效率差，第一种的效率取决于最慢的一个计算，第二种在动态为单位的角度来看，也是以最慢的一个计算决定，但是由于计算之间不会互相影响，所以之后想对「慢计算」进行降级的话能很方便的完成。</p><h2 id="三个问题"><a href="#三个问题" class="headerlink" title="三个问题"></a>三个问题</h2><p>在决定模型以后，需要考虑第一个问题，「构造出一个通用的协议兼容同步计算和异步计算的调用」。一种是同步轮询，一种是异步调用。由于底层依赖的外部长时计算有请求的次数限制，所以同步轮询需要记录请求时间来控制轮询的时间间隔，但是没有性能问题的风险。而对于异步调用，如果下游系统被某些原因 block 住的时候会无限的建立连接，在超过线程池的上限以后会 block 住调用方。所以比较下来还是使用轮询的方式简单实用，只需要维护一个调用队列，每个请求带上「上一次请求的时间戳」和「重试次数」，如果在消费到一个还没有超过调用间隔的请求，不累加重试次数，直接放入队列末尾；如果一个请求失败则直接修改时间戳，累加重试次数放入队列末尾；如果超过了重试次数，直接抛出系统记为一个 bad case。</p><p>在确定轮询的方式以后，第二个重试问题也迎刃而解，仅由顶部调用方来控制请求状态，并且提供重试，这样单向的数据流在后期的问题排查和维护过程中是非常重要的。而第三个问题，横向扩展能力，由于使用了「以计算为单位的pull模型」，扩展新的计算可见是非常方便的，只需要添加独立的线程。并且扩展每个计算调用系统本身也是非常方便的，需要对「分发任务逻辑」和「调用逻辑」进行解耦，扩展时只扩展「调用逻辑」部分，不然的话还需要保证每个线程之间分发任务的队列的一致性，是很冗余的设计。那么整个轮询系统内部也被划分为了两个部分，第一个部分消费 Kafka，维护调用队列，第二个部分消费调用队列进行底层接口调用，并且会反馈调用结果给第一个部分，使其进行调用队列的状态维护。</p><p><img src="/images/a3-1.png" alt="a3-1"></p><p>而上面也提到了单向数据流的好处，所以这里为了规避掉双向数据流，将请求完成后的队列维护工作也放在接口调用部分。所以就变成了「状态维护」部分只管往调用队列里放请求，「接口调用」部分负责调用接口并且使用 response 来维护调用队列里的请求状态，例如请求次数加一之后放入队列末尾。</p><p><img src="/images/a3-2.png" alt="a3-2"></p><h2 id="复用Storm"><a href="#复用Storm" class="headerlink" title="复用Storm"></a>复用Storm</h2><p>上面的结构一看非常像 Storm 的流式结构了，并且 Storm 能保证一条 Kafka message 在轮询系统中一定会被成功消费并且是顺序消费，还能帮我们管理 Kafka offset 状态，还不需要写多线程，扩容起来也非常方便。那么何乐为不为呢？</p><p><img src="/images/a3-3.png" alt="a3-3"></p><p>将设计图一改，瞬间转变成一个 Storm 架构，其实上面单向数据流的设计也规避了 Storm 中不能由下游 Bolt 给上游 Bolt 传递消息的情况。而 Storm 本身也提供重试机制，在该重试机制下我们可以重新考虑之前数据结构的设计。</p><p>因为我们需要考虑的是两类重试情况，一种是通过重试能解决的网络问题，一种是通过重试不能解决的系统问题。而当我们在遇到超过重试次数没有解决的问题时，之前的解决方案是抛出系统持久化到一个地方，之后再想办法解决，但是这样又增添了该系统的复杂程度，需要通过自动化的方案能区分这个 case 到底是网络问题还是系统问题，之后再通过一套方案将它解决掉再写入系统。</p><p>试想最简单的处理方案是遇到网络问题通过重试自然的解决它，而遇到系统问题直接 block 整个系统，等待计算提供方解决问题后再继续。而 Storm 的机制刚好提供了这种方案的解决策略，如果遇到重试的请求都进行无限次的重试，因为短暂的问题肯定是会在有限次重试的过程中恢复，而系统问题是无限次重试都不能解决的，那么遇到很多的系统问题 case 不是会浪费IO，并且也没有 block 整个系统吗？</p><p>其实并不会，Storm 内部设计的时候一次会从 Kafka 中拿出多个 message 形成多个 tuple，只有在这些 tuple 全部 ack 掉以后才会继续向后面拿数据。所以如果在一批数据中出现了一些系统问题的 case，他们通过无限的 fail 重试是会 block 整个 topology 的，并且他们的个数不会很多，所以不会对下游造成 IO 的压力。对 Kafka 的 offset 进行检测接上警报以后，很快消费能力就跟不上生产能力，就能知道出现了这样的系统问题，在下游的服务修好以后，再接着进行消费，也不会丢失数据。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>系统的设计中每一部分一定要简单纯粹，不要想让一个部分做多件事情。</p>]]></content>
      
      
      
        <tags>
            
            <tag> distributed-system </tag>
            
            <tag> storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库的在线迁移[2]</title>
      <link href="/2018/10/16/a2/"/>
      <url>/2018/10/16/a2/</url>
      
        <content type="html"><![CDATA[<h2 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h2><ul><li>Spark version: 2.2.1</li><li>EMR: Amazon EMR<ul><li>Master: m4.xlarge [8vCore, 16GB] * 1</li><li>Task: r4.xlarge[4vCore, 30.5GB] * (0-20)</li><li>Core: r4.xlarge[4vCore, 30.5GB] * (1-15)</li></ul></li><li>Mongo Collection:<ul><li>A: 73.4G</li><li>B: 28.7G</li></ul></li></ul><p><em>Task 和 Core 都是 Auto Scaling, B表与A表是一对多的关系。</em></p><p>操作非常简单，从 Mongo 中分别读取 A , B 表。再将两表 <code>join</code> 后，选取字段，存入一个已经按照 C 字段 shard 的 Mongo 当中。并且 C 字段不是 <code>_id</code>。</p><h2 id="Trap"><a href="#Trap" class="headerlink" title="Trap"></a>Trap</h2><h3 id="Full-Scan"><a href="#Full-Scan" class="headerlink" title="Full Scan"></a>Full Scan</h3><p>在 MongoSpark 中如果使用 schema，并且在 schema 中对一些参数设置了 <code>nullable=false</code> 会出现在 NodeManager 进行 sample partition统计的时候需要使用这个 filter 条件对全表进行 scan，所以如果有些字段没有索引的话，会发现 load 数据的时间特别长。（还好 Dreamsome 踩过这个坑，不然不知道猴年马月能发现。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> count = <span class="keyword">if</span> (matchQuery.isEmpty) &#123;</span><br><span class="line">         results.getNumber(<span class="string">"count"</span>).longValue()</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">         connector.withCollectionDo(readConfig, &#123; coll: <span class="type">MongoCollection</span>[<span class="type">BsonDocument</span>] =&gt; coll.countDocuments(matchQuery) &#125;)</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">val</span> avgObjSizeInBytes = results.get(<span class="string">"avgObjSize"</span>, <span class="keyword">new</span> <span class="type">BsonInt64</span>(<span class="number">0</span>)).asNumber().longValue()</span><br><span class="line">       <span class="keyword">val</span> numDocumentsPerPartition: <span class="type">Int</span> = math.floor(partitionSizeInBytes.toFloat / avgObjSizeInBytes).toInt</span><br><span class="line">       <span class="keyword">val</span> numberOfSamples = math.floor(samplesPerPartition * count / numDocumentsPerPartition.toFloat).toInt</span><br></pre></td></tr></table></figure><p><a href="https://github.com/mongodb/mongo-spark/blob/master/src/main/scala/com/mongodb/spark/rdd/partitioner/MongoSamplePartitioner.scala#L88" target="_blank" rel="noopener">mongo-spark/MongoSamplePartitioner.scala at master · mongodb/mongo-spark · GitHub</a></p><p>源码中可以看到，如果不包含 <code>matchQuery</code> 是没有问题的，如果有的话会使用 <code>matchQuery</code> 进行 count。</p><h3 id="NodeManger-Restart"><a href="#NodeManger-Restart" class="headerlink" title="NodeManger Restart"></a>NodeManger Restart</h3><p>在任务执行中间，偶尔会出现 <code>java.lang.RuntimeException: Executor is not registered</code> 的报错。查看后主要原因是因为 NodeManager 在任务运行中挂掉重启以后，本来在它管理下的 Executor 没有办法重现注册导致的。但是看到 <code>Spark</code> 社区有人报这个bug，并且被标记为在 <code>1.6.0</code> 版本已经 fix 了。黑人问号脸。</p><p><a href="https://issues.apache.org/jira/browse/SPARK-9439" target="_blank" rel="noopener">SPARK-9439 ExternalShuffleService should be robust to NodeManager restarts in yarn - ASF JIRA</a></p><h3 id="Mongo-Spark-Upsert"><a href="#Mongo-Spark-Upsert" class="headerlink" title="Mongo Spark Upsert"></a>Mongo Spark Upsert</h3><p>Mongo 中的 Upsert 操作不是原子操作，所以在两个线程同时 <code>upsert</code> 一个不存在的 <code>_id</code> 时，是可能出现报错的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">To prevent MongoDB from inserting the same document more than once, create a unique index on the name field. With a unique index, if multiple applications issue the same update with upsert: true, exactly one update() would successfully insert a new document.</span><br><span class="line"></span><br><span class="line">The remaining operations would either:</span><br><span class="line"></span><br><span class="line"> 1. update the newly inserted document, or</span><br><span class="line"></span><br><span class="line"> 2. fail when they attempted to insert a duplicate.</span><br><span class="line">   If the operation fails because of a duplicate index key error, applications may retry the operation which will succeed as an update operation.</span><br></pre></td></tr></table></figure><p><a href="https://docs.mongodb.com/manual/reference/method/db.collection.update/#use-unique-indexes" target="_blank" rel="noopener">db.collection.update() — MongoDB Manual</a></p><p>以上是官方文档中的说明，可能出现同时插入时，后一个 <code>upsert</code> 报错的情况。而对于这种情况来说，使用 Mongo spark 是很难处理的，没办法 catch 住后一个异常。先来看看 Mongo spark 的 <code>save</code> 方法。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span></span>[<span class="type">D</span>](dataset: <span class="type">Dataset</span>[<span class="type">D</span>], writeConfig: <span class="type">WriteConfig</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> mongoConnector = <span class="type">MongoConnector</span>(writeConfig.asOptions)</span><br><span class="line">    <span class="keyword">val</span> dataSet = dataset.toDF()</span><br><span class="line">    <span class="keyword">val</span> mapper = rowToDocumentMapper(dataSet.schema)</span><br><span class="line">    <span class="keyword">val</span> documentRdd: <span class="type">RDD</span>[<span class="type">BsonDocument</span>] = dataSet.rdd.map(row =&gt; mapper(row))</span><br><span class="line">    <span class="keyword">val</span> fieldNames = dataset.schema.fieldNames.toList</span><br><span class="line">    <span class="keyword">val</span> queryKeyList = <span class="type">BsonDocument</span>.parse(writeConfig.shardKey.getOrElse(<span class="string">"&#123;_id: 1&#125;"</span>)).keySet().asScala.toList</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (writeConfig.forceInsert || !queryKeyList.forall(fieldNames.contains(_))) &#123;</span><br><span class="line">      <span class="type">MongoSpark</span>.save(documentRdd, writeConfig)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      documentRdd.foreachPartition(iter =&gt; <span class="keyword">if</span> (iter.nonEmpty) &#123;</span><br><span class="line">        mongoConnector.withCollectionDo(writeConfig, &#123; collection: <span class="type">MongoCollection</span>[<span class="type">BsonDocument</span>] =&gt;</span><br><span class="line">          iter.grouped(writeConfig.maxBatchSize).foreach(batch =&gt; &#123;</span><br><span class="line">            <span class="keyword">val</span> updateOptions = <span class="keyword">new</span> <span class="type">UpdateOptions</span>().upsert(<span class="literal">true</span>)</span><br><span class="line">            <span class="keyword">val</span> requests = batch.map(doc =&gt;</span><br><span class="line">              <span class="keyword">if</span> (queryKeyList.forall(doc.containsKey(_))) &#123;</span><br><span class="line">                <span class="keyword">val</span> queryDocument = <span class="keyword">new</span> <span class="type">BsonDocument</span>()</span><br><span class="line">                queryKeyList.foreach(key =&gt; queryDocument.append(key, doc.get(key)))</span><br><span class="line">                <span class="keyword">if</span> (writeConfig.replaceDocument) &#123;</span><br><span class="line">                  <span class="keyword">new</span> <span class="type">ReplaceOneModel</span>[<span class="type">BsonDocument</span>](queryDocument, doc, updateOptions)</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                  queryDocument.keySet().asScala.foreach(doc.remove(_))</span><br><span class="line">                  <span class="keyword">new</span> <span class="type">UpdateOneModel</span>[<span class="type">BsonDocument</span>](queryDocument, <span class="keyword">new</span> <span class="type">BsonDocument</span>(<span class="string">"$set"</span>, doc), updateOptions)</span><br><span class="line">                &#125;</span><br><span class="line">              &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="type">InsertOneModel</span>[<span class="type">BsonDocument</span>](doc)</span><br><span class="line">              &#125;)</span><br><span class="line">            collection.bulkWrite(requests.toList.asJava)</span><br><span class="line">          &#125;)</span><br><span class="line">        &#125;)</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>在集合一些 <code>ReplaceOneModel</code>,  <code>UpdateOneModel</code>,  <code>InsertOneModel</code> 最后调用的是 <code>collection.bulkWrite</code> 方法。对使用者来说是没有办法 catch 其中一条的异常的，所以可能导致整个 task 失败重试。在设计上就应该尽量规避有两个 partition 同时 upsert 一个 <code>_id</code> 对象的情况。</p><h3 id="Mongo-Shard"><a href="#Mongo-Shard" class="headerlink" title="Mongo Shard"></a>Mongo Shard</h3><p>当 mongo 的 shard key 不是 <code>_id</code>，而是其他 filed 的时候，会出现同一个 <code>_id</code> 的多个元素被写入到数据库中。因为 mongo 内部只能保证在一个 shard 中的 collection 强制的唯一性。并且在进行 shard 的时候，会自动对 shard 进行索引，但是不会创建唯一性索引。所以在可能会出现多个同一 <code>_id</code> 的情况下，需要注意。</p><p><a href="https://stackoverflow.com/questions/11241819/duplicate-documents-on-id-in-mongo" target="_blank" rel="noopener">mongodb - Duplicate documents on _id (in mongo) - Stack Overflow</a></p><p>而且经过实验发现，在 Mongo Spark save 的过程当中需要指定 <code>WriteConfig</code> 中的 <code>shardKey</code> ，而且必须包含  <code>{_id: 1}</code> ，不然会报错。比如 <code>shardKey</code> 是 <code>user</code>，需要写成 <code>{_id: 1, user: 1}</code>。这是因为 <code>user</code> 并不是数据库的 <code>unique index</code>，而 <code>_id</code> 在这个 shard 中是 <code>unique index</code> 并且是 <code>immutable</code> 的， 所以如果我用 <code>user</code> 做 query 条件去更新 <code>_id</code> 就会出错。</p><h3 id="Yarn-Resource"><a href="#Yarn-Resource" class="headerlink" title="Yarn Resource"></a>Yarn Resource</h3><p>在分 Executor Container 的时候是一台物理机器一台的分，所以可能出现内存碎片。比如一台16G内存的机器，4.5G一个 Executor Container，那么只能产生3个Executor Container，还剩下 2.5G 的内存不够启一个 Executor Container，所以产生碎片。并且这个碎片是不会在 Yarn UI 中表现出来， 所以会导致在 UI 中出现 <code>total &lt;&gt; used + reserved</code> 的情况。</p><p>并且每个 Executor Container 的内存使用不只是通过 <code>spark.executor.memory</code> 设置的大小，会有多余的内存来作为 Container 的运行使用。</p><h2 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h2><h3 id="Spark-Join-Shuffle"><a href="#Spark-Join-Shuffle" class="headerlink" title="Spark Join Shuffle"></a>Spark Join Shuffle</h3><p>Spark 在进行 <code>join</code> 操作的之前会对 <code>join key</code> 进行 <code>repartition</code>。而 Mongo Spark 在从 Mongo 中读取数据的时候会使用 <code>_id</code> 进行 <code>partition</code>，这样会多做一次较为耗时的工作。可以在 MongoSpark 读取数据的时候直接通过 <code>join key</code> 进行 <code>partition</code>。</p><p>但是 MongoSpark 中没有支持一种 partition 策略，保证一些 <code>join key</code> 对应的 Document 全部分在一个 partition 当中，基本都是按照 partitionSize 结合 <code>join key</code> 来做切分，所以需要自己实现，并且如果数据分布不均匀的话可能导致数据倾斜而造成内存问题。所以需要对自己的数据集有一定认识以后再选取合适的方法。</p><p>下文中有详细的指出各种 partitioner 的策略：<br><a href="https://github.com/mongodb/mongo-spark/blob/master/doc/2-configuring.md" target="_blank" rel="noopener">mongo-spark/2-configuring.md at master · mongodb/mongo-spark · GitHub</a></p><p>并且如果是一个小的集合和另外一个大的集合进行 join 的时候，可以考虑 <code>broadcast join</code> 通过将小的集合广播到其他 Excutor 上的形式来避免 shuffle。</p><h3 id="EMR-Auto-Scaling"><a href="#EMR-Auto-Scaling" class="headerlink" title="EMR Auto Scaling"></a>EMR Auto Scaling</h3><p>EMR 的自动收缩会导致一些并没有完成所有 Task 的机器被回收，导致一些机器重启，而之上的所有 Excuter 执行的任务都需要重新运行。如果需要依赖 cache 的任务还需要重跑上游 Task，在跑大体量的任务的时候，不应该再把这个风险引入。</p><h3 id="Resource-assignment"><a href="#Resource-assignment" class="headerlink" title="Resource assignment"></a>Resource assignment</h3><p><a href="https://www.iteblog.com/archives/1659.html" target="_blank" rel="noopener">Spark性能优化：资源调优篇 – 过往记忆</a><br><a href="https://community.qingcloud.com/topic/314/%E6%B5%85%E8%B0%88spark%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98" target="_blank" rel="noopener">浅谈Spark应用程序的性能调优 | 青云QingCloud 社区</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库的在线迁移[1]</title>
      <link href="/2018/08/19/a1/"/>
      <url>/2018/08/19/a1/</url>
      
        <content type="html"><![CDATA[<h2 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h2><p>在不暂停服务的前提下将一个 <strong>290G</strong> 的 Mongo 数据表中的部分字段迁移到 Postgresql 数据库，保证足够低的差异性。</p><h2 id="Strategy"><a href="#Strategy" class="headerlink" title="Strategy"></a>Strategy</h2><p>一切的工作的基础是 MongoDB oplog 的幂等原则：</p><ul><li>首先启动一个服务将 MongoDB 中实时生产的 oplog 同步到 kafka 中。</li><li>启动 Spark 任务将目标表中的字段批量同步到 Postgresql 中。</li><li>启动 Storm 服务将 kafka 中的 oplog 回放到 Postgresql 中。</li><li>启动 Spark 任务进行一致性的检查。</li></ul><p><img src="/images/a1-1.png" alt="a1-1"></p><p>必须保证第一个过程在第二个过程之前启动，第三个任务在第二个任务完成之后启动。任务流程如图，oplog 被同步到 kafka 的一个 topic 中，这个 topic 被分成了8个 partition，启动了 3个 broker。然后将这个 kafka topic 作为 Storm 任务的 KafkaSpout，并发数为4。下游进行持久化任务的 Bolt 的并发数也为4。</p><h3 id="同步-Oplog"><a href="#同步-Oplog" class="headerlink" title="同步 Oplog"></a>同步 Oplog</h3><p>这一步需要注意的是同一个 <code>_id</code> 的 oplog 的乱序问题，我们在回放 oplog 的时候必须按照发生的时间顺序进行回放，不然会出现丢失数据的情况。所以一定要保证 oplog 是按照生成的顺序放入 kafka 队列中的。在这种情况下肯定是单线程的服务来同步数据更加的合适，就不需要担心由于并发带来的乱序问题。</p><p>第二个可能导致乱序的点是 oplog 在 kafka 中的存储位置，我们为了保证同一个 <code>_id</code> 的对象 oplog 不乱序，那么必须保证它们被存储在同一个 partition 当中。如果存储在不同的 partition 当中的话可能会在 Storm 的不同 Spout Consumer thread 中被处理，那么就有可能会出现创建时间在后面的 oplog 先被回放到 Postgresql 当中。而如何能保证同一个 <code>_id</code> 的对象放入到同一个 kafka partition 当中？只需要将 <code>_id</code> 作为 kafka message 的 key，因为 kafka 的 partition 机制就是如果有 message key 就按照 message key 进行 hash 以后进行分区。参考源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Compute the partition for the given record.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> topic The topic name</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> key The key to partition on (or null if no key)</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> keyBytes serialized key to partition on (or null if no key)</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> value The value to partition on or null</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> valueBytes serialized value to partition on or null</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> cluster The current cluster metadata</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">   List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">   <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">   <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">       <span class="keyword">int</span> nextValue = nextValue(topic);</span><br><span class="line">       List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">       <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">           <span class="keyword">int</span> part = Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">           <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">           <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">       <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">nextValue</span><span class="params">(String topic)</span> </span>&#123;</span><br><span class="line">   AtomicInteger counter = topicCounterMap.get(topic);</span><br><span class="line">   <span class="keyword">if</span> (<span class="keyword">null</span> == counter) &#123;</span><br><span class="line">       counter = <span class="keyword">new</span> AtomicInteger(<span class="keyword">new</span> Random().nextInt());</span><br><span class="line">       AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);</span><br><span class="line">       <span class="keyword">if</span> (currentCounter != <span class="keyword">null</span>) &#123;</span><br><span class="line">           counter = currentCounter;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> counter.getAndIncrement();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果消息的 key 为 null，则先根据 topic 名获取上次计算分区时使用的一个整数并加一。然后判断 topic 的可用分区数是否大于0，如果大于0则使用获取的 <code>nextValue</code> 的值和可用分区数进行取模操作。如果 topic 的可用分区数小于等于0，则用获取的 <code>nextValue</code> 的值和总分区数进行取模操作（随机选择了一个不可用分区）</p><p>如果消息的 key 不为 null，就是根据 hash 算法 <code>murmur2</code> 算出 key 的 hash 值，然后和分区数进行取模运算。</p><h3 id="Storm-回放"><a href="#Storm-回放" class="headerlink" title="Storm 回放"></a>Storm 回放</h3><h4 id="乱序"><a href="#乱序" class="headerlink" title="乱序"></a>乱序</h4><p>现在我们已经保证同 <code>_id</code> 的消息会进入到同一个 Storm Spout thread 当中，现在还需要保证在发送到 Bolt Task 的时候也进入到同一个。这就需要考虑 Storm 的 grouping 策略了，其中只有 <code>FieldGrouping</code> 能满足要求，<code>FieldGrouping</code> 是通过 <code>parentBolt</code>  发出的 stream 当中声明的某一个或者几个 field 来做 grouping，比如 <code>parentBolt</code> 发出的 stream 中有：<code>username</code> 和 <code>password</code> 两个 field，而在声明 <code>FieldGrouping</code> 的时候设置按照 <code>username</code> 这个 field 来做 grouping。那么 <code>username</code> 相同的stream 则一定会进入到同一个 BoltThread 当中。</p><p>但是这次的设计当中只有1个 Bolt，它的父级 Bolt 是一个 Spout。而没有找到合适的api来对一个 Spout 的 stream 声明 field，默认只有一个 <code>bytes</code> field。通过分析发现在 <code>KafkaSpout</code> 类中有一个 public 方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">declarer.declare(<span class="keyword">this</span>._spoutConfig.scheme.getOutputFields();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>是用来声明 <code>Fields</code> 的，通过参看文档，没有携带 <code>streamName</code> 参数的 <code>declare</code> 方法会声明一个 <code>streamName</code> 为 <code>default</code> 的 stream。</p><p>所以我们只要使用自己的 <code>scheme</code> ，并且重载它的 <code>getOutputFields</code> 参数即可完成对这个 Spout 的 stream 声明 field。并且发现 <code>KafkaConfig</code> 类中 stream 是一个 <code>MultiScheme</code> 类型的 public 参数，构造函数里使用 <code>RawMultiScheme</code> 类进行初始化它的值，而该类中的 <code>getOutputFields</code> 方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Fields <span class="title">getOutputFields</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Fields(<span class="keyword">new</span> String[]&#123;<span class="string">"bytes"</span>&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以默认的 <code>Fields</code> 是 <code>bytes</code>。那么只要继承 <code>backtype.storm.spout.Scheme</code> 类重载 <code>getOutputFields</code> 和 <code>deserialize</code> 即可。由于传入 <code>Spout</code> 的要么是 bytes，要么是一个 String，所以如果不重载 <code>deserialize</code> 方法对其进行反序列化，那么设定的 <code>field</code> 也是没有实际意义的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyScheme</span> <span class="keyword">implements</span> <span class="title">Scheme</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Object&gt; <span class="title">deserialize</span><span class="params">(<span class="keyword">byte</span>[] ser)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">           ...</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Fields <span class="title">getOutputFields</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Fields(...);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="网络不稳定性"><a href="#网络不稳定性" class="headerlink" title="网络不稳定性"></a>网络不稳定性</h4><p>上面说了怎么保证 <code>Storm</code> 内部的不乱序问题，而仅凭以上的方法还不足以保证数据的完整性。因为在 <code>Storm</code> 内部传输信息是需要通过网络进行传输，所以数据是有丢失的风险的。而 <code>Storm</code> 本身为了应对这种风险也设立了一种容错机制。具体可以参考: <a href="http://storm.apache.org/releases/1.0.6/Guaranteeing-message-processing.html" target="_blank" rel="noopener">Guaranteeing Message Processing</a></p><p>总得来说就是 <code>Storm</code> 内部通过 <code>SpoutOutputCollector</code> 给每一个从 <code>Spout</code> 发出的 tuple 给定一个 id，如果在设定的 timeout 时间内没有完成这个 tuple 应该完成的所有 task，那么会发出一个 fail 信号让 <code>Storm</code> 通过这个 id 来对这个 tuple 进行重试。而使用者仅需要设定 timeout 时间，并且在 <code>collector.emit</code> 的时候将 tuple 作为第一个参数。</p><h3 id="TIPS"><a href="#TIPS" class="headerlink" title="TIPS"></a>TIPS</h3><ul><li><p>无论是离线的批量导入还是在线的回放，<code>insert</code> 和 <code>update</code> 操作需要使用 <code>upsert</code> 操作代替，不然会出现大量的由于 <code>id</code> 重复或者 <code>id</code> 不存在的报错。比如在表中有一个 <code>id</code> 为 a 的数据，而在第一步中记录了对 a 的 <code>update</code> 操作和 <code>delete</code> 操作，所以在第二步启动的时候这个 a 数据已经不存在了，而在回放的时候直接使用 <code>update</code> 操作回放会报错。</p></li><li><p>由于是对表中的部分数据进行迁移，所以在 <code>Bolt</code> 当中需要对 oplog 进行过滤，只对包含目标 <code>field</code> 的 oplog 进行重放，否则会存在大量的垃圾数据。</p></li><li><p>MongoDB oplog 的 offset 最好进行缓存，做好容错工作。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《Typescript Handbook》阅读笔记</title>
      <link href="/2018/01/31/a8/"/>
      <url>/2018/01/31/a8/</url>
      
        <content type="html"><![CDATA[<h2 id="原始数据类型"><a href="#原始数据类型" class="headerlink" title="原始数据类型"></a>原始数据类型</h2><ul><li><code>boolean</code></li><li><code>number</code></li><li><code>string</code></li><li><code>void</code>: 只能为定义为 <code>void</code> 的变量赋值为 <code>undefined</code> 和 <code>null</code></li><li><code>null</code> / <code>undefined</code>: 是所有类型的子类型</li><li><code>any</code>: 定义为 <code>any</code> 的变量可以被赋值为任意类型的值，可以使用任意方法，任意属性也能被访问</li><li><code>联合类型</code>: 可以使用 <code>string | number</code> 来定义联合属性，当不能确定一个联合属性类型的变量到底是哪一个类型的时候，只能访问此联合类型的所有类型里共有的属性或方法</li></ul><p>定义的时候没有赋值的变量都会被类型推断为 <code>any</code></p><p>使用 <code>type</code> 关键字可以用来创建类型别名和字符串字面量</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Name = <span class="built_in">string</span></span><br><span class="line"><span class="keyword">type</span> NameResolver = <span class="function"><span class="params">()</span> =&gt;</span> <span class="built_in">string</span></span><br><span class="line"><span class="keyword">type</span> NameOrResolver = Name | NameResolver</span><br></pre></td></tr></table></figure><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> EventNames = <span class="string">'click'</span> | <span class="string">'scroll'</span> | <span class="string">'mousemove'</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">handleEvent</span>(<span class="params">ele: Element, event: EventNames</span>) </span>&#123;</span><br><span class="line">    <span class="comment">// do something</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">handleEvent(<span class="built_in">document</span>.getElementById(<span class="string">'hello'</span>), <span class="string">'scroll'</span>)  <span class="comment">// 没问题</span></span><br><span class="line">handleEvent(<span class="built_in">document</span>.getElementById(<span class="string">'world'</span>), <span class="string">'dbclick'</span>) <span class="comment">// 报错，event 不能为 'dbclick'</span></span><br></pre></td></tr></table></figure><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>可选属性</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Person &#123;</span><br><span class="line">    name: <span class="built_in">string</span>,</span><br><span class="line">    age?: <span class="built_in">number</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>任意属性</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Person &#123;</span><br><span class="line">    name: <span class="built_in">string</span>,</span><br><span class="line">    age?: <span class="built_in">number</span>,</span><br><span class="line">    [propName: <span class="built_in">string</span>]: <span class="built_in">any</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一旦定义了任意属性，那么确定属性和可选属性都必须是它的子属性</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Person &#123;</span><br><span class="line">    name: <span class="built_in">string</span>,</span><br><span class="line">    age?: <span class="built_in">number</span>,</span><br><span class="line">    <span class="comment">// error</span></span><br><span class="line">    [propName: <span class="built_in">string</span>]: <span class="built_in">string</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只读属性</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Person &#123;</span><br><span class="line">    readonly id: <span class="built_in">number</span>,</span><br><span class="line">    name: <span class="built_in">string</span>,</span><br><span class="line">    age?: <span class="built_in">number</span>,</span><br><span class="line">    [propName: <span class="built_in">string</span>]: <span class="built_in">any</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只读属性只能在对象初始化的时候赋值，后面再赋值会报错</p><p>接口定义数组</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> MyArray &#123;</span><br><span class="line">    (index: <span class="built_in">number</span>): <span class="built_in">number</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> _myArray: MyArray = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure><p>接口定义函数</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> SearchFunc &#123;</span><br><span class="line">    (source: <span class="built_in">string</span>, subString: <span class="built_in">string</span>): <span class="built_in">boolean</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> mySearch: SearchFunc</span><br><span class="line">mySearch = <span class="function"><span class="keyword">function</span>(<span class="params">source: <span class="built_in">string</span>, subString: <span class="built_in">string</span></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> source.search(subString) !== <span class="number">-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接口定义混合类型</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Counter &#123;</span><br><span class="line">(start: <span class="built_in">number</span>): <span class="built_in">string</span></span><br><span class="line">interval: <span class="built_in">number</span></span><br><span class="line">reset(): <span class="built_in">void</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getCounter</span>(<span class="params"></span>): <span class="title">Counter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> counter = &lt;Counter&gt;<span class="function"><span class="keyword">function</span> (<span class="params">start: <span class="built_in">number</span></span>) </span>&#123; &#125;</span><br><span class="line">    counter.interval = <span class="number">123</span></span><br><span class="line">    counter.reset = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123; &#125;</span><br><span class="line">    <span class="keyword">return</span> counter</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> c = getCounter()</span><br><span class="line">c(<span class="number">10</span>)</span><br><span class="line">c.reset()</span><br><span class="line">c.interval = <span class="number">5.0</span></span><br></pre></td></tr></table></figure><p>这样函数也有了自己的属性</p><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> mySum = <span class="function"><span class="keyword">function</span>(<span class="params">x: <span class="built_in">number</span>, y: <span class="built_in">number</span></span>): <span class="title">number</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> x + y</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> mySum: <span class="function">(<span class="params">x: <span class="built_in">number</span>, y: <span class="built_in">number</span></span>) =&gt;</span> <span class="built_in">number</span> = <span class="function"><span class="keyword">function</span>(<span class="params">x: <span class="built_in">number</span>, y: <span class="built_in">number</span></span>): <span class="title">number</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> x + y</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>mySum</code> 的类型会通过等号右边的函数表达式推断得到，所以上下两个函数表达式等价<br>这里需要区分 <code>es6</code> 里的 <code>=&gt;</code> 和 <code>Typescript</code> 中的 <code>=&gt;</code>, <code>ts</code> 中只是用来做函数的定义。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">buildName</span>(<span class="params">firstName: <span class="built_in">string</span>, lastName: <span class="built_in">string</span> = 'Cat'</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> firstName + <span class="string">' '</span> + lastName</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>TypeScript</code> 会将添加了默认值的参数识别为可选参数，此时就不受 <code>可选参数必须接在必需参数后面</code> 的限制</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">push</span>(<span class="params">array: <span class="built_in">any</span>[], ...items: <span class="built_in">any</span>[]</span>) </span>&#123;</span><br><span class="line">    items.forEach(<span class="function"><span class="keyword">function</span>(<span class="params">item</span>) </span>&#123;</span><br><span class="line">        array.push(item)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> a = []</span><br><span class="line">push(a, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>剩余参数可以用数组来进行定义</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">reverse</span>(<span class="params">x: <span class="built_in">number</span></span>): <span class="title">number</span></span></span><br><span class="line"><span class="function"><span class="function"><span class="keyword">function</span> <span class="title">reverse</span>(<span class="params">x: <span class="built_in">string</span></span>): <span class="title">string</span></span></span></span><br><span class="line"><span class="function"><span class="function"><span class="function"><span class="keyword">function</span> <span class="title">reverse</span>(<span class="params">x: <span class="built_in">number</span> | <span class="built_in">string</span></span>): <span class="title">number</span> | <span class="title">string</span> </span>&#123;</span></span></span><br><span class="line"><span class="function"><span class="function">    <span class="title">if</span> (<span class="params"><span class="keyword">typeof</span> x === '<span class="built_in">number</span>'</span>) </span>&#123;</span></span><br><span class="line"><span class="function">        <span class="title">return</span> <span class="title">Number</span>(<span class="params">x.toString().split(<span class="string">''</span>).reverse().join(<span class="string">''</span>)</span>)</span></span><br><span class="line"><span class="function">    &#125; <span class="title">else</span> <span class="title">if</span> (<span class="params"><span class="keyword">typeof</span> x === '<span class="built_in">string</span>'</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x.split(<span class="string">''</span>).reverse().join(<span class="string">''</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以将精确的函数定义写在前面，多类型的函数实现写在后面来进行函数的重载。<br><strong>其实这就是声明的合并，适用于接口、函数、类，合并的属性的类型必须是唯一的。</strong></p><h2 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h2><p>数组合并了相同类型的对象，而元组合并了不同类型的对象</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> tuple: [<span class="built_in">string</span>, <span class="built_in">number</span>] = [<span class="string">'a'</span>, <span class="number">25</span>]</span><br><span class="line"><span class="keyword">let</span> tuple1: [<span class="built_in">string</span>, <span class="built_in">number</span>] = [<span class="string">'a'</span>, <span class="number">25</span>, <span class="string">'b'</span>]</span><br></pre></td></tr></table></figure><p>类似第二种赋值，是一种越界的赋值，越界的元素会被定义为元组中每个类型的联合类型。所以第三项的类型为 <code>string | number</code></p><h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><p>多数与 <code>C++</code> 类特性相识，这里提一点特殊的</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> Animal &#123;</span><br><span class="line">    name = <span class="string">'Jack'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">constructor</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>ES7</code> 提案中的实例属性在 <code>Typescript</code> 中实现了，可以不在构造函数当中定义变量</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> Animal &#123;</span><br><span class="line">    <span class="keyword">static</span> num = <span class="number">42</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">constructor</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>ES7</code> 提案中的静态属性在这里也是支持的</p><p><strong>需要注意的是，<code>Typescript</code> 编译之后的代码中，并没有限制 <code>private</code> 属性在外部的可访问性</strong></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="keyword">class</span> Animal &#123;</span><br><span class="line">    <span class="keyword">public</span> name</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">constructor</span>(<span class="params">name</span>) &#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> sayHi()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> Cat <span class="keyword">extends</span> Animal &#123;</span><br><span class="line">    <span class="keyword">public</span> sayHi() &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">`Meow, My name is <span class="subst">$&#123;<span class="keyword">this</span>.name&#125;</span>`</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> cat = <span class="keyword">new</span> Cat(<span class="string">'Tom'</span>)</span><br></pre></td></tr></table></figure><p>抽象类与其他面向对象语言也类似，抽象类不能被实例化，抽象方法必须在子类中进行实现</p><h3 id="类与接口"><a href="#类与接口" class="headerlink" title="类与接口"></a>类与接口</h3><p>多个类之间的公用方法可以抽象在接口中，然后在多个类中自己实现。这是在保证类只继承自另一个类的时候，还能有很高的灵活性（一个类可以实现多个接口）。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Alarm &#123;</span><br><span class="line">    alert()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> Door &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> SecurityDoor <span class="keyword">extends</span> Door <span class="keyword">implements</span> Alarm &#123;</span><br><span class="line">    alert() &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">'SecurityDoor alert'</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> Car <span class="keyword">implements</span> Alarm &#123;</span><br><span class="line">    alert() &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">'Car alert'</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然接口也是可以继承接口</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Alarm &#123;</span><br><span class="line">    alert()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> LightableAlarm <span class="keyword">extends</span> Alarm &#123;</span><br><span class="line">    lightOn()</span><br><span class="line">    lightOff()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接口也可以继承类</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> Point &#123;</span><br><span class="line">    x: <span class="built_in">number</span></span><br><span class="line">    y: <span class="built_in">number</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">interface</span> Point3d <span class="keyword">extends</span> Point &#123;</span><br><span class="line">    z: <span class="built_in">number</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> point3d: Point3d = &#123;x: <span class="number">1</span>, y: <span class="number">2</span>, z: <span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure><h2 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h2><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">createArray</span>&lt;<span class="title">T</span>&gt;(<span class="params">length: <span class="built_in">number</span>, value: T</span>): <span class="title">Array</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> result: T[] = [];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">        result[i] = value</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">createArray(<span class="number">3</span>, <span class="string">'x'</span>) <span class="comment">// ['x', 'x', 'x']</span></span><br></pre></td></tr></table></figure><p>在函数名后先申明泛型，然后在函数的申明和实现中进行使用，类似于 <code>C++</code> 的模板函数进行使用。更好用的是利用泛型约束来对参数类型进行更灵活的约束。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">interface</span> Lengthwise &#123;</span><br><span class="line">    length: <span class="built_in">number</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">loggingIdentity</span>&lt;<span class="title">T</span> <span class="title">extends</span> <span class="title">Lengthwise</span>&gt;(<span class="params">arg: T</span>): <span class="title">T</span> </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(arg.length);</span><br><span class="line">    <span class="keyword">return</span> arg;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">loggingIdentity(<span class="number">7</span>) <span class="comment">// Error</span></span><br></pre></td></tr></table></figure><p>这样可以约束传入的参数必须包含 <code>length</code></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">copyFields</span>&lt;<span class="title">T</span> <span class="title">extends</span> <span class="title">U</span>, <span class="title">U</span>&gt;(<span class="params">target: T, source: U</span>): <span class="title">T</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> id <span class="keyword">in</span> source) &#123;</span><br><span class="line">        target[id] = (&lt;T&gt;source)[id];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> target;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> x = &#123; a: <span class="number">1</span>, b: <span class="number">2</span>, c: <span class="number">3</span>, d: <span class="number">4</span> &#125;</span><br><span class="line"></span><br><span class="line">copyFields(x, &#123; b: <span class="number">10</span>, d: <span class="number">20</span> &#125;)</span><br></pre></td></tr></table></figure><p>多个参数也可以互相约束，约束 <code>U</code> 中不会出现 <code>T</code> 中不存在的字段，非常好用。<br>在使用接口来定义一个函数的输入输出类型的时候，也可以使用泛型来定义。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 普通</span></span><br><span class="line"><span class="keyword">interface</span> SearchFunc &#123;</span><br><span class="line">  (source: <span class="built_in">string</span>, subString: <span class="built_in">string</span>): <span class="built_in">boolean</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> mySearch: SearchFunc;</span><br><span class="line">mySearch = <span class="function"><span class="keyword">function</span>(<span class="params">source: <span class="built_in">string</span>, subString: <span class="built_in">string</span></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> source.search(subString) !== <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 泛型</span></span><br><span class="line"><span class="keyword">interface</span> CreateArrayFunc &#123;</span><br><span class="line">    &lt;T&gt;(length: <span class="built_in">number</span>, value: T): <span class="built_in">Array</span>&lt;T&gt;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> createArray: CreateArrayFunc;</span><br><span class="line">createArray = <span class="function"><span class="keyword">function</span>&lt;<span class="title">T</span>&gt;(<span class="params">length: <span class="built_in">number</span>, value: T</span>): <span class="title">Array</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> result: T[] = [];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">        result[i] = value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">createArray(<span class="number">3</span>, <span class="string">'x'</span>); <span class="comment">// ['x', 'x', 'x']</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 泛型参数提前到接口名上</span></span><br><span class="line"><span class="keyword">interface</span> CreateArrayFunc&lt;T&gt; &#123;</span><br><span class="line">    (length: <span class="built_in">number</span>, value: T): <span class="built_in">Array</span>&lt;T&gt;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> createArray: CreateArrayFunc&lt;<span class="built_in">any</span>&gt;;</span><br><span class="line">createArray = <span class="function"><span class="keyword">function</span>&lt;<span class="title">T</span>&gt;(<span class="params">length: <span class="built_in">number</span>, value: T</span>): <span class="title">Array</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> result: T[] = [];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">        result[i] = value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">createArray(<span class="number">3</span>, <span class="string">'x'</span>); <span class="comment">// ['x', 'x', 'x']</span></span><br></pre></td></tr></table></figure><p>同样在泛型也能用于类的定义</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> GenericNumber&lt;T&gt; &#123;</span><br><span class="line">    zeroValue: T;</span><br><span class="line">    add: <span class="function">(<span class="params">x: T, y: T</span>) =&gt;</span> T;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> myGenericNumber = <span class="keyword">new</span> GenericNumber&lt;<span class="built_in">number</span>&gt;();</span><br><span class="line">myGenericNumber.zeroValue = <span class="number">0</span>;</span><br><span class="line">myGenericNumber.add = <span class="function"><span class="keyword">function</span>(<span class="params">x, y</span>) </span>&#123; <span class="keyword">return</span> x + y; &#125;;</span><br></pre></td></tr></table></figure><p><strong>只要泛型的申明提前到接口名，类名上的时候就需要在实例化的时候带上泛型的类型</strong><br>在 <code>Typescript 2.3</code> 以后，可以使用泛型参数的默认类型</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">createArray</span>&lt;<span class="title">T</span> = <span class="title">string</span>&gt;(<span class="params">length: <span class="built_in">number</span>, value: T</span>): <span class="title">Array</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> result: T[] = [];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">        result[i] = value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> typescript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-images compose</title>
      <link href="/2018/01/31/a9/"/>
      <url>/2018/01/31/a9/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇是我学习 <code>docker</code> 多镜像编排的第一篇博客，首先通过一个实际的例子使用 <code>docekr</code> 原生命令来对应用栈进行编排连接，再通过 <code>docker-compose</code> 工具进行自动化编排。并从中介绍一些原生命令的使用以及相关的底层知识。</p></blockquote><h2 id="AUFS-amp-Volume"><a href="#AUFS-amp-Volume" class="headerlink" title="AUFS &amp; Volume"></a>AUFS &amp; Volume</h2><blockquote><p>参考:</p><ul><li><a href="http://dockone.io/article/128" target="_blank" rel="noopener">深入理解Docker Volume（一）</a></li><li><a href="https://coolshell.cn/articles/17061.html" target="_blank" rel="noopener">DOCKER基础技术：AUFS</a></li><li><a href="https://yq.aliyun.com/articles/63517?spm=5176.100239.blogcont63035.17.2894c648X7KfsM" target="_blank" rel="noopener">大白话Docker入门（二）</a></li></ul></blockquote><p><code>Docker</code> 本身的设计理念就与传统虚拟机不同，<code>Docker</code> 更倾向于进行资源的隔离。而对于文件系统，<code>Docker</code> 使用了 <code>AUFS(Advanced union filesystem)</code> 来进行文件的隔离（这里我觉得更准确的说是写保护）。那我们肯定要先从系统的层面了解 <code>AUFS</code> 。</p><p>其实在多个 <code>Linux</code> 系统发行版中都是有 <code>AUFS</code> 对应的实现方式: <code>mount -t aufs **</code>。其初衷是想将一个不想被修改的文件 <code>A</code> 与另一个空闲空间 <code>B</code> 联合，那么所有对 <code>A</code> 进行的修改都会保存在 <code>B</code> 中，不会改坏原来的东西。当然在这个初衷的刺激下就产生了功能更强大一些的 <code>AUFS</code> 命令，可以将多个文件/文件夹 <code>union</code> 到一个文件/文件夹上，并且可以为这多个文件/文件夹设置权限。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> sudo mount -t aufs -o dirs=./a=rw:./b=ro none ./c</span><br></pre></td></tr></table></figure><ul><li><p>该命令就是将 <code>a</code> 文件夹和 <code>b</code> 文件夹 <code>union</code> 到 <code>c</code> 文件夹，<code>a</code> 相对于 <code>c</code> 的权限是读写权限，意思就是 <code>a</code>，<code>c</code> 各自的改变都会在对方身上显现。而 <code>b</code> 只是可读权限，意思就是 <code>b</code> 修改后，<code>c</code> 能够观察到，但是 <code>c</code> 修改 <code>b</code> 下属的文件不会在 <code>b</code> 中有任何作用。</p></li><li><p>当 <code>a</code> ，<code>b</code> 中有同名文件的时候，<code>c</code> 中的该文件依照先后顺序决定，越往前的优先级越高。</p></li><li><p>当多个 <code>rw</code> 的文件被 <code>union</code> 在一起的，当我们创建文件的时候，会被轮流写到各个文件夹中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> sudo mount -t aufs  -o dirs=./1=rw:./2=rw:./3=rw -o create=rr none ./mnt</span><br><span class="line"><span class="meta">$</span> touch ./mnt/a ./mnt/b ./mnt/c</span><br><span class="line"><span class="meta">$</span> tree</span><br><span class="line">.</span><br><span class="line">├── 1</span><br><span class="line">│   └── a</span><br><span class="line">├── 2</span><br><span class="line">│   └── c</span><br><span class="line">└── 3</span><br><span class="line">    └── b</span><br></pre></td></tr></table></figure><p>当然可以设置一些轮询的策略，比如 <code>create=mfs | most-free-space</code> 选一个可用空间最大的分支； <code>create=mfsrr:low</code> 选一个空间大于 <code>low</code> 的 <code>branch</code>。</p></li></ul><p>而这个 <code>Docker</code> 本身的文件策略也有一些不足的地方，就是当你删除 <code>Docker</code> 容器并通过该镜像重启的时候，之前的更改将会丢失。所以为了持久化保存数据并且共享容器间的数据，<code>Docker</code> 提出了 <code>Volume</code> 的概念，它可以绕过默认的 <code>AUFS</code> 而已正常的文件或者目录的形式存在于 <code>host</code> 和 <code>container</code> 当中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker run -it --name debian-test -v ~/Projects/DebianTest/App1:/usr/src/app:rw debian /bin/bash</span><br></pre></td></tr></table></figure><p>该命令就在 <code>image</code> 运行的时候初始化了 <code>Volume</code>，将 <code>host</code> 的 <code>~/Projects/DebianTest</code> 文件夹与 <code>container</code> 的 <code>/usr/src/app</code> 文件夹 <code>union</code> 了起来，权限是 <code>rw</code> 。</p><p>之后可以新开一个 <code>terminal</code> ，检查一下是否成功。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker inspect --format "&#123;&#123; .Volumes &#125;&#125;" debian-test</span><br><span class="line">// docker inspect 命令可以查看镜像和容器的详细信息，默认列出全部信息，可以通过--format参数来指定输出的模板格式，以便输出特定的信息</span><br></pre></td></tr></table></figure><p>但是我发现在我的 <code>Mac</code> 上这个命令会出现一些问题，可以尝试打出全部内容，手动过滤。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker inspect | grep Mount -A 10</span><br><span class="line">// -A 限制输出的行数</span><br><span class="line"></span><br><span class="line">"Mounts": [</span><br><span class="line">            &#123;</span><br><span class="line">                "Type": "bind",</span><br><span class="line">                "Source": "/Users/CoderSong/Projects/DebianTest/App1",</span><br><span class="line">                "Destination": "/usr/src/app",</span><br><span class="line">                "Mode": "",</span><br><span class="line">                "RW": true,</span><br><span class="line">                "Propagation": "rprivate"</span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">"Config": &#123;</span><br></pre></td></tr></table></figure><p>然后我们在 <code>host:/Users/CoderSong/Projects/DebianTest/App1</code> 中创建文件就能在 <code>container</code> 中看见。这里我们指定了 <code>container</code> 中的文件夹路径，但是同样的功能如果是使用 <code>dockerfile</code> 文件实现的话，是不能指定的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FROM debian</span><br><span class="line">VOLUME ~/Projects/Django/App1</span><br></pre></td></tr></table></figure><p>当然更方便的是可以使用别的容器的 <code>Volume</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker run -it --name debian-re-test --volumes-from debian-test /bin/bash</span><br></pre></td></tr></table></figure><p>无论 <code>debian-test</code> 是否在运行，它都能起作用。只要有容器连接 <code>Volume</code>，它就不会被删除。</p><h2 id="Link"><a href="#Link" class="headerlink" title="Link"></a>Link</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker run -it --name redis-test redis /bin/bash</span><br><span class="line"><span class="meta">$</span> docker run -it --name node-test --link redis-test:redis node /bin/bash</span><br></pre></td></tr></table></figure><p>以上的命令，我们先启动了一个 <code>redis</code> 镜像，然后启动了一个 <code>node</code> 镜像，并将它连接到了 <code>redis</code> 镜像。这里 <code>node</code> 容器叫做接收容器，或者父容器；<code>redis</code> 容器叫做子容器或者源容器。一个接收容器可以连接多个源容器，多个源容器可以连接多个接收容器。</p><p><code>--link</code> 指令主要做了三件事情：</p><ul><li>设置接收容器的环境变量</li><li>更新接收容器的 <code>/etc/hosts</code> 文件</li><li>建立 <code>iptables</code> 规则进行通信</li></ul><h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><ul><li><p>每有一个源容器，接收容器就会设置一个名为 <code>&lt;alias&gt;_NAME</code> 环境变量。</p></li><li><p>预先在源容器中设置的部分环境变量同样会设置在接受容器的环境变量中，这些环境变量包括 <code>Dockerfile</code> 中使用 <code>ENV</code> 命令设置的，以及 <code>docker run</code> 命令中使用 <code>-e</code>, <code>--env=[]</code> 参数设置的。</p></li><li><p>接收容器同样会为源容器中暴露的端口设置环境变量。如 <code>redis</code> 容器的IP为 <code>172.17.0.2</code>， 且暴露了8000的 <code>tcp</code> 端口，则在web容器中会看到如下环境变量。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">REDIS_PORT_8080_TCP_ADDR=172.17.0.2</span><br><span class="line">REDIS_PORT_8080_TCP_PORT=8080</span><br><span class="line">REDIS_PORT_8080_PROTO=tcp</span><br><span class="line">REDIS_PORT_8080_TCP=tcp://172.17.0.82:8080</span><br><span class="line">REDIS_PORT=tcp://172.17.0.82:8080</span><br></pre></td></tr></table></figure></li></ul><h3 id="更新容器的-etc-hosts-文件"><a href="#更新容器的-etc-hosts-文件" class="headerlink" title="更新容器的 /etc/hosts 文件"></a>更新容器的 <code>/etc/hosts</code> 文件</h3><p><code>Docker</code> 容器的IP地址是不固定的，容器重启后IP地址可能和之前不同。所以 <code>link</code> 操作会在 <code>/etc/hosts</code> 中添加一项–源容器的IP和别名，以用来解析源容器的IP地址。并且当源容器重启以后，会自动更新接收容器的 <code>/etc/hosts</code> 文件。这样就不用担心IP的变化对连接的影响。</p><p>这个整个过程是在容器启动的时候完成的：</p><ul><li>先找到接收容器（将要启动的容器）的所有源容器，然后将源容器的别名和IP地址添加到接收容器的 <code>/etc/hosts</code> </li><li>更新所有父sandbox的 <code>hosts</code> 文件</li></ul><p>这样当一个容器重启以后，自身的 <code>hosts</code> 文件和以自身为源容器的接受容器的 <code>hosts</code> 文件更新。</p><h3 id="建立-iptabls-规则"><a href="#建立-iptabls-规则" class="headerlink" title="建立 iptabls 规则"></a>建立 <code>iptabls</code> 规则</h3><p><code>Docker</code> 为了安全起见，默认会将 <code>Docker daemon</code> 的 <code>-icc</code> 参数设置为 <code>false</code>，容器间的通信就被禁止了。当 <code>redis</code> 容器想要向外界提供服务时，必定暴露一定的端口，假如暴露了 <code>tcp/5432</code> 端口。这样仅需要 <code>node</code> 容器和 <code>redis</code> 容器的 <code>tcp/5432</code> 端口进行通信就可以了。假如 <code>node</code> IP地址为 <code>172.17.0.2/16</code> ，db容器的IP为 <code>172.17.0.1/16</code>，则需建立如下 <code>iptables</code> 规则。</p>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-A DOCKER -s 172.17.0.2/32 -d 172.17.0.1/32 -i docker0 -o docker0 -p tcp -m tcp --dport 5432 -j ACCEPT</span><br><span class="line">-A DOCKER -s 172.17.0.1/32 -d 172.17.0.2/32 -i docker0 -o docker0 -p tcp -m tcp --sport 5432 -j ACCEPT</span><br></pre></td></tr></table></figure><p>这样就能确保通信的流量不会被丢弃掉。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker inspect --format='&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;' [name]</span><br><span class="line">// 该命令可以查看容器的IP</span><br></pre></td></tr></table></figure><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p><img src="http://oj7mt8loy.bkt.clouddn.com/docker.png" alt="construct-image"></p><p>拉取3个需要的 <code>image</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker pull redis</span><br><span class="line"><span class="meta">$</span> docker pull node</span><br><span class="line"><span class="meta">$</span> docker pull haproxy</span><br></pre></td></tr></table></figure><p>运行6个 <code>container</code> ，注意启动顺序和数据卷的挂载</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker run -it --name redis-master -v ~/Projects/redis/master:/data redis /bin/bash</span><br><span class="line"><span class="meta">$</span> docker run -it --name redis-slave1 --link redis-master:master -v ~/Projects/redis/slave1 redis:/data /bin/bash</span><br><span class="line"><span class="meta">$</span> docker run -it --name redis-slave2 --link redis-master:master -v ~/Projects/redis/slave2 redis:/data /bin/bash</span><br><span class="line"><span class="meta">$</span> docker run -it --name APP1 --link redis-master:db -v ~/Projects/Node/App1:/usr/src/app node /bin/bash</span><br><span class="line"><span class="meta">$</span> docker run -it --name APP2 --link redis-master:db -v ~/Projects/Node/App2:/usr/src/app node /bin/bash</span><br><span class="line"><span class="meta">$</span> docker run -it --name HAProxy --link APP1:APP1 --link APP2:APP2 -p 6301:6301 -v ~/Projects/HAProxy:/tmp haproxy /bin/bash</span><br></pre></td></tr></table></figure><p>检查一下启动状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker ps</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES</span><br><span class="line">4db8c514f5d2        haproxy             "/docker-entrypoin..."   6 seconds ago       Up 5 seconds        0.0.0.0:6301-&gt;6301/tcp   HAProxy</span><br><span class="line">f970b888ef3c        node                "/bin/bash"              9 minutes ago       Up 9 minutes                                 APP2</span><br><span class="line">469506f852a9        node                "/bin/bash"              20 minutes ago      Up 19 minutes                                APP1</span><br><span class="line">e0afd181685a        redis               "docker-entrypoint..."   About an hour ago   Up About an hour    6379/tcp                 redis-slave2</span><br><span class="line">272b43e402cc        redis               "docker-entrypoint..."   About an hour ago   Up About an hour    6379/tcp                 redis-slave1</span><br><span class="line">ea63586ce28c        redis               "docker-entrypoint..."   About an hour ago   Up About an hour    6379/tcp                 redis-master</span><br></pre></td></tr></table></figure><p>现在将 <code>redis</code> 配置复制到 <code>host-dir</code> 中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// redis配置</span><br><span class="line"></span><br><span class="line">daemonize yes</span><br><span class="line">pidfile /var/run/redis.pid</span><br><span class="line">port 6379</span><br><span class="line">timeout 300</span><br><span class="line">loglevel debug</span><br><span class="line">logfile /usr/local/bin/log-redis.log</span><br><span class="line">databases 8</span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line">rdbcompression yes</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line">dir /usr/local/bin/db/</span><br><span class="line">appendonly no</span><br><span class="line">appendfsync everysec</span><br><span class="line"></span><br><span class="line">// slave 节点需要填上这一行配置，master不用</span><br><span class="line">slaveof master 6379</span><br></pre></td></tr></table></figure><p>然后进入 <code>redis container</code> 中修改配置并启动 <code>redis</code>（下面以 <code>redis-master</code> 为例）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 连入正在运行的容器</span><br><span class="line"><span class="meta">$</span> docker attach redis-master</span><br><span class="line"><span class="meta">$</span> cp redis.conf /usr/local/bin/redis.conf</span><br><span class="line">// 新建本地数据库的位置（这是在配置中写的地址）</span><br><span class="line"><span class="meta">$</span> mkdir db</span><br><span class="line">// 用配置文件启动服务</span><br><span class="line"><span class="meta">$</span> redis-server redis.conf</span><br><span class="line">// 用客户端检查一下服务是否启动</span><br><span class="line"><span class="meta">$</span> redis-cli</span><br></pre></td></tr></table></figure><p>接下来测试一下3个 <code>redis</code> 节点是否连通</p><ul><li><p>先到 <code>redis-master</code> 节点放入值</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker attach redis-master</span><br><span class="line"><span class="meta">$</span> redis-cli</span><br><span class="line"><span class="meta">$</span> 127.0.0.1:6379&gt; set master testtest</span><br><span class="line"><span class="meta">$</span> 127.0.0.1:6379&gt; get master</span><br><span class="line"><span class="meta">$</span> 127.0.0.1:6379&gt; testtest</span><br></pre></td></tr></table></figure></li><li><p>分别到两个 <code>slave</code> 节点检查</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker attach redis-slave1</span><br><span class="line"><span class="meta">$</span> redis-cli</span><br><span class="line"><span class="meta">$</span> 127.0.0.1:6379&gt; get master</span><br><span class="line"><span class="meta">$</span> 127.0.0.1:6379&gt; testtest</span><br></pre></td></tr></table></figure></li></ul><p>初始化 <code>App</code> 节点（下面以 <code>App1</code> 为例）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker attach APP1</span><br><span class="line"><span class="meta">$</span> npm i -g koa-generator pm2</span><br><span class="line"><span class="meta">$</span> cd /usr/src/app</span><br><span class="line"><span class="meta">$</span> koa2 APP1</span><br><span class="line"><span class="meta">$</span> cd APP1</span><br><span class="line"><span class="meta">$</span> npm i</span><br><span class="line"><span class="meta">$</span> npm i -s ioredis</span><br></pre></td></tr></table></figure><p>然后用下面的文件覆盖 <code>/router/index.js</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">const router = require('koa-router')()</span><br><span class="line">const redis = require('ioredis')</span><br><span class="line">const redisClient = new redis(6379, 'db')</span><br><span class="line"></span><br><span class="line">router.get('/', async (ctx, next) =&gt; &#123;</span><br><span class="line">  // 利用我们刚放入 redis 里的值</span><br><span class="line">  const result = await redisClient.get('master')</span><br><span class="line">  await ctx.render('index', &#123;</span><br><span class="line">    title: `Hello Koa 2! -- $&#123;result&#125;`</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">router.get('/string', async (ctx, next) =&gt; &#123;</span><br><span class="line">  ctx.body = 'koa2 string'</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">router.get('/json', async (ctx, next) =&gt; &#123;</span><br><span class="line">  ctx.body = &#123;</span><br><span class="line">    title: 'koa2 json'</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">module.exports = router</span><br></pre></td></tr></table></figure><p>最后用 <code>pm2</code> 守护进程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> pm2 start bin/www</span><br><span class="line">// 测试</span><br><span class="line">curl localhost:3000</span><br></pre></td></tr></table></figure><p>在配置 <code>APP2</code> 的时候注意更换一个端口，然后配置 <code>HAProxy</code> 节点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">        log 127.0.0.1 local0</span><br><span class="line">        maxconn 4096</span><br><span class="line">        chroot /usr/local/sbin</span><br><span class="line">        daemon</span><br><span class="line">        nbproc 4</span><br><span class="line">        pidfile /usr/local/sbin/haproxy.pid</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">        log 127.0.0.1  local3</span><br><span class="line">        mode http</span><br><span class="line">        option dontlognull</span><br><span class="line">        option redispatch</span><br><span class="line">        retries 2</span><br><span class="line">        maxconn 2000</span><br><span class="line">        balance roundrobin</span><br><span class="line">        timeout connect 5000ms</span><br><span class="line">        timeout client 50000ms</span><br><span class="line">        timeout server 50000ms</span><br><span class="line">        </span><br><span class="line">listen redis_proxy</span><br><span class="line">        bind 0.0.0.0:6301</span><br><span class="line">        stats enable</span><br><span class="line">        stats uri /haproxy-stats</span><br><span class="line">                server APP1 APP1:3000 check inter 2000 rise 2 fall 5</span><br><span class="line">                server APP2 APP2:4000 check inter 2000 rise 2 fall 5</span><br></pre></td></tr></table></figure><p>然后进入 <code>HAProxy</code> 节点启动服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> docker attach HAProxy</span><br><span class="line"><span class="meta">$</span> cd /tmp</span><br><span class="line"><span class="meta">$</span> cp haproxy.conf /usr/local/sbin/</span><br><span class="line"><span class="meta">$</span> cd /usr/local/sbin/</span><br><span class="line"><span class="meta">$</span> haproxy -f haproxy.conf</span><br></pre></td></tr></table></figure><p>然后就能在本地访问 <code>http://[harpoxy-ip]:6301</code></p>]]></content>
      
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++编译&amp;&amp;运行</title>
      <link href="/2017/11/02/a10/"/>
      <url>/2017/11/02/a10/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文以 <code>UNIX</code> 环境为主，结合一些技术博客和 <code>&lt;&lt;C++ Primer&gt;&gt;</code> 做一些总结和整理。</p><ul><li><a href="http://blog.chinaunix.net/uid-26495963-id-3252608.html" target="_blank" rel="noopener">C/C++程序编译过程</a></li><li><a href="http://www.cnblogs.com/lidabo/archive/2012/04/17/2454568.html" target="_blank" rel="noopener">C++中的头文件和源文件</a></li><li><a href="http://c.biancheng.net/cpp/biancheng/view/134.html" target="_blank" rel="noopener">C++ inline内联函数</a></li></ul></blockquote><h2 id="编译过程"><a href="#编译过程" class="headerlink" title="编译过程"></a>编译过程</h2><h3 id="单文件"><a href="#单文件" class="headerlink" title="单文件"></a>单文件</h3><p>这里的单文件指的是单独的 <code>.cpp/.c</code> 文件，因为 <code>.h</code> 文件只是进行一些变量的声明，是不需要进行编译的。</p><ul><li><p><strong>预处理（预处理器 <code>cpp</code> ）：</strong> 预处理器cpp将对源文件中的宏进行展开</p>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> gcc -E hello.cpp -o hello.i</span><br><span class="line">// or</span><br><span class="line"><span class="meta">$</span> cpp hello.cpp -o hello.i</span><br></pre></td></tr></table></figure></li><li><p><strong>编译（编译器 <code>gcc/g++</code> ）：</strong> gcc将c文件编译成汇编文件，然后编译成机器码。（编译器将 <code>.i</code> 文件编译成汇编文件 <code>.s</code>）。</p>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> gcc -S hello.i</span><br></pre></td></tr></table></figure></li><li><p><strong>汇编（汇编器 <code>as</code> ）：</strong> 汇编器将汇编文件编译成机器码 <strong>（可以通过 <code>nm -a hello.o</code> 查看机器码文件）</strong></p>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> gcc -c hello.s -o hello.o</span><br><span class="line">// or</span><br><span class="line"><span class="meta">$</span> as hello.s -o hello.o</span><br></pre></td></tr></table></figure></li><li><p><strong>链接（连接器 <code>ld</code> ）：</strong> 链接器ld将目标文件和外部符号进行连接，得到一个可执行二进制文件。</p>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> gcc hello.o -o hello</span><br></pre></td></tr></table></figure></li></ul><h3 id="头文件"><a href="#头文件" class="headerlink" title="头文件"></a>头文件</h3><p>我们在第一步当中可以看到，这一步的作用就是把宏进行了展开。那么我们的头文件也是在这里被以宏的方式引入到了 <code>hello.cpp</code> 当中。那么我们下面展开介绍一下 <code>#include</code>与头文件中的一些注意事项。</p><h4 id="include"><a href="#include" class="headerlink" title="#include"></a>#include</h4><p><code>#include</code> 是c语言的宏命令，会在第一步（预处理）中起作用。会将后面那个头文件完完整整的引入到当前的文件当中。<strong>而且仅是做替换，而不会有其他的副作用。</strong></p>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// math.h</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">del</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span></span>;</span><br></pre></td></tr></table></figure>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.cpp</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"math.h"</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> c = add(<span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line">  <span class="keyword">int</span> d = del(<span class="number">3</span>, <span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>经过第一步预处理以后：<br>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># main.i</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">del</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> c = add(<span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line">  <span class="keyword">int</span> d = del(<span class="number">3</span>, <span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>而对于头文件的声明当中 <code>&quot; &quot;</code> 和 <code>&lt; &gt;</code> 是有区别的，如果头文件名在 <code>&lt; &gt;</code> 中，就会被认为是标准头文件。编译器会在预定义的位置查找该头文件，如果是 <code>&quot; &quot;</code> 就认为它是非系统头文件，非系统文件查找通常开始于源文件所在路径。</p><h4 id="头文件保护符"><a href="#头文件保护符" class="headerlink" title="头文件保护符"></a>头文件保护符</h4><p>头文件保护符是为了保证头文件在一个 <code>.cpp</code> 文件当中被多次引用不会出现问题。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// file1.h  </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">file1</span>  </span></span><br><span class="line"><span class="class">&#123;</span>  </span><br><span class="line">&#125;;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// file2.h  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"file1.h"</span>  </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">file2</span>  </span></span><br><span class="line"><span class="class">&#123;</span>  </span><br><span class="line">&#125;;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// file3.h  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"file1.h"</span>  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"file2.h"</span></span></span><br></pre></td></tr></table></figure><p>上面<code>file3.h</code>的代码展开以后就变成了</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// file1.h展开的内容  </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">file1</span>  </span></span><br><span class="line"><span class="class">&#123;</span>  </span><br><span class="line">&#125;;  </span><br><span class="line"></span><br><span class="line"><span class="comment">// file2.h展开的内容  </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">file1</span>  </span></span><br><span class="line"><span class="class">&#123;</span>  </span><br><span class="line">&#125;;  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">file2</span>  </span></span><br><span class="line"><span class="class">&#123;</span>  </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>class file1</code> 被引用了两次，导致编译器报错。这时就可以加上头文件保护符来解决这个问题。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// file1.h  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _FILE1_H_  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _FILE1_H_  </span></span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">file1</span>  </span></span><br><span class="line"><span class="class">&#123;</span>  </span><br><span class="line">&#125;;  </span><br><span class="line">  </span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// !_FILE1_H_</span></span></span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// file2.h  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _FILE2_H_  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _FILE2_H_  </span></span><br><span class="line">  </span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"file1.h"</span>  </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">file2</span>  </span></span><br><span class="line"><span class="class">&#123;</span>  </span><br><span class="line">&#125;;  </span><br><span class="line">  </span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// !_FILE2_H_</span></span></span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// file3.h  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _FILE3_H_  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _FILE3_H_  </span></span><br><span class="line">  </span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"file1.h"</span>  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"file2.h"</span>  </span></span><br><span class="line">  </span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// !_FILE3_H_</span></span></span><br></pre></td></tr></table></figure><p>这时因为 <code>_FILE1_H_</code> 只出现了一次，就不会出现重定义的问题。</p><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><p>头文件中需要区别 <strong>声明</strong> 与 <strong>定义</strong> 两个概念。声明因为不涉及到内存的分配，所以是允许多次出现的，而定义则会进行内存的分配，所以定义只能出现一次。而在头文件中是只允许出现声明和一些特殊的定义的（ 类定义， 值在编译时已知的 <code>const</code> 对象和 <code>inline</code> 函数）</p><ul><li><p>值在编译时就已知的 <code>const</code> 对象：<br>如：<code>const char c = &#39;c&#39;</code> 这个是在编译时就已经确定值的，之后程序不能改变。<br>而 <code>const char *c = &#39;c&#39;</code> 是不可以的，因为指针不是在编译时确定值的。<br>并且全局的 <code>const</code> 对象是没有 <code>extend</code> 的声明的，所以只对当前 <code>.cpp</code> 文件有效。所以将它放在头文件中进行引用后，仅对引用文件有效，而对其他文件不可见。所以不会出现重定义。</p></li><li><p><code>inline</code>：因为在函数的调用执行过程当中，我们需要将实参、局部变量、返回地址以及若干寄存器都压入栈中，然后才能执行函数体中的代码；函数体中的代码执行完毕后还要清理现场，将之前压入栈中的数据都出栈，才能接着执行函数调用位置以后的代码。如果一个运行时间很长的函数，那么这些调用代价也是可以忽略的。不过对于一些简单的函数，这些调用代价是很昂贵的。我们就可以使用 <code>inline</code> 函数，它会像宏定义一样进行代码的替换，而不进行调用过程。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> *a, <span class="keyword">int</span> *b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> temp;</span><br><span class="line">    temp = *a;</span><br><span class="line">    *a = *b;</span><br><span class="line">    *b = temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> m, n;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;m&gt;&gt;n;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;m&lt;&lt;<span class="string">", "</span>&lt;&lt;n&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    swap(&amp;m, &amp;n);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;m&lt;&lt;<span class="string">", "</span>&lt;&lt;n&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在编译器遇到函数调用 <code>swap(&amp;m, &amp;n)</code> 的时候就会进行替换，并用实参代替形参。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> temp;</span><br><span class="line">temp = *(&amp;m);</span><br><span class="line">*(&amp;m) = *(&amp;n);</span><br><span class="line">*(&amp;n) = temp;</span><br></pre></td></tr></table></figure></li></ul><ul><li><code>class</code>：对于类的定义成员函数是可以写在定义体内的，这样的话编译器会默认这个函数是 <code>inline</code> 的，也可以声明在定义体内然后在外面进行实现。</li></ul><h3 id="多文件"><a href="#多文件" class="headerlink" title="多文件"></a>多文件</h3><p>多文件互相依赖的情况，只需要先单独将各文件编译成 <code>.o</code> 文件，然后 <code>link</code> 一下就行了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Circle.h</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> CIRCLE_H  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CIRCLE_H  </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Circle</span>  </span></span><br><span class="line"><span class="class">&#123;</span>  </span><br><span class="line">  </span><br><span class="line">&#125;;  </span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// Circle.cpp</span><br><span class="line">#include &quot;Circle.h&quot;  </span><br><span class="line">  </span><br><span class="line">#include &lt;iostream&gt;  </span><br><span class="line">using namespace std;  </span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.cpp</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"Circle.h"</span>  </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;  </span></span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">   ... </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>进行编译：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ g++ -c Circle.cpp -o Circle.o</span><br><span class="line">$ g++ -c main.cpp -o main.o</span><br><span class="line">$ g++ main.o Circle.o -o main</span><br></pre></td></tr></table></figure><p>如果有修改，每次只需要对增量文件进行编译就行了。如果项目比较大，可以使用 <code>makefile</code> 文件来进行自动化编译。<strong>（后面会有文章继续介绍 <code>makefile</code> 和其他的自动化编译）</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redux数据流</title>
      <link href="/2017/10/24/a12/"/>
      <url>/2017/10/24/a12/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文参考阮一峰老师的文章，着重从数据流的角度分析 <code>redux</code></p><ul><li><a href="http://www.ruanyifeng.com/blog/2016/09/redux_tutorial_part_one_basic_usages.html" target="_blank" rel="noopener">Redux 入门教程（一）：基本用法</a></li><li><a href="http://www.ruanyifeng.com/blog/2016/09/redux_tutorial_part_two_async_operations.html" target="_blank" rel="noopener">Redux 入门教程（二）：中间件与异步操作</a></li><li><a href="http://www.ruanyifeng.com/blog/2016/09/redux_tutorial_part_three_react-redux.html" target="_blank" rel="noopener">Redux 入门教程（三）：React-Redux 的用法</a></li></ul></blockquote><p><img src="http://oj7mt8loy.bkt.clouddn.com/redux.png" alt="redux"></p><h2 id="同步数据流"><a href="#同步数据流" class="headerlink" title="同步数据流"></a>同步数据流</h2><p>参照图例，这是一次用户行为的数据流图。</p><ul><li><p><strong>(1)</strong> 用户操作 <code>View</code>。</p></li><li><p><strong>(2)(3)</strong> <code>View</code> 通过 <code>Action Creator</code> 发出相应的 <code>Action</code>。</p><ul><li><code>Action Creator</code> 就是一个 <code>Action</code> 工厂，统一管理所有的 <code>Action</code>。让代码更好管理，互用性更强。</li></ul></li><li><p><strong>(4)</strong> <code>Store</code> 通过 <code>dispatch</code> 函数获取相应的 <code>Action</code>，并且触发 <code>Reduer</code> 计算新的 <code>State</code>。</p><ul><li><p><code>dispatch</code> 之所以可以自动触发 <code>Reducer</code>，是因为在生成 <code>Store</code> 的时候就已经绑定好了。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; createStore &#125; <span class="keyword">from</span> <span class="string">'redux'</span>;</span><br><span class="line"><span class="keyword">const</span> store = createStore(reducer);</span><br></pre></td></tr></table></figure></li><li><p><strong><code>dispatch</code> 的接口只接收对象。</strong></p></li></ul></li><li><p><strong>(5)</strong> <code>Reduer</code> 接收现在的 <code>State</code>，以及 <code>Action</code>。做出相应的状态变化计算，得到新的 <code>State</code>。并且通过 <code>Store</code> 的 <code>subscibe</code> 监听 <code>State</code> 的变化，并回调对应的 <code>Listener</code> 函数。</p><ul><li><code>Reducer</code> 是状态机的核心，定义了状态转移的计算方法。 <strong>也正是因为这些 <code>Action</code> 是我们手动绑定并进行处理，保证了数据流的单向性。</strong></li><li>当然对于比较繁琐的 <code>Reducer</code> 的设计也有更好的设计模式，比如提供了 <code>combineReducers</code> 函数，详细用法可见阮一峰老师的文档。</li><li>对应的 <code>Listener</code> 函数也是在申明的时候已经做好了绑定。  <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; createStore &#125; <span class="keyword">from</span> <span class="string">'redux'</span>;</span><br><span class="line"><span class="keyword">const</span> store = createStore(reducer);</span><br><span class="line"></span><br><span class="line">store.subscribe(listener);</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>(6)</strong> 在 <code>Listener</code> 中获取现在的 <code>State</code> 并用它重新渲染 <code>View</code>。</p><ul><li>可以通过 <code>store.getState()</code> 获取现在的 <code>State</code>。<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">listerner</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> newState = store.getState();</span><br><span class="line">  component.setState(newState);   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="异步数据流"><a href="#异步数据流" class="headerlink" title="异步数据流"></a>异步数据流</h2><p>由于 <code>Redux</code> 中 <code>store.dispatch</code> 的接口要求很严格，只能传递对象类型的 <code>Action</code>，所以这里我们需要先引入中间件来完成我们理想的设计。</p><h3 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h3><ul><li><strong>(4)</strong> 在原第4步过程的基础上，我们引入中间件。 <code>Action</code> 会先被中间件逐步拦截处理以后传递给 <code>Reducer</code>。并且多个中间件是支持通过 <code>applyMiddlewares()</code> 函数来连接在一起。</li></ul><h3 id="异步实现"><a href="#异步实现" class="headerlink" title="异步实现"></a>异步实现</h3><ul><li><p><strong>(3)</strong> 异步数据流首先对传统的仅发送对象的 <code>Action</code> 做了修改，这里发送函数类型的 <code>Action</code>，在这个返回函数当中先发送了一个异步开始的对象 <code>Action</code> ，在结束的时候再发送异步成功/失败的对象 <code>Action</code>。</p><blockquote><p>这里是我纠结比较久的地方，最开始我很不能接受这种将IO操作放在 <code>Action</code> 里的设计，因为我觉得像这样的数据处理相关的操作是应该放在 <code>Reducer</code> 里的。后来我和室友讨论了以后，有了一些新的想法：</p><ul><li>首先异步操作是应该被放在网络层（或者叫IO层），而 <code>Reducer</code> 是担任数据计算的任务，所以把异步操作放在 <code>Reducer</code> 里也是一种不适当的分层。</li><li>然后因为 <code>Creator</code> 的任务本来就很轻松，只用生成一些 <code>Action</code> 对象，所以这边把网络层放入其中也比较合适。</li><li>最后这种设计其实也没有和最初的思想违背，<code>Creator</code> 还是只是生成一些 <code>Action</code>，而并没有执行这些 <code>Action</code>。</li></ul><p><strong>以上只是个人看法，欢迎拍砖讨论。</strong></p></blockquote></li><li><p>至于实现的方案就有很多了，比如阮一峰老师文章里的 <code>redux-thunk</code> 和 <code>redux-promise</code>，还有现在比较流行的基于 <code>Generator</code> 的 <code>redux-sage</code>。这里就不一一赘述。</p></li></ul><h2 id="React-Reduce"><a href="#React-Reduce" class="headerlink" title="React-Reduce"></a>React-Reduce</h2><p>当直接使用 <code>React-Reduce</code> 的时候，需要按照规定的范式将组件拆分为 <code>UI组件</code> 和 <code>容器组件</code>。详细可见阮一峰老师的文档，这里主要介绍使用了 <code>React-Reduce</code> 以后对于我们的数据流有哪些影响。</p><ul><li><p><strong>(1)(2)</strong> 通过 <code>mapDispatchToProps</code> 函数，可以设置哪些用户的操作会被当做 <code>Action</code>，并且当做哪个 <code>Action</code> 传递给 <code>Store</code>，也就是我们不需要在第一步中 Hard code 一些动作到 <code>Action</code> 的代码。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> mapDispatchToProps = (</span><br><span class="line">  dispatch,</span><br><span class="line">  ownProps</span><br><span class="line">) =&gt; &#123;</span><br><span class="line">  <span class="keyword">return</span> &#123;</span><br><span class="line">    onClick: <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">      dispatch(&#123;</span><br><span class="line">        type: <span class="string">'SET_VISIBILITY_FILTER'</span>,</span><br><span class="line">        filter: ownProps.filter</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>(6)</strong> 通过 <code>mapStateToProps</code> 函数，可以进行 <code>State</code> 到 <code>UI组件</code> 的 <code>prop</code> 的映射。并对 <code>View</code> 进行重新渲染，也就是说我们不需要在第6步当中再写一些获取现在 <code>State</code> 做渲染的工作。<strong>（非常适合做一些过滤、分析、或者担任数据的组织层）</strong></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> mapStateToProps = <span class="function">(<span class="params">state</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> &#123;</span><br><span class="line">    todos: getVisibleTodos(state.todos, state.visibilityFilter)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul>  <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 根据是否完成进行过滤</span></span><br><span class="line"><span class="keyword">const</span> getVisibleTodos = <span class="function">(<span class="params">todos, filter</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">switch</span> (filter) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">'SHOW_ALL'</span>:</span><br><span class="line">      <span class="keyword">return</span> todos</span><br><span class="line">    <span class="keyword">case</span> <span class="string">'SHOW_COMPLETED'</span>:</span><br><span class="line">      <span class="keyword">return</span> todos.filter(<span class="function"><span class="params">t</span> =&gt;</span> t.completed)</span><br><span class="line">    <span class="keyword">case</span> <span class="string">'SHOW_ACTIVE'</span>:</span><br><span class="line">      <span class="keyword">return</span> todos.filter(<span class="function"><span class="params">t</span> =&gt;</span> !t.completed)</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="built_in">Error</span>(<span class="string">'Unknown filter: '</span> + filter)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> front-end </tag>
            
            <tag> react </tag>
            
            <tag> redux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一次多进程优化实践</title>
      <link href="/2017/09/14/a11/"/>
      <url>/2017/09/14/a11/</url>
      
        <content type="html"><![CDATA[<p>我们先从最近手里的一个项目说起，其实这个项目的需求很简单：<strong>从多数据源抓取数据，进行数据整合以后分别存入到不同的数据库中。当然不同数据库存储的数据结构是不一样的，但是也只是对数据源 attribute 的重新过滤组合而已。</strong></p><p>当每一份数据的体量以及整个数据的体量变得很大的时候，系统的实时性大大降低（因为在数据库的另一端是有客户端等着将数据进行可视化展示的），这个时候我就不得不好好审视一下我的代码结构了。早先在设计的时候，因为没有考虑到数据这么大的体量，并且为了增强日志文件的可读性和一些客观限制，我没有选择大量的异步并发。</p><blockquote><p>为了后面描述比较方便，我先罗列一下这些客观限制： </p></blockquote><blockquote><ul><li><code>Azure Cosmos DB</code> 是对并发数量有限制的，大概在 <code>20次/s</code> 的时候会发出警告。</li><li><code>Azure Cosmos DB</code> 是对 <code>Stored Procedure</code> 的 <code>request body</code> 以及 <code>response body</code> 有限制的。</li><li><code>Node</code> 的异步数量是存在限制的，数据库连接数也是存在限制的。</li></ul></blockquote><h2 id="初步模型"><a href="#初步模型" class="headerlink" title="初步模型"></a>初步模型</h2><p>单进程单线程同步跑任务，这个速度肯定是我们接受不了的。那我们开始优化我们的架构。对于这种多数据源多任务的场景，<strong>生产者消费者</strong> 的行为模式作为基础应该是最合适不过了。这样我们就可以把业务逻辑完全解耦为：</p><ul><li>生产者从数据源抓数据整理为 <strong>数据单元</strong> 放到缓存队列。</li><li>消费者从缓存队列拿出 <strong>数据单元</strong> 进行处理。</li></ul><p>解耦完成后，我们对这两部分一一的审视。这样单一性的任务我们能很好的进行多线程、多进程的处理，这里我选择在生产者的 <strong>单一数据源</strong> ，消费者的 <strong>文件－数据库（一个数据源会产生多个文件，每份文件要存储到多个数据库，这里的意思是一个文件存储到一个数据库）</strong> 粒度上选择多进程处理。</p><ul><li>生产者</li></ul><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> cluster = <span class="built_in">require</span>(<span class="string">'cluster'</span>);</span><br><span class="line"><span class="keyword">const</span> cpuNum = <span class="built_in">require</span>(<span class="string">'os'</span>).cpus().length;</span><br><span class="line"><span class="keyword">const</span> redis = <span class="built_in">require</span>(<span class="string">'redis'</span>);</span><br><span class="line"><span class="keyword">const</span> sourceList = [...];</span><br><span class="line"><span class="keyword">const</span> sourceIndex = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cluster.isMaster) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; cpuNum; i++) &#123;</span><br><span class="line">        cluster.fork();</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (sourceIndex &lt; sourceList.length) &#123;</span><br><span class="line">        <span class="comment">// 选择数据源</span></span><br><span class="line">        <span class="keyword">let</span> source = sourceList[++sourceIndex];</span><br><span class="line">        <span class="comment">// 抓数据并过滤成对象，存入redis</span></span><br><span class="line">        <span class="keyword">let</span> dataObj = catchAndParser(source);</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>消费者</li></ul><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> cluster = <span class="built_in">require</span>(<span class="string">'cluster'</span>);</span><br><span class="line"><span class="keyword">const</span> cpuNum = <span class="built_in">require</span>(<span class="string">'os'</span>).cpus().length;</span><br><span class="line"><span class="keyword">const</span> redis = <span class="built_in">require</span>(<span class="string">'redis'</span>);</span><br><span class="line"><span class="keyword">const</span> worker = <span class="built_in">require</span>(<span class="string">'./worker'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> workers = &#123;</span><br><span class="line">    mssql: worker.mssql,</span><br><span class="line">    documentdb: worker.documentdb,</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cluster.isMaster) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; cpuNum; i++) &#123;</span><br><span class="line">        cluster.fork();</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 从redis里取任务</span></span><br><span class="line">    <span class="keyword">let</span> task = getTaskFromRedis();</span><br><span class="line">    <span class="comment">// 进行数据重组以及存储</span></span><br><span class="line">    worker[task.type](task);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样我们会发现我们起的进程数达到 <code>CUP</code> 的两倍了，其实这边可以自己根据任务是否会吃满 <code>CUP</code> ，会吃多少，并结合进程切换的时间以及内存问题来调整进程数量。到现在我们完成了我们的初步模型，但是有一个很麻烦的问题暴露在了我们面前，我们现在的逻辑没有去维护连接池，也就是说我们会在 <code>Worker</code> 进程中让它自己去进行连接，完成任务再断开连接。这样显然也是我们不希望去看到的。</p><h2 id="连接池"><a href="#连接池" class="headerlink" title="连接池"></a>连接池</h2><p>最初我有两种设想：</p><ul><li>在主进程建立连接池，然后所有 <code>Worker</code> 需要连接的时候就去这个地方取来用。</li><li>在每一个进程当中去维护自己的连接池。</li></ul><p>思来想去，咨询前辈后发现第一种想法有点太傻了。先不说父子进程间监听 <code>socket</code> 的问题，光是子进程对取回来的连接进行复用这一点上也是对性能的浪费。所以当然是每个进程维护自己的连接池比较好，这样不论是多线程还是异步的情况下，都能不让连接成为性能的瓶颈。</p><p>在实现上，我们需要放在全局声明连接池，这样因为子进程是 <code>fork</code> 出去的，也会在自己的进程当中声明连接池。完成了我们每个进程一个连接池的目的。</p><p>参考：<a href="https://stackoverflow.com/questions/24339179/nodejs-cluster-with-mysql-connections" target="_blank" rel="noopener">Nodejs Cluster with MySQL connections</a></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> cluster = <span class="built_in">require</span>(<span class="string">'cluster'</span>);</span><br><span class="line"><span class="keyword">var</span> http = <span class="built_in">require</span>(<span class="string">'http'</span>);</span><br><span class="line"><span class="keyword">var</span> numCPUs = <span class="built_in">require</span>(<span class="string">'os'</span>).cpus().length;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> mysql = <span class="built_in">require</span>(<span class="string">'mysql'</span>);</span><br><span class="line"><span class="keyword">var</span> pool  = mysql.createPool(&#123;</span><br><span class="line">   connectionLimit : <span class="number">10</span>,</span><br><span class="line">   host            : <span class="string">'example.org'</span>,</span><br><span class="line">   user            : <span class="string">'bob'</span>,</span><br><span class="line">   password        : <span class="string">'secret'</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cluster.isMaster) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="数据库层面"><a href="#数据库层面" class="headerlink" title="数据库层面"></a>数据库层面</h2><p>其实我们在数据库层面的操作也比较简单：</p><ul><li>根据某个字段获取数据库里的内容（避免设计子增主键的部分重复存储）</li><li>批量存储</li></ul><h3 id="批量存储"><a href="#批量存储" class="headerlink" title="批量存储"></a>批量存储</h3><p>可以看到性能瓶颈的地方就在第二点，这里不同的数据库就会有不同的支持。对于 <code>Documentdb</code>，可以将批量数据封装成数组全部丢给 <code>Stored procedure</code> ，但其实 <code>Stored procedure</code> 中也是一个一个数据存入数据库中。（这里与数据库是多线程还是单线程有关，后面会去研究一下 <code>Documentdb</code> 的底层再来补坑）。对于前面提到的客观条件1、2，其实是可以把数据包分包再异步，如果并发数量超过限制再使用队列管理异步。<strong>参考：<a href="https://docs.microsoft.com/en-us/azure/cosmos-db/programming" target="_blank" rel="noopener">Azure Cosmos DB server-side programming: Stored procedures</a></strong></p><p>而对于 <code>Sql server</code>，就可以选择用 <code>bulk</code> 还是 <code>insert</code> 的 <code>sql</code> 语句中 <code>OPENROWSET(BULK...)</code> 选项都是可行的，但是从代码组织来看用 <code>bulk</code> 是更好的选择。 <strong>参考：<a href="https://docs.microsoft.com/zh-cn/sql/relational-databases/import-export/import-bulk-data-by-using-bulk-insert-or-openrowset-bulk-sql-server" target="_blank" rel="noopener">使用 BULK INSERT 或 OPENROWSET(BULK…) 导入批量数据</a></strong></p><h3 id="批量查找"><a href="#批量查找" class="headerlink" title="批量查找"></a>批量查找</h3><p>数量较少时，我觉得放在服务器端异步并发比较好。数量比较多时就把任务交给服务器端的 <code>Stored procedure</code> 处理。比较麻烦的是， <code>Sql server</code> 的 <strong>SP</strong> 是不接受数组的，可以通过字符串操作分隔符来模拟数组。<strong>参考：<a href="http://www.cnblogs.com/HeroTan/p/4817288.html" target="_blank" rel="noopener">sql server 模拟数组</a></strong></p><hr><p><strong>2017年9月21日更新</strong></p><blockquote><p>上一次的文章当中有一些地方有错误的地方和一些需要完善的地方，这边进行指出并更新。</p></blockquote><h2 id="错误"><a href="#错误" class="headerlink" title="错误"></a>错误</h2><p>生产者的伪代码中直接使用了数组来分发数据源的方法是完全错误的，其实每个进程都会拷贝一份代码去执行，这种方法需要让每个进程中去共享 <code>sourceIndex</code> 才能够实现。而我们这边的子进程是通过父进程 <code>fork</code> 所得，所以需要在父进程来维护 <code>sourceIndex</code>，分发给子进程。或者也直接使用消息队列来实现这一部分的功能。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> cluster = <span class="built_in">require</span>(<span class="string">'cluster'</span>);</span><br><span class="line"><span class="keyword">const</span> cpuNum = <span class="built_in">require</span>(<span class="string">'os'</span>).cpus().length;</span><br><span class="line"><span class="keyword">const</span> redis = <span class="built_in">require</span>(<span class="string">'redis'</span>);</span><br><span class="line"><span class="keyword">const</span> sourceList = [...];</span><br><span class="line"><span class="keyword">const</span> sourceIndex = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cluster.isMaster) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; cpuNum; i++) &#123;</span><br><span class="line">        <span class="keyword">let</span> worker = cluster.fork();</span><br><span class="line">        worker.send(sourceList[sourceIndex]);</span><br><span class="line">        sourceindex++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    process.on(<span class="string">'message'</span>, <span class="function">(<span class="params">source</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> dataObj = catchAndParser(source);</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="完善"><a href="#完善" class="headerlink" title="完善"></a>完善</h2><p><code>rsmq</code> 是一个基于 <code>redis</code> 封装好的消息队列的库，使用起来也比较方便。唯一不太好的地方是没有封装 <strong>循环队列</strong> ，这使得场景下处理起来比较麻烦。比如我现在的任务是循环不变的，做完了又重头做。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> cluster = <span class="built_in">require</span>(<span class="string">'cluster'</span>);</span><br><span class="line"><span class="keyword">const</span> cpuNum = <span class="built_in">require</span>(<span class="string">'os'</span>).cpus().length;</span><br><span class="line"><span class="keyword">const</span> rsmq = <span class="built_in">require</span>(<span class="string">'rsmq'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> worker = <span class="keyword">async</span> (worker, process) =&gt; &#123;</span><br><span class="line">    <span class="comment">// 封装好的promise对象</span></span><br><span class="line">    <span class="keyword">let</span> task = <span class="keyword">await</span> rsmq.receiveMessage(<span class="string">'qName'</span>);</span><br><span class="line">    <span class="keyword">if</span> (!task) &#123;</span><br><span class="line">        worker.send(<span class="string">'finished'</span>);</span><br><span class="line">        process.kill();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 执行任务</span></span><br><span class="line">        ...</span><br><span class="line">        process.kill();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cluster.isMaster) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; cpuNum; i++) &#123;</span><br><span class="line">        cluster.fork();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cluster.on(<span class="string">'exit'</span>, <span class="function">(<span class="params">worker, code, signal</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">'Worker '</span> + worker.process.pid + <span class="string">' died with code: '</span> + code + <span class="string">', and signal: '</span> + signal);</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">'Starting a new worker'</span>);</span><br><span class="line">        <span class="comment">// 退出后重启进程</span></span><br><span class="line">        cluster.fork();</span><br><span class="line">    &#125;);</span><br><span class="line">    </span><br><span class="line">    cluster.on(<span class="string">'message'</span>, <span class="function">(<span class="params">msg</span>) =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (msg === <span class="string">'finished'</span>) &#123;</span><br><span class="line">            <span class="comment">// 关闭退出重启cluster.removeAllListener('exit');</span></span><br><span class="line">            <span class="comment">// 重新填充数据源</span></span><br><span class="line">            ...</span><br><span class="line">            <span class="comment">// 重新启动所有进程</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; cpuNum; i++) &#123;</span><br><span class="line">                cluster.fork();</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            cluster.on(<span class="string">'exit'</span>, <span class="function">(<span class="params">worker, code, signal</span>) =&gt;</span> &#123;</span><br><span class="line">                <span class="built_in">console</span>.log(<span class="string">'Worker '</span> + worker.process.pid + <span class="string">' died with code: '</span> + code + <span class="string">', and signal: '</span> + signal);</span><br><span class="line">                <span class="built_in">console</span>.log(<span class="string">'Starting a new worker'</span>);</span><br><span class="line">                <span class="comment">// 退出后重启进程</span></span><br><span class="line">                cluster.fork();</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    &#125;)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    worker(cluster.worker, process);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>当然这种实现只是一个思路，而且不是特别好，因为每次做完任务之后都需要重启一个 <code>worker</code> 进程，可以长期保持几个固定的进程，主进程通过通信来分发任务。不用浪费资源去重启进程。</strong></p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><ul><li>在一个场景下，我希望使用前台的开关来控制我后台的进程。这种时候因为 <code>fork</code> 进程的句柄在打开开关的那个进程中，我无法在后面关闭的进程当中获取。所以其实可以在启动进程的时候，将进程号发送到消息队列中，关闭时进行关闭。（我这里描述的场景是一个开关同时控制多个任务，如果一个开关控制一个还是直接以任务名做 <code>key</code>， 进程号作为 <code>value</code> 存入 <code>redis</code> 中比较好）</li><li>通过 <code>fork</code> 出来的子进程，<code>stdin</code>, <code>stdout</code>, <code>stderr</code> 三个流都会复制父进程，如果需要重定向，需要在 <code>fork</code> 时进行配置。</li></ul><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> cp = <span class="built_in">require</span>(<span class="string">'child_process'</span>);</span><br><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">'fs'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> main = <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">let</span> worker = cp.fork(<span class="string">'./test.js'</span>, &#123; silent: <span class="literal">true</span> &#125;);</span><br><span class="line">  <span class="keyword">let</span> fileStream = fs.createWriteStream(<span class="string">'./output'</span>);</span><br><span class="line"></span><br><span class="line">  worker.stdout.pipe(fileStream);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">main();</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> distributed-system </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mongoose Schema</title>
      <link href="/2017/08/16/a7/"/>
      <url>/2017/08/16/a7/</url>
      
        <content type="html"><![CDATA[<h2 id="Schema-Type"><a href="#Schema-Type" class="headerlink" title="Schema Type"></a>Schema Type</h2><ul><li>String</li><li>Number</li><li>Date</li><li>Buffer</li><li>Boolean</li><li>Mixed</li><li>Decimal Type <strong>(在3.4中新增，最多支持34位小数，并且存储的是实际值而不是浮点数)</strong></li><li>Object</li><li>Objectid</li><li>Array</li></ul><h2 id="Usage-notes"><a href="#Usage-notes" class="headerlink" title="Usage notes"></a>Usage notes</h2><h3 id="Date"><a href="#Date" class="headerlink" title="Date"></a>Date</h3><figure class="highlight plain"><figcaption><span>内建的 ```Date``` 方法没有被纳入 ```Mongoose``` 。所以如果使用像 ```setMonth``` 这样的方法是不会执行的，如果一定要使用需要通过 ```markModified``` 方法告诉 ```Mongoose``` 。</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>var Assignment = mongoose.model(‘Assignment’, { dueDate: Date });<br>Assignment.findOne(function (err, doc) {<br>  doc.dueDate.setMonth(3);<br>  doc.save(callback); // THIS DOES NOT SAVE YOUR CHANGE</p><p>  doc.markModified(‘dueDate’);<br>  doc.save(callback); // works<br>})</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">### Mixed</span><br><span class="line">当改变了 Mixed 元素的结构类型时，需要通过 ```markModified``` 函数告诉 ```Mongoose``` 后才会自动生效。</span><br></pre></td></tr></table></figure><p>person.anything = { x: [3, 4, { y: “changed” }] };<br>person.markModified(‘anything’);<br>person.save(); // anything will now get saved</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">### ObjectId</span><br><span class="line">声明时需要使用 ```Schema.Types.ObjectId```。</span><br><span class="line"></span><br><span class="line">### Arrays</span><br><span class="line">当将元素声明为 ```Array``` 以后，默认值会是空数组 ```[]```，如果想修复这个问题，需要添加 ```default``` 属性。被声明为 ```Array``` 的元素如果被指定为 ```required``` ，那么至少需要一个元素在其中。</span><br><span class="line"></span><br><span class="line">## Schema Type handle definition</span><br><span class="line">在 ```Schmea``` 中对于每一个元素都有一些定义好的属性供开发者使用。可以直接定义也可以通过 ```path``` 定义。</span><br></pre></td></tr></table></figure><p>// directly<br>var schema = new Schema({<br>  test: {<br>    type: String,<br>    lowercase: true<br>  }<br>});</p><p>// use path<br>var schema2 = new Schema({test: String});</p><p>schema2.path(test).lowercase(true);</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### Common</span><br><span class="line">+ **default(val)** </span><br><span class="line"></span><br><span class="line">    这个属性就是为元素添加默认值，只要在修改之前都会是这个值。</span><br><span class="line">    对于文档里提到的对于 ```mixed``` 属性，如果不设置特殊的函数返回默认值，那么多个实例会指向第一个实例。但是我在 ```4.11.7``` 版本测试，这个问题已经得到修复。</span><br><span class="line">    </span><br><span class="line">+ **validate(obj, [errorMsg], [type])** </span><br><span class="line">    </span><br><span class="line">    为元素添加检验器，来检验输入的值是否符合要求。第一个参数是检验器，支持 ```RegExp```, ```Function```, ```Object```。正则表达式可以进行最简单的字面检验，函数可以进行较为复杂的逻辑检验，对象可以支持多个检验器的组合，并且可以携带错误信息。</span><br></pre></td></tr></table></figure><pre><code>var many = [    { validator: validator, msg: &apos;uh oh&apos; }  , { validator: anotherValidator, msg: &apos;failed&apos; }]new Schema({ name: { type: String, validate: many }});<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">更加细节的是，错误信息可以自定义，当然如果没有自定义，内部为准备了一些错误信息模板。自定义错误信息中可以使用模板来获得一些内部属性。</span><br><span class="line"></span><br><span class="line">+ **&#123;PATH&#125; :** 非法的 document path</span><br><span class="line">+ **&#123;VALUE&#125; :** 非法的值</span><br><span class="line">+ **&#123;TYPE&#125; :** 检验器的类型，比如 ```Regexp```, ```min```, ```user defined</span><br></pre></td></tr></table></figure>+ **{MIN} :** 检验器设定的最大值+ **{Max} :** 检验器设定的最小值同时也提供了异步检验器，可以通过设置 <figure class="highlight plain"><figcaption><span>属性来告诉 ```Mongoose``` 这是一个异步检验器。在回调中需要返回 ```true``` 或者 ```false``` 来告诉检验器是否成功。**（利用这个属性可以方便的写一个如果不存在则存入数据库的逻辑。）** 这个方法会在 ```save``` 动作之前执行，如果需要的话也可以自己进行[调用](http://mongoosejs.com/docs/api.html#document_Document-validate)，```document.validate(function(err)&#123;&#125;)```。 如果在 ```save``` 之前检验器失败，但是没有错误处理的话，异常会被先抛到 ```Model``` 再到 ```db connection``` ，可以通过监听 ```error``` 捕获。    </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+ **get(fn)** </span><br><span class="line"></span><br><span class="line">    为元素添加返回转换器，可以对元素的内容进行转换以后再返回。转换函数中可以接受两个值，第一个是需要过滤的参数，第二个是这个元素对应的 ```SchemaType```，可以使用```SchemaType``` 来定制一些功能。官方文档中举了一个日期处理和信用卡卡号隐藏中间几位数字的例子，还是蛮实用的。</span><br></pre></td></tr></table></figure></code></pre><p>   function inspector (val, schematype) {<br>      if (schematype.options.required) {<br>        return schematype.path + ‘ is required’;<br>      } else {<br>        return schematype.path + ‘ is not’;<br>      }<br>    }</p><pre><code>var VirusSchema = new Schema({  name: { type: String, required: true, get: inspector },  taxonomy: { type: String, get: inspector }})var Virus = db.model(&apos;Virus&apos;, VirusSchema);Virus.findById(id, function (err, virus) {  console.log(virus.name);     // name is required  console.log(virus.taxonomy); // taxonomy is not})<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+ **set(fn)**</span><br><span class="line"></span><br><span class="line">     为元素添加保存转换器，先将元素转换成相应格式以后再存入数据库。同样定义 ```get``` 方法， ```set``` 方法的转换函数也支持两个参数，第一个是需要过滤的参数，第二个是这个元素对应的 ```SchemaType```，可以使用```SchemaType``` 来定制一些功能。</span><br><span class="line">    </span><br><span class="line">+ **select(bool)**   </span><br><span class="line">     </span><br><span class="line">     用来决定该元素是否要包含在搜索结果当中，但是这个属性会被 ```query``` 级别的声明覆盖。</span><br></pre></td></tr></table></figure>T = db.model(&apos;T&apos;, new Schema({ x: { type: String, select: true }}));T.find(..); // field x will always be selected ..// .. unless overridden;T.find().select(&apos;-x&apos;).exec(callback); <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">     </span><br><span class="line">+ **index(options)**</span><br><span class="line">    </span><br><span class="line">    来定义是否为该元素添加索引，支持 ```Object```, ```Boolean```, ```String```， ```Object``` 用来定义复合索引。**（先留flag，后面会来填MongoDB index的相关问题）**</span><br><span class="line">    </span><br><span class="line">+ **required(required, [options.isRequired], [options.ErrorConstructor], [message])**</span><br><span class="line"></span><br><span class="line">    为元素添加存在检查器，算是检查器的一个特例，所以同样有错误信息等。并且 ```required``` 属性同样支持函数来自定义存在检查，如果没有进行自定义那么 ```Mongoose``` 会检查这个元素的值是否等于 ```null``` 或者 ```undefined``` 来判断是否存在。**（但是这边的自定义功能感觉和 ```validate``` 有点冗余）**</span><br><span class="line">    </span><br><span class="line">+ **sparse(bool)**</span><br><span class="line"></span><br><span class="line">    为元素添加稀疏索引。**作用是当该元素为空是不进入索引。**</span><br><span class="line">    </span><br><span class="line">+ **unique(bool)**</span><br><span class="line"></span><br><span class="line">    为元素添加唯一索引。**作用是只允许一条索引字段为空的记录存在，之后就不允许插入了。再次插入 记录时会报错。**    </span><br><span class="line">    </span><br><span class="line">+ **text(bool)**</span><br><span class="line"></span><br><span class="line">    为元素添加全文索引。**（全文索引的坑下次和符合索引一起填。）**    </span><br><span class="line">    </span><br><span class="line">### String</span><br><span class="line"></span><br><span class="line">+ **checkRequired(value, doc)**</span><br><span class="line">    </span><br><span class="line">    对于 ```String``` 属性特殊定制的 ```required``` 属性，```required``` 会直接调用字符串的 ```checkRequired``` 方法。会针对字符串，不仅检查是否为空，还会检查长度、类型和原型链，空字符串会被判 ```fail``` 。</span><br><span class="line">    </span><br><span class="line">+ **enum([args...])** </span><br><span class="line"></span><br><span class="line">    一种特殊的检查器，会检查输入的字符串是否在规定的串中，同样有错误信息。</span><br></pre></td></tr></table></figure>var states = [&apos;opening&apos;, &apos;open&apos;, &apos;closing&apos;, &apos;closed&apos;]var s = new Schema({ state: { type: String, enum: states }})var M = db.model(&apos;M&apos;, s)var m = new M({ state: &apos;invalid&apos; })m.save(function (err) {  console.error(String(err)) // ValidationError: `invalid` is not a valid enum value for path `state`.  m.state = &apos;open&apos;  m.save(callback) // success})// or with custom error messagesvar enum = {  values: [&apos;opening&apos;, &apos;open&apos;, &apos;closing&apos;, &apos;closed&apos;],  message: &apos;enum validator failed for path `{PATH}` with value `{VALUE}`&apos;}var s = new Schema({ state: { type: String, enum: enum })var M = db.model(&apos;M&apos;, s)var m = new M({ state: &apos;invalid&apos; })m.save(function (err) {  console.error(String(err)) // ValidationError: enum validator failed for path `state` with value `invalid`  m.state = &apos;open&apos;  m.save(callback) // success})<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">    </span><br><span class="line">+ **lowercase(bool)**</span><br><span class="line"></span><br><span class="line">    一种特殊的 ```set``` 属性，会将输入的字符串全部转为小写之后再存入数据库。</span><br><span class="line">    </span><br><span class="line">+ **uppercase(bool)**    </span><br><span class="line">   </span><br><span class="line">   一种特殊的 ```set``` 属性，会将输入的字符串全部转为大写之后再存入数据库。   </span><br><span class="line">    </span><br><span class="line">+ **match(regExp, [message])**</span><br><span class="line">    </span><br><span class="line">    一种特殊的检查器，会检查输入的字符串是否满足正则表达式。空字符串和 ```null``` 会通过这个检查器，所以如果要过滤这些特殊情况还需要添加 ```required``` 属性。</span><br><span class="line">    </span><br><span class="line">+ **maxlength(value, [message])**</span><br><span class="line">    </span><br><span class="line">    一种特殊的检查器，会检查输入的字符串的长度是否比阈值小。会对应错误信息模板中的 ```&#123;MAXLENGTH&#125;``` 。</span><br><span class="line">    </span><br><span class="line">+ **minlength(value, [message])**   </span><br><span class="line">        </span><br><span class="line">    一种特殊的检查器，会检查输入的字符串的长度是否比阈值大。会对应错误信息模板中的 ```&#123;MINLENGTH&#125;``` 。</span><br><span class="line">    </span><br><span class="line">+ **trim(bool)**    </span><br><span class="line">    </span><br><span class="line">    一种特殊的 ```set``` 属性，会将输入字符串先修剪两端的空格再存入数据库。</span><br><span class="line">    </span><br><span class="line">### Number</span><br><span class="line">    </span><br><span class="line">+ **checkRequired(value, doc)**</span><br><span class="line">    </span><br><span class="line">    对于 ```Number``` 属性特殊定制的 ```required``` 属性，```required``` 会直接调用字符串的 ```checkRequired``` 方法。不仅检查是否为 ```null``` 还会检查类型和原型链。</span><br><span class="line"></span><br><span class="line">+ **max(maximum, [message])**</span><br><span class="line"></span><br><span class="line">    一种特殊的检查器，会检查输入的数字是否比阈值小。会对应错误信息模板中的 ```&#123;MAX&#125;``` 。</span><br><span class="line">    </span><br><span class="line">+ **min(value, [message])**</span><br><span class="line"></span><br><span class="line">    一种特殊的检查器，会检查输入的数字是否比阈值大。会对应错误信息模板中的 ```&#123;MIN&#125;``` 。</span><br><span class="line">    </span><br><span class="line">### Date</span><br><span class="line">    </span><br><span class="line">+ **checkRequired(value, doc)**</span><br><span class="line">    </span><br><span class="line">    对于 ```Date``` 属性特殊定制的 ```required``` 属性，```required``` 会直接调用字符串的 ```checkRequired``` 方法。不仅检查是否为 ```null``` 还会检查类型和原型链。</span><br><span class="line">    </span><br><span class="line">+ **expires(when)**</span><br><span class="line"></span><br><span class="line">    为元素添加 ```TTL Index```，这个属性是 ```Date``` 独有的。传入的属性可以是秒数，也可是比较友好的字符串形式。</span><br></pre></td></tr></table></figure>// expire in 24 hoursnew Schema({ createdAt: { type: Date, expires: 60*60*24 }});// expire in 24 hoursnew Schema({ createdAt: { type: Date, expires: &apos;24h&apos; }});// expire in 1.5 hoursnew Schema({ createdAt: { type: Date, expires: &apos;1.5h&apos; }});<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">    </span><br><span class="line">+ **max(maximum, [message])**</span><br><span class="line"></span><br><span class="line">    一种特殊的检查器，会检查输入的数字是否比阈值小。会对应错误信息模板中的 ```&#123;MAX&#125;``` 。输入的值必须是 ```Date``` 类型。</span><br><span class="line">    </span><br><span class="line">+ **min(maximum, [message])**    </span><br><span class="line">    </span><br><span class="line">    一种特殊的检查器，会检查输入的数字是否比阈值大。会对应错误信息模板中的 ```&#123;MIN&#125;``` 。输入的值必须是 ```Date``` 类型。</span><br><span class="line">    </span><br><span class="line">### Object</span><br><span class="line"></span><br><span class="line">+ **auto(bool)**</span><br><span class="line"></span><br><span class="line">    如果打开会自动添加 ```ObjectId``` 到元素的值中。 </span><br><span class="line">    </span><br><span class="line">## Custom</span><br><span class="line">在 ```Mongoose 4.4.0``` 中，支持了自定义 ```Schema Type``` 的功能，新建的 ```Schema Type``` 需要继承自 ```mongoose.SchemaType``` ，与 ```mongoose.SchemaTypes``` 的原型链保持一致，并且需要实现 ```cast()``` 方法。</span><br></pre></td></tr></table></figure></code></pre><p>function Int8(key, options) {<br> mongoose.SchemaType.call(this, key, options, ‘Int8’);<br>}<br>Int8.prototype = Object.create(mongoose.SchemaType.prototype);</p><p>// <code>cast()</code> takes a parameter that can be anything. You need to<br>// validate the provided <code>val</code> and throw a <code>CastError</code> if you<br>// can’t convert it.<br>Int8.prototype.cast = function(val) {<br> var _val = Number(val);<br> if (isNaN(_val)) {<br>   throw new Error(‘Int8: ‘ + val + ‘ is not a number’);<br> }<br> _val = Math.round(_val);<br> if (_val &lt; -0x80 || _val &gt; 0x7F) {<br>   throw new Error(‘Int8: ‘ + val +<br>     ‘ is outside of the range of valid 8-bit ints’);<br> }<br> return _val;<br>};</p><p>// Don’t forget to add <code>Int8</code> to the type registry<br>mongoose.Schema.Types.Int8 = Int8;</p><p>var testSchema = new Schema({ test: Int8 });<br>var Test = mongoose.model(‘Test’, testSchema);</p><p>var t = new Test();<br>t.test = ‘abc’;<br>assert.ok(t.validateSync());<br>assert.equal(t.validateSync().errors[‘test’].name, ‘CastError’);<br>assert.equal(t.validateSync().errors[‘test’].message,<br> ‘Cast to Int8 failed for value “abc” at path “test”‘);<br>assert.equal(t.validateSync().errors[‘test’].reason.message,<br> ‘Int8: abc is not a number’);</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## Creating from ES6 Classes Using</span><br><span class="line">```Mongoose``` 同样支持了 ```ES6``` 的 ```Class``` 特性，可以使用 ```Class``` 新建类之后使用 ```loadClass()``` 导入， </span><br><span class="line"></span><br><span class="line">+ ```getter/setter``` 函数对应 ```get/set</span><br></pre></td></tr></table></figure><ul><li>类方法对应 <figure class="highlight plain"><figcaption><span>的方法</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">+ 静态方法对应 ```Model``` 静态方法。</span><br></pre></td></tr></table></figure></li></ul><p>const schema = new Schema({ firstName: String, lastName: String });</p><p>class PersonClass {<br> // <code>fullName</code> becomes a virtual<br> get fullName() {<br>   return <code>${this.firstName} ${this.lastName}</code>;<br> }</p><p> set fullName(v) {<br>   const firstSpace = v.indexOf(‘ ‘);<br>   this.firstName = v.split(‘ ‘)[0];<br>   this.lastName = firstSpace === -1 ? ‘’ : v.substr(firstSpace + 1);<br> }</p><p> // <code>getFullName()</code> becomes a document method<br> getFullName() {<br>   return <code>${this.firstName} ${this.lastName}</code>;<br> }</p><p> // <code>findByFullName()</code> becomes a static<br> static findByFullName(name) {<br>   const firstSpace = name.indexOf(‘ ‘);<br>   const firstName = name.split(‘ ‘)[0];<br>   const lastName = firstSpace === -1 ? ‘’ : name.substr(firstSpace + 1);<br>   return this.findOne({ firstName, lastName });<br> }<br>}</p><p>schema.loadClass(PersonClass);<br>var Person = db.model(‘Person’, schema);</p><p>Person.create({ firstName: ‘Jon’, lastName: ‘Snow’ }).<br> then(doc =&gt; {<br>   assert.equal(doc.fullName, ‘Jon Snow’);<br>   doc.fullName = ‘Jon Stark’;<br>   assert.equal(doc.firstName, ‘Jon’);<br>   assert.equal(doc.lastName, ‘Stark’);<br>   return Person.findByFullName(‘Jon Snow’);<br> }).<br> then(doc =&gt; {<br>   assert.equal(doc.fullName, ‘Jon Snow’);<br> });<br>``` </p>]]></content>
      
      
      
        <tags>
            
            <tag> mongodb </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
