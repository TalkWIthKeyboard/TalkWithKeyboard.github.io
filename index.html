<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  <meta http-equiv="pragma" content="no-cache">
  <meta http-equiv="cache-control" content="no-cache">
  <meta http-equiv="expires" content="0">
  
  <title>GRYFFONDOR</title>
  <meta name="author" content="TalkWithKeyboard">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="GRYFFONDOR">

  
    <meta property="og:image" content>
  

  
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

</head>
</html>
 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">GRYFFONDOR</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class=""></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/atom.xml" title="Subscribe me.">
			  <i class=""></i>RSS
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 <div class="page-header logo">
  <h1>GRYFFONDOR<span class="blink-fast">∎</span></h1>
</div>

<div class="row page">

	
	<div class="col-md-9">
	

		<div class="slogan">


		<i class="fa fa-heart blink-slow"></i>

		「@JIKE」 Data engineer/Code player

</div>    

		<div id="top_search"></div>
		<div class="mypage">
		
		<!-- title and entry -->
		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2020/09/10/a18/" >Spark Memory Management</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2020-09-10  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<p>本文主要是对Spark的内存管理模块进行了代码走读，从业务逻辑上Spark将内存划分为执行区（Execution区，内存主要用来进行shuffle，join，sort，aggregate的计算）、存储区（Storage区，内存主要用来进行缓存和data transfer）。为了优化JVM内存系统的一些问题，在堆内存和堆外内存的基础上抽象了Tungsten内存系统。文中对涉及到的内的关键方法进行了分析。</p>
<h2 id="代码清单"><a href="#代码清单" class="headerlink" title="代码清单"></a>代码清单</h2><ul>
<li>org.apache.spark.memory.MemoryManager</li>
<li>org.apache.spark.memory.UnifiedMemoryManager</li>
<li>org.apache.spark.memory.MemoryPool</li>
<li>org.apache.spark.memory.ExecutionMemoryPool</li>
<li>org.apache.spark.memory.StorageMemoryPool</li>
<li>org.apache.spark.memory.MemoryConsumer</li>
<li>org.apache.spark.memory.TaskMemoryManager</li>
<li>org.apache.spark.unsafe.memory.MemoryLocation</li>
<li>org.apache.spark.unsafe.memory.MemoryBlock</li>
<li>org.apache.spark.unsafe.memory.MemoryAllocator</li>
<li>org.apache.spark.unsafe.memory.HeapMemoryAllocator</li>
<li>org.apache.spark.unsafe.memory.UnsafeMemoryAllocator</li>
<li>org.apache.spark.storage.memory.MemoryStore</li>
</ul>
<h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><p><img src="/images/a18-1.jpg" alt="a18-1"><br>全局只有唯一一个MemoryManager，里面维护了4个Pool。从业务上分为Execution和Storage，从存储位置分为OnHeap和OffHeap。每个task需要使用多个数据结构，每个数据结构都是一个<code>MemoryConsumer</code>的实现，每个task的这些consumer都通过<code>TaskMemoryManager</code>进行管理，多个<code>TaskMemoryManager</code>共同维护一个<code>Tungsten</code>的页结构。</p>
<h2 id="Tungsten"><a href="#Tungsten" class="headerlink" title="Tungsten"></a>Tungsten</h2><p>为了解决JVM对象存储时的overhead问题，以及GC造成的性能损耗，而提出了一个新的内存模型。提供一套像C/C++一样可以直接操作内存的接口（实际操作的是堆外内存），再为了通用性提供了更高层的接口将堆内存和堆外内存进行了统一。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MemoryLocation</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Nullable</span></span><br><span class="line">  Object obj;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">long</span> offset;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">MemoryLocation</span><span class="params">(@Nullable Object obj, <span class="keyword">long</span> offset)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.obj = obj;</span><br><span class="line">    <span class="keyword">this</span>.offset = offset;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">MemoryLocation</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(<span class="keyword">null</span>, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setObjAndOffset</span><span class="params">(Object newObj, <span class="keyword">long</span> newOffset)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.obj = newObj;</span><br><span class="line">    <span class="keyword">this</span>.offset = newOffset;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Object <span class="title">getBaseObject</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> obj;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">getBaseOffset</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> offset;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MemoryBlock</span> <span class="keyword">extends</span> <span class="title">MemoryLocation</span> </span>&#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> length;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">int</span> pageNumber = NO_PAGE_NUMBER;</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Tungsten提供了一套类似操作系统页内存管理一样的结构，每页会存储一个<code>MemoryBlock</code>结构。<br><code>length</code>是整个Block实际占用的内存大小，<code>pageNumber</code>是在页数组中的index位置。<code>MemoryLocation</code>统一了堆内外内存的寻址，如果是off-heap，则<code>obj</code>为null，<code>offset</code>为绝对内存地址；如果是on-heap，则<code>obj</code>为对象的基地址，<code>offset</code>为偏移量。所以在实际使用过程当中就需要在物理地址与<code>pageNumber</code>,<code>offsetInPage</code>之间进行转换：</p>
<ul>
<li>on-heap: <code>address = page.obj + page.offset + inPageOffset</code></li>
<li>off-heap: <code>address = page.offset + inPageOffset</code></li>
</ul>
<p>但是在这套结构中物理地址不会直接的存储，<code>pageNumer</code> + <code>offsetInPage</code>的组合就能唯一的定位一个值的位置，所以提供了一个编码方法用64位的long值存储这个坐标，前13位是pageNumber，后51位是inPageOffset。在<code>TaskMemoryManager</code>当中提供了多个转换的方法：</p>
<ul>
<li><code>long encodePageNumberAndOffset(MemoryBlock page, long offsetInPage)</code>：给定页和页内偏移量计算encode值</li>
<li><code>long encodePageNumberAndOffset(int pageNumer, long offsetInPage)</code>：给定页号和页内偏移量计算encode值</li>
<li><code>int decodePageNumber(long pagePlusOffsetAddress)</code>：给定encode值，解码pageNumber</li>
<li><code>long decodeOffset(long pagePlusOffsetAddress)</code>：给定encode值，解码offset</li>
<li><code>Object getPage(long pagePlusOffsetAddress)</code>：给定encode值，获取页</li>
<li><code>long getOffsetInPage(long pagePlusOffsetAddress)</code>：给定encode值，获取页内偏移</li>
</ul>
<h2 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h2><h3 id="MemoryManager"><a href="#MemoryManager" class="headerlink" title="MemoryManager"></a>MemoryManager</h3><p>该类是内存管理的统筹类，定义了所有的内存管理动作。因为是一个抽象类，所以这些动作有的会下放给实现类实现，有些动作会委托<code>MemoryPool</code>类实现。下面是接口的分类：</p>
<ul>
<li><p>获取内存大小：</p>
<ul>
<li><code>abstract maxOnHeapStorageMemory</code>：获取Storage区最大能使用的堆内存大小（动态变化的）</li>
<li><code>abstract maxOffHeapStorageMemory</code>：获取Storage区最大能使用的堆外内存大小（动态变化的）</li>
<li><code>storageMemoryUsed</code>: Storage区已使用的内存大小</li>
<li><code>onHeapStorageMemoryUsed</code>：Storage区已使用的堆内存大小</li>
<li><code>offHeapStorageMemoryUsed</code>：Storage区已使用的堆外内存大小</li>
<li><code>executionMemoryUsed</code>: Execution区已使用的内存大小</li>
<li><code>onHeapExecutionMemoryUsed</code>：Execution区已使用的堆内存大小</li>
<li><code>offHeapExecutionMemoryUsed</code>：Execution区已使用的堆外内存大小</li>
<li><code>getExecutionMemoryUsageForTask</code>：获取一个task在Execution区占用的内存大小</li>
</ul>
</li>
<li><p>获取更多的内存空间：</p>
<ul>
<li><code>abstract acquireStorageMemory(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode)</code>：为一个Block获取<code>numBytes</code>的Storage区内存空间，如果获取不到足够的空间可能会删除一个存在的Block。</li>
<li><code>abstract acquireExecutionMemory(numBytes: Long, taskAttemptId: Long, memoryMode: MemoryMode)</code>：为一个task获取<code>numBytes</code>的Execution区内存空间，当不能获取到足够执行的内存空间时，这个方法会阻塞，直到获取到足够多的内存。</li>
</ul>
</li>
<li><p>释放内存空间：</p>
<ul>
<li><code>releaseAllExecutionMemoryForTask(taskAttemptId: Long)</code>：释放一个task占用的所有Execution区内存空间</li>
<li><code>releaseStorageMemory(numBytes: Long, memoryMode: MemoryMode)</code>：释放<code>numBytes</code>的Storage区内存空间</li>
<li><code>releaseAllStorageMemory()</code>：释放所有的Storage区内存空间</li>
<li><code>releaseUnrollMemory(numBytes: Long, memoryMode: MemoryMode)</code>：释放<code>numBytes</code>的用于unroll block的内存空间</li>
</ul>
</li>
<li><p><code>Tungsten</code>相关</p>
</li>
</ul>
<h3 id="UnifiedMemoryManager"><a href="#UnifiedMemoryManager" class="headerlink" title="UnifiedMemoryManager"></a>UnifiedMemoryManager</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">UnifiedMemoryManager</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    conf: <span class="type">SparkConf</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    val maxHeapMemory: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    onHeapStorageRegionSize: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    numCores: <span class="type">Int</span></span>)</span></span><br></pre></td></tr></table></figure>

<p>构造函数中的：</p>
<ul>
<li><code>maxHeapMemory</code>：是堆内存的总大小</li>
<li><code>onHeapStorageRegionSize</code>：是堆内存中Storage区的起始大小</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">maxOnHeapStorageMemory</span></span>: <span class="type">Long</span> = synchronized &#123;</span><br><span class="line">  maxHeapMemory - onHeapExecutionMemoryPool.memoryUsed</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">maxOffHeapStorageMemory</span></span>: <span class="type">Long</span> = synchronized &#123;</span><br><span class="line">  maxOffHeapMemory - offHeapExecutionMemoryPool.memoryUsed</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这两个方法就是简单的计算，不过<code>maxHeapMemory</code>是创建<code>UnifiedMemoryManager</code>时传入的参数，而<code>maxOffHeapMemory</code>是从<code>spark.memory.offHeap.size</code>参数中读入。</p>
<p>::acquireExecutionMemory::<br><code>acquireExecutionMemory</code>中主要的任务就是要给出<code>MemoryPool.acquireMemory()</code>中的两个回调，一个是获取更多的Execution区内存的回调，一个是获取Execution区最多能获取到的内存大小。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maybeGrowExecutionPool</span></span>(extraMemoryNeeded: <span class="type">Long</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (extraMemoryNeeded &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// There is not enough free memory in the execution pool, so try to reclaim memory from</span></span><br><span class="line">    <span class="comment">// storage. We can reclaim any free memory from the storage pool. If the storage pool</span></span><br><span class="line">    <span class="comment">// has grown to become larger than `storageRegionSize`, we can evict blocks and reclaim</span></span><br><span class="line">    <span class="comment">// the memory that storage has borrowed from execution.</span></span><br><span class="line">    <span class="keyword">val</span> memoryReclaimableFromStorage = math.max(</span><br><span class="line">      storagePool.memoryFree,</span><br><span class="line">      storagePool.poolSize - storageRegionSize)</span><br><span class="line">    <span class="keyword">if</span> (memoryReclaimableFromStorage &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// Only reclaim as much space as is necessary and available:</span></span><br><span class="line">      <span class="keyword">val</span> spaceToReclaim = storagePool.freeSpaceToShrinkPool(</span><br><span class="line">        math.min(extraMemoryNeeded, memoryReclaimableFromStorage))</span><br><span class="line">      storagePool.decrementPoolSize(spaceToReclaim)</span><br><span class="line">      executionPool.incrementPoolSize(spaceToReclaim)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>👆获取更多的Execution区内存的回调，这里最重要的是计算可以归还内存大小的逻辑，在<code>memoryFree</code>（空闲的内存大小）和<code>poolSize-storageRegionSize</code>（向Executions区借的内存大小）中取一个更大的值。然后真正归还的内存大小是在<code>memoryReclaimableFromStorage</code>（可以归还的内存大小）和<code>extraMemoryNeeded</code>（Executions区需要扩大的内存大小）之间取一个更小的值。</p>
<p>计算完成以后需要真正的进行内存操作释放需要的内存，该方法在<code>StorageMemoryPool</code>中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">freeSpaceToShrinkPool</span></span>(spaceToFree: <span class="type">Long</span>): <span class="type">Long</span> = lock.synchronized &#123;</span><br><span class="line">  <span class="keyword">val</span> spaceFreedByReleasingUnusedMemory = math.min(spaceToFree, memoryFree)</span><br><span class="line">  <span class="keyword">val</span> remainingSpaceToFree = spaceToFree - spaceFreedByReleasingUnusedMemory</span><br><span class="line">  <span class="keyword">if</span> (remainingSpaceToFree &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// If reclaiming free memory did not adequately shrink the pool, begin evicting blocks:</span></span><br><span class="line">    <span class="keyword">val</span> spaceFreedByEviction =</span><br><span class="line">      memoryStore.evictBlocksToFreeSpace(<span class="type">None</span>, remainingSpaceToFree, memoryMode)</span><br><span class="line">    <span class="comment">// When a block is released, BlockManager.dropFromMemory() calls releaseMemory(), so we do</span></span><br><span class="line">    <span class="comment">// not need to decrement _memoryUsed here. However, we do need to decrement the pool size.</span></span><br><span class="line">    spaceFreedByReleasingUnusedMemory + spaceFreedByEviction</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    spaceFreedByReleasingUnusedMemory</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">`</span><br></pre></td></tr></table></figure>

<p>先计算空闲空间的大小，如果空闲空间大于等于需要释放的空间大小，则不需要进行内存对象操作。否则的话，需要删除一些内存Block。删除的方法在<code>MemoryStore</code>中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">evictBlocksToFreeSpace</span></span>(</span><br><span class="line">    blockId: <span class="type">Option</span>[<span class="type">BlockId</span>],</span><br><span class="line">    space: <span class="type">Long</span>,</span><br><span class="line">    memoryMode: <span class="type">MemoryMode</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">  assert(space &gt; <span class="number">0</span>)</span><br><span class="line">  memoryManager.synchronized &#123;</span><br><span class="line">    <span class="keyword">var</span> freedMemory = <span class="number">0</span>L</span><br><span class="line">    <span class="keyword">val</span> rddToAdd = blockId.flatMap(getRddId)</span><br><span class="line">    <span class="keyword">val</span> selectedBlocks = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">BlockId</span>]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">blockIsEvictable</span></span>(blockId: <span class="type">BlockId</span>, entry: <span class="type">MemoryEntry</span>[_]): <span class="type">Boolean</span> = &#123;</span><br><span class="line">      entry.memoryMode == memoryMode &amp;&amp; (rddToAdd.isEmpty || rddToAdd != getRddId(blockId))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// This is synchronized to ensure that the set of entries is not changed</span></span><br><span class="line">    <span class="comment">// (because of getValue or getBytes) while traversing the iterator, as that</span></span><br><span class="line">    <span class="comment">// can lead to exceptions.</span></span><br><span class="line">    entries.synchronized &#123;</span><br><span class="line">      <span class="keyword">val</span> iterator = entries.entrySet().iterator()</span><br><span class="line">      <span class="keyword">while</span> (freedMemory &lt; space &amp;&amp; iterator.hasNext) &#123;</span><br><span class="line">        <span class="keyword">val</span> pair = iterator.next()</span><br><span class="line">        <span class="keyword">val</span> blockId = pair.getKey</span><br><span class="line">        <span class="keyword">val</span> entry = pair.getValue</span><br><span class="line">        <span class="keyword">if</span> (blockIsEvictable(blockId, entry)) &#123;</span><br><span class="line">          <span class="comment">// We don't want to evict blocks which are currently being read, so we need to obtain</span></span><br><span class="line">          <span class="comment">// an exclusive write lock on blocks which are candidates for eviction. We perform a</span></span><br><span class="line">          <span class="comment">// non-blocking "tryLock" here in order to ignore blocks which are locked for reading:</span></span><br><span class="line">          <span class="keyword">if</span> (blockInfoManager.lockForWriting(blockId, blocking = <span class="literal">false</span>).isDefined) &#123;</span><br><span class="line">            selectedBlocks += blockId</span><br><span class="line">            freedMemory += pair.getValue.size</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dropBlock</span></span>[<span class="type">T</span>](blockId: <span class="type">BlockId</span>, entry: <span class="type">MemoryEntry</span>[<span class="type">T</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> data = entry <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">DeserializedMemoryEntry</span>(values, _, _) =&gt; <span class="type">Left</span>(values)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">SerializedMemoryEntry</span>(buffer, _, _) =&gt; <span class="type">Right</span>(buffer)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">val</span> newEffectiveStorageLevel =</span><br><span class="line">        blockEvictionHandler.dropFromMemory(blockId, () =&gt; data)(entry.classTag)</span><br><span class="line">      <span class="keyword">if</span> (newEffectiveStorageLevel.isValid) &#123;</span><br><span class="line">        <span class="comment">// The block is still present in at least one store, so release the lock</span></span><br><span class="line">        <span class="comment">// but don't delete the block info</span></span><br><span class="line">        blockInfoManager.unlock(blockId)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// The block isn't present in any store, so delete the block info so that the</span></span><br><span class="line">        <span class="comment">// block can be stored again</span></span><br><span class="line">        blockInfoManager.removeBlock(blockId)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (freedMemory &gt;= space) &#123;</span><br><span class="line">      <span class="keyword">var</span> lastSuccessfulBlock = <span class="number">-1</span></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        logInfo(<span class="string">s"<span class="subst">$&#123;selectedBlocks.size&#125;</span> blocks selected for dropping "</span> +</span><br><span class="line">          <span class="string">s"(<span class="subst">$&#123;Utils.bytesToString(freedMemory)&#125;</span> bytes)"</span>)</span><br><span class="line">        (<span class="number">0</span> until selectedBlocks.size).foreach &#123; idx =&gt;</span><br><span class="line">          <span class="keyword">val</span> blockId = selectedBlocks(idx)</span><br><span class="line">          <span class="keyword">val</span> entry = entries.synchronized &#123;</span><br><span class="line">            entries.get(blockId)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// This should never be null as only one task should be dropping</span></span><br><span class="line">          <span class="comment">// blocks and removing entries. However the check is still here for</span></span><br><span class="line">          <span class="comment">// future safety.</span></span><br><span class="line">          <span class="keyword">if</span> (entry != <span class="literal">null</span>) &#123;</span><br><span class="line">            dropBlock(blockId, entry)</span><br><span class="line">            afterDropAction(blockId)</span><br><span class="line">          &#125;</span><br><span class="line">          lastSuccessfulBlock = idx</span><br><span class="line">        &#125;</span><br><span class="line">        logInfo(<span class="string">s"After dropping <span class="subst">$&#123;selectedBlocks.size&#125;</span> blocks, "</span> +</span><br><span class="line">          <span class="string">s"free memory is <span class="subst">$&#123;Utils.bytesToString(maxMemory - blocksMemoryUsed)&#125;</span>"</span>)</span><br><span class="line">        freedMemory</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// like BlockManager.doPut, we use a finally rather than a catch to avoid having to deal</span></span><br><span class="line">        <span class="comment">// with InterruptedException</span></span><br><span class="line">        <span class="keyword">if</span> (lastSuccessfulBlock != selectedBlocks.size - <span class="number">1</span>) &#123;</span><br><span class="line">          <span class="comment">// the blocks we didn't process successfully are still locked, so we have to unlock them</span></span><br><span class="line">          (lastSuccessfulBlock + <span class="number">1</span> until selectedBlocks.size).foreach &#123; idx =&gt;</span><br><span class="line">            <span class="keyword">val</span> blockId = selectedBlocks(idx)</span><br><span class="line">            blockInfoManager.unlock(blockId)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      blockId.foreach &#123; id =&gt;</span><br><span class="line">        logInfo(<span class="string">s"Will not store <span class="subst">$id</span>"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      selectedBlocks.foreach &#123; id =&gt;</span><br><span class="line">        blockInfoManager.unlock(id)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="number">0</span>L</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该类当中有一个存储所有Block的Map，即：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> entries = <span class="keyword">new</span> <span class="type">LinkedHashMap</span>[<span class="type">BlockId</span>, <span class="type">MemoryEntry</span>[_]](<span class="number">32</span>, <span class="number">0.75</span>f, <span class="literal">true</span>)</span><br></pre></td></tr></table></figure>

<p><code>LinkedHashMap</code>不是线程安全的，所以每次操作之前也是需要加锁。如果没有获取到需要释放的内存空间大小则遍历Block，判断遍历的Block与需要存储的Block是否是同一个存储区域（还判断了遍历的Block与需要存储的Block是否是同一个），如果通过了判断则需要先将该Block锁住，加入候选名单。</p>
<p>找够所有的候选者以后还没有达到需要释放的内存空间大小则将所有锁住的Block解锁，返回0，表示这个操作失败。如果达到了，则开始释放内存的过程。将每一个Block执行<code>dropBlock</code>，<code>afterDropAction</code>的操作。在<code>dropBlock</code>中会删除该Block本身的数据（除非Block还在被操作），检查Block是否还在被其他的storage存储，如果是的话就先不删除其metadata，否则的话继续删除metadata。<code>afterDropAction</code>是个hook，可以由调用方指定删除之后的动作。如果在删除过程当中失败的话，需要将没有删除的Block解锁。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeMaxExecutionPoolSize</span></span>(): <span class="type">Long</span> = &#123;</span><br><span class="line">  maxMemory - math.min(storagePool.memoryUsed, storageRegionSize)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>👆获取Execution区最多能获取到的内存大小，是通过最大的内存大小减去Storage区最大能占用的内存大小。Storage区能占用的上限是<code>storageRegionSize</code>。</p>
<p>下面来看真正进行内存分配的函数<code>acquireMemory</code>，该方法在<code>ExecutionMemoryPool</code>中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[memory] <span class="function"><span class="keyword">def</span> <span class="title">acquireMemory</span></span>(</span><br><span class="line">    numBytes: <span class="type">Long</span>,</span><br><span class="line">    taskAttemptId: <span class="type">Long</span>,</span><br><span class="line">    maybeGrowPool: <span class="type">Long</span> =&gt; <span class="type">Unit</span> = (additionalSpaceNeeded: <span class="type">Long</span>) =&gt; (),</span><br><span class="line">    computeMaxPoolSize: () =&gt; <span class="type">Long</span> = () =&gt; poolSize): <span class="type">Long</span> = lock.synchronized &#123;</span><br><span class="line">  assert(numBytes &gt; <span class="number">0</span>, <span class="string">s"invalid number of bytes requested: <span class="subst">$numBytes</span>"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> clean up this clunky method signature</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Add this task to the taskMemory map just so we can keep an accurate count of the number</span></span><br><span class="line">  <span class="comment">// of active tasks, to let other tasks ramp down their memory in calls to `acquireMemory`</span></span><br><span class="line">  <span class="keyword">if</span> (!memoryForTask.contains(taskAttemptId)) &#123;</span><br><span class="line">    memoryForTask(taskAttemptId) = <span class="number">0</span>L</span><br><span class="line">    <span class="comment">// This will later cause waiting tasks to wake up and check numTasks again</span></span><br><span class="line">    lock.notifyAll()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Keep looping until we're either sure that we don't want to grant this request (because this</span></span><br><span class="line">  <span class="comment">// task would have more than 1 / numActiveTasks of the memory) or we have enough free</span></span><br><span class="line">  <span class="comment">// memory to give it (we always let each task get at least 1 / (2 * numActiveTasks)).</span></span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> simplify this to limit each task to its own slot</span></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> numActiveTasks = memoryForTask.keys.size</span><br><span class="line">    <span class="keyword">val</span> curMem = memoryForTask(taskAttemptId)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// In every iteration of this loop, we should first try to reclaim any borrowed execution</span></span><br><span class="line">    <span class="comment">// space from storage. This is necessary because of the potential race condition where new</span></span><br><span class="line">    <span class="comment">// storage blocks may steal the free execution memory that this task was waiting for.</span></span><br><span class="line">    maybeGrowPool(numBytes - memoryFree)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Maximum size the pool would have after potentially growing the pool.</span></span><br><span class="line">    <span class="comment">// This is used to compute the upper bound of how much memory each task can occupy. This</span></span><br><span class="line">    <span class="comment">// must take into account potential free memory as well as the amount this pool currently</span></span><br><span class="line">    <span class="comment">// occupies. Otherwise, we may run into SPARK-12155 where, in unified memory management,</span></span><br><span class="line">    <span class="comment">// we did not take into account space that could have been freed by evicting cached blocks.</span></span><br><span class="line">    <span class="keyword">val</span> maxPoolSize = computeMaxPoolSize()</span><br><span class="line">    <span class="keyword">val</span> maxMemoryPerTask = maxPoolSize / numActiveTasks</span><br><span class="line">    <span class="keyword">val</span> minMemoryPerTask = poolSize / (<span class="number">2</span> * numActiveTasks)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// How much we can grant this task; keep its share within 0 &lt;= X &lt;= 1 / numActiveTasks</span></span><br><span class="line">    <span class="keyword">val</span> maxToGrant = math.min(numBytes, math.max(<span class="number">0</span>, maxMemoryPerTask - curMem))</span><br><span class="line">    <span class="comment">// Only give it as much memory as is free, which might be none if it reached 1 / numTasks</span></span><br><span class="line">    <span class="keyword">val</span> toGrant = math.min(maxToGrant, memoryFree)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// We want to let each task get at least 1 / (2 * numActiveTasks) before blocking;</span></span><br><span class="line">    <span class="comment">// if we can't give it this much now, wait for other tasks to free up memory</span></span><br><span class="line">    <span class="comment">// (this happens if older tasks allocated lots of memory before N grew)</span></span><br><span class="line">    <span class="keyword">if</span> (toGrant &lt; numBytes &amp;&amp; curMem + toGrant &lt; minMemoryPerTask) &#123;</span><br><span class="line">      logInfo(<span class="string">s"TID <span class="subst">$taskAttemptId</span> waiting for at least 1/2N of <span class="subst">$poolName</span> pool to be free"</span>)</span><br><span class="line">      lock.wait()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      memoryForTask(taskAttemptId) += toGrant</span><br><span class="line">      <span class="keyword">return</span> toGrant</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="number">0</span>L  <span class="comment">// Never reached</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>首先关注一下锁的对象，在调用方<code>MemoryManager</code>初始化的时候有声明锁的对象：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GuardedBy</span>(<span class="string">"this"</span>)</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">val</span> onHeapStorageMemoryPool = <span class="keyword">new</span> <span class="type">StorageMemoryPool</span>(<span class="keyword">this</span>, <span class="type">MemoryMode</span>.<span class="type">ON_HEAP</span>)</span><br><span class="line"><span class="meta">@GuardedBy</span>(<span class="string">"this"</span>)</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">val</span> offHeapStorageMemoryPool = <span class="keyword">new</span> <span class="type">StorageMemoryPool</span>(<span class="keyword">this</span>, <span class="type">MemoryMode</span>.<span class="type">OFF_HEAP</span>)</span><br><span class="line"><span class="meta">@GuardedBy</span>(<span class="string">"this"</span>)</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">val</span> onHeapExecutionMemoryPool = <span class="keyword">new</span> <span class="type">ExecutionMemoryPool</span>(<span class="keyword">this</span>, <span class="type">MemoryMode</span>.<span class="type">ON_HEAP</span>)</span><br><span class="line"><span class="meta">@GuardedBy</span>(<span class="string">"this"</span>)</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">val</span> offHeapExecutionMemoryPool = <span class="keyword">new</span> <span class="type">ExecutionMemoryPool</span>(<span class="keyword">this</span>, <span class="type">MemoryMode</span>.<span class="type">OFF_HEAP</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[memory] <span class="class"><span class="keyword">class</span> <span class="title">ExecutionMemoryPool</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    lock: <span class="type">Object</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    memoryMode: <span class="type">MemoryMode</span></span></span></span><br><span class="line"><span class="class"><span class="params">  </span>)</span></span><br></pre></td></tr></table></figure>

<p>通过上面两个代码片段可以看出，多个Pool的锁对象都是<code>MemoryManger</code>，所以多个Pool之间是互斥的，不论是<code>StorageMemoryPool</code>还是<code>ExecutionMemoryPool</code>。</p>
<p>然后整个函数的工作方式：</p>
<ul>
<li>如果是一个新的task，先帮它加入到<code>memoryForTask</code>中，内存设为0，然后唤醒所有等待队列里的线程开始等锁。<code>memoryForTask</code>是一个保存<code>taskId -&gt; memory</code>的map。</li>
<li>进入一个死循环中，先查看是否需要获取更多的内存，如果需要的话则调用<code>maybeGrowPool</code>回调。计算一个task理论能分配到的最大内存和最小内存，即<code>1/2N * maxPoolSize &lt;= cache &lt;= 1/N * maxPoolSize</code>。接着计算实际最大能分配到的内存以及最终实际分配的内存。</li>
<li>如果实际分配到的内存小于需要的内存或者这个任务分配到的总内存都没有达到理论最小内存的话，则将锁还掉以后继续等锁。如果拿到了需要的内存以后就更新<code>memoryForTask</code>并进行返回。</li>
</ul>
<p>::acquireStorageMemory::</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">acquireStorageMemory</span></span>(</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    numBytes: <span class="type">Long</span>,</span><br><span class="line">    memoryMode: <span class="type">MemoryMode</span>): <span class="type">Boolean</span> = synchronized &#123;</span><br><span class="line">  assertInvariants()</span><br><span class="line">  assert(numBytes &gt;= <span class="number">0</span>)</span><br><span class="line">  <span class="keyword">val</span> (executionPool, storagePool, maxMemory) = memoryMode <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">MemoryMode</span>.<span class="type">ON_HEAP</span> =&gt; (</span><br><span class="line">      onHeapExecutionMemoryPool,</span><br><span class="line">      onHeapStorageMemoryPool,</span><br><span class="line">      maxOnHeapStorageMemory)</span><br><span class="line">    <span class="keyword">case</span> <span class="type">MemoryMode</span>.<span class="type">OFF_HEAP</span> =&gt; (</span><br><span class="line">      offHeapExecutionMemoryPool,</span><br><span class="line">      offHeapStorageMemoryPool,</span><br><span class="line">      maxOffHeapStorageMemory)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (numBytes &gt; maxMemory) &#123;</span><br><span class="line">    <span class="comment">// Fail fast if the block simply won't fit</span></span><br><span class="line">    logInfo(<span class="string">s"Will not store <span class="subst">$blockId</span> as the required space (<span class="subst">$numBytes</span> bytes) exceeds our "</span> +</span><br><span class="line">      <span class="string">s"memory limit (<span class="subst">$maxMemory</span> bytes)"</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (numBytes &gt; storagePool.memoryFree) &#123;</span><br><span class="line">    <span class="comment">// There is not enough free memory in the storage pool, so try to borrow free memory from</span></span><br><span class="line">    <span class="comment">// the execution pool.</span></span><br><span class="line">    <span class="keyword">val</span> memoryBorrowedFromExecution = <span class="type">Math</span>.min(executionPool.memoryFree,</span><br><span class="line">      numBytes - storagePool.memoryFree)</span><br><span class="line">    executionPool.decrementPoolSize(memoryBorrowedFromExecution)</span><br><span class="line">    storagePool.incrementPoolSize(memoryBorrowedFromExecution)</span><br><span class="line">  &#125;</span><br><span class="line">  storagePool.acquireMemory(blockId, numBytes)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果需要申请的内存大于最大内存则返回false，申请的内存大于Storage区的剩余内存，则需要从Execution区借内存。Storage区不能将正在运行的task踢出Execution区，所以只能从中获取空闲的空间大小。数值计算完成以后，开始真正的分配。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acquireMemory</span></span>(</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    numBytesToAcquire: <span class="type">Long</span>,</span><br><span class="line">    numBytesToFree: <span class="type">Long</span>): <span class="type">Boolean</span> = lock.synchronized &#123;</span><br><span class="line">  assert(numBytesToAcquire &gt;= <span class="number">0</span>)</span><br><span class="line">  assert(numBytesToFree &gt;= <span class="number">0</span>)</span><br><span class="line">  assert(memoryUsed &lt;= poolSize)</span><br><span class="line">  <span class="keyword">if</span> (numBytesToFree &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    memoryStore.evictBlocksToFreeSpace(<span class="type">Some</span>(blockId), numBytesToFree, memoryMode)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// <span class="doctag">NOTE:</span> If the memory store evicts blocks, then those evictions will synchronously call</span></span><br><span class="line">  <span class="comment">// back into this StorageMemoryPool in order to free memory. Therefore, these variables</span></span><br><span class="line">  <span class="comment">// should have been updated.</span></span><br><span class="line">  <span class="keyword">val</span> enoughMemory = numBytesToAcquire &lt;= memoryFree</span><br><span class="line">  <span class="keyword">if</span> (enoughMemory) &#123;</span><br><span class="line">    _memoryUsed += numBytesToAcquire</span><br><span class="line">  &#125;</span><br><span class="line">  enoughMemory</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>先从Storage中删除一些Block释放一些内存，如果有足够的内存申请就更新已使用的内存计数器，否则直接返回false。</p>
<h3 id="MemoryPool"><a href="#MemoryPool" class="headerlink" title="MemoryPool"></a>MemoryPool</h3><p>这是一个抽象类，整个类都在维护一个变量<code>_poolSize</code>，表示内存使用量。提供了维护这个量的一些方法，如：</p>
<ul>
<li><code>poolSize: Long</code>：获取<code>_poolSize</code></li>
<li><code>memoryFree: Long</code>：获取空闲的内存空间大小</li>
<li><code>incrementPoolSize(delta: Long)</code>：提高<code>_poolSize</code></li>
<li><code>decrementPoolSize(delta: Long)</code>：降低<code>_poolSize</code></li>
</ul>
<p>以及一个抽象方法：</p>
<ul>
<li><code>memoryUsed: Long</code></li>
</ul>
<h3 id="ExecutionMemoryPool"><a href="#ExecutionMemoryPool" class="headerlink" title="ExecutionMemoryPool"></a>ExecutionMemoryPool</h3><p>该类中维护了一个<code>taskId -&gt; memory</code>的Map：<code>memoryForTask</code>来管理内存。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">memoryUsed</span></span>: <span class="type">Long</span> = lock.synchronized &#123;</span><br><span class="line">  memoryForTask.values.sum</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实现父类的抽象方法，直接将<code>memoryForTask</code>中的values累加。</p>
<p><code>acquireMemory</code>已经在上文中分析过了。<code>releaseMemory</code>在<code>MemoryManager.releaseExecutionMemory</code>中被调用：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">releaseMemory</span></span>(numBytes: <span class="type">Long</span>, taskAttemptId: <span class="type">Long</span>): <span class="type">Unit</span> = lock.synchronized &#123;</span><br><span class="line">  <span class="keyword">val</span> curMem = memoryForTask.getOrElse(taskAttemptId, <span class="number">0</span>L)</span><br><span class="line">  <span class="keyword">val</span> memoryToFree = <span class="keyword">if</span> (curMem &lt; numBytes) &#123;</span><br><span class="line">    logWarning(</span><br><span class="line">      <span class="string">s"Internal error: release called on <span class="subst">$numBytes</span> bytes but task only has <span class="subst">$curMem</span> bytes "</span> +</span><br><span class="line">        <span class="string">s"of memory from the <span class="subst">$poolName</span> pool"</span>)</span><br><span class="line">    curMem</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    numBytes</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (memoryForTask.contains(taskAttemptId)) &#123;</span><br><span class="line">    memoryForTask(taskAttemptId) -= memoryToFree</span><br><span class="line">    <span class="keyword">if</span> (memoryForTask(taskAttemptId) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">      memoryForTask.remove(taskAttemptId)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  lock.notifyAll() <span class="comment">// Notify waiters in acquireMemory() that memory has been freed</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在正式释放之前会先比较一下现在该task所占用的内存和需要释放的内存的大小，如果task所占内存小于需要释放的内存也只会释放task所占内存，不会再释放其他的task。因为有新的内存空间出现，所以可以唤醒等待队列里的线程，开始给新任务争取内存。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">releaseAllMemoryForTask</span></span>(taskAttemptId: <span class="type">Long</span>): <span class="type">Long</span> = lock.synchronized &#123;</span><br><span class="line">  <span class="keyword">val</span> numBytesToFree = getMemoryUsageForTask(taskAttemptId)</span><br><span class="line">  releaseMemory(numBytesToFree, taskAttemptId)</span><br><span class="line">  numBytesToFree</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该方法会释放一个task所有的内存，直接获取task所占用的内存以后调用上面的<code>releaseMemory</code>方法。</p>
<h3 id="StorageMemoryPool"><a href="#StorageMemoryPool" class="headerlink" title="StorageMemoryPool"></a>StorageMemoryPool</h3><p>该类负责Storage区的内存管理，在类中维护了一个<code>_memoryUsed</code>参数，来表示使用了多少内存。并且会关联一个<code>MemoryStore</code>对象，该对象会完成真正的内存管理操作。</p>
<p>重要的<code>acquireMemory</code>和<code>freeSpaceToShrinkPool</code>函数均在上文中进行了介绍。</p>
<h3 id="TaskMemoryManager"><a href="#TaskMemoryManager" class="headerlink" title="TaskMemoryManager"></a>TaskMemoryManager</h3><p>该类负责管理一个task的内存，该类中不会直接操作内存，会通过<code>MemoryManager</code>来进行管理。不过因为底层使用了<code>Tungsten</code>内存模型，该类中还会维护内存模型使用的页机制相关的变量。所有的<code>TaskMemoryManager</code>会共用一个<code>MemoryManager</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">acquireExecutionMemory</span><span class="params">(<span class="keyword">long</span> required, MemoryConsumer consumer)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span>(required &gt;= <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">assert</span>(consumer != <span class="keyword">null</span>);</span><br><span class="line">  MemoryMode mode = consumer.getMode();</span><br><span class="line">  <span class="comment">// If we are allocating Tungsten pages off-heap and receive a request to allocate on-heap</span></span><br><span class="line">  <span class="comment">// memory here, then it may not make sense to spill since that would only end up freeing</span></span><br><span class="line">  <span class="comment">// off-heap memory. This is subject to change, though, so it may be risky to make this</span></span><br><span class="line">  <span class="comment">// optimization now in case we forget to undo it late when making changes.</span></span><br><span class="line">  <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">    <span class="keyword">long</span> got = memoryManager.acquireExecutionMemory(required, taskAttemptId, mode);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Try to release memory from other consumers first, then we can reduce the frequency of</span></span><br><span class="line">    <span class="comment">// spilling, avoid to have too many spilled files.</span></span><br><span class="line">    <span class="keyword">if</span> (got &lt; required) &#123;</span><br><span class="line">      <span class="comment">// Call spill() on other consumers to release memory</span></span><br><span class="line">      <span class="comment">// Sort the consumers according their memory usage. So we avoid spilling the same consumer</span></span><br><span class="line">      <span class="comment">// which is just spilled in last few times and re-spilling on it will produce many small</span></span><br><span class="line">      <span class="comment">// spill files.</span></span><br><span class="line">      TreeMap&lt;Long, List&lt;MemoryConsumer&gt;&gt; sortedConsumers = <span class="keyword">new</span> TreeMap&lt;&gt;();</span><br><span class="line">      <span class="keyword">for</span> (MemoryConsumer c: consumers) &#123;</span><br><span class="line">        <span class="keyword">if</span> (c != consumer &amp;&amp; c.getUsed() &gt; <span class="number">0</span> &amp;&amp; c.getMode() == mode) &#123;</span><br><span class="line">          <span class="keyword">long</span> key = c.getUsed();</span><br><span class="line">          List&lt;MemoryConsumer&gt; list =</span><br><span class="line">              sortedConsumers.computeIfAbsent(key, k -&gt; <span class="keyword">new</span> ArrayList&lt;&gt;(<span class="number">1</span>));</span><br><span class="line">          list.add(c);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">while</span> (!sortedConsumers.isEmpty()) &#123;</span><br><span class="line">        <span class="comment">// Get the consumer using the least memory more than the remaining required memory.</span></span><br><span class="line">        Map.Entry&lt;Long, List&lt;MemoryConsumer&gt;&gt; currentEntry =</span><br><span class="line">          sortedConsumers.ceilingEntry(required - got);</span><br><span class="line">        <span class="comment">// No consumer has used memory more than the remaining required memory.</span></span><br><span class="line">        <span class="comment">// Get the consumer of largest used memory.</span></span><br><span class="line">        <span class="keyword">if</span> (currentEntry == <span class="keyword">null</span>) &#123;</span><br><span class="line">          currentEntry = sortedConsumers.lastEntry();</span><br><span class="line">        &#125;</span><br><span class="line">        List&lt;MemoryConsumer&gt; cList = currentEntry.getValue();</span><br><span class="line">        MemoryConsumer c = cList.get(cList.size() - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">long</span> released = c.spill(required - got, consumer);</span><br><span class="line">          <span class="keyword">if</span> (released &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            logger.debug(<span class="string">"Task &#123;&#125; released &#123;&#125; from &#123;&#125; for &#123;&#125;"</span>, taskAttemptId,</span><br><span class="line">              Utils.bytesToString(released), c, consumer);</span><br><span class="line">            got += memoryManager.acquireExecutionMemory(required - got, taskAttemptId, mode);</span><br><span class="line">            <span class="keyword">if</span> (got &gt;= required) &#123;</span><br><span class="line">              <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            cList.remove(cList.size() - <span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span> (cList.isEmpty()) &#123;</span><br><span class="line">              sortedConsumers.remove(currentEntry.getKey());</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClosedByInterruptException e) &#123;</span><br><span class="line">          <span class="comment">// This called by user to kill a task (e.g: speculative task).</span></span><br><span class="line">          logger.error(<span class="string">"error while calling spill() on "</span> + c, e);</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e.getMessage());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">          logger.error(<span class="string">"error while calling spill() on "</span> + c, e);</span><br><span class="line">          <span class="comment">// checkstyle.off: RegexpSinglelineJava</span></span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> SparkOutOfMemoryError(<span class="string">"error while calling spill() on "</span> + c + <span class="string">" : "</span></span><br><span class="line">            + e.getMessage());</span><br><span class="line">          <span class="comment">// checkstyle.on: RegexpSinglelineJava</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// call spill() on itself</span></span><br><span class="line">    <span class="keyword">if</span> (got &lt; required) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">long</span> released = consumer.spill(required - got, consumer);</span><br><span class="line">        <span class="keyword">if</span> (released &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          logger.debug(<span class="string">"Task &#123;&#125; released &#123;&#125; from itself (&#123;&#125;)"</span>, taskAttemptId,</span><br><span class="line">            Utils.bytesToString(released), consumer);</span><br><span class="line">          got += memoryManager.acquireExecutionMemory(required - got, taskAttemptId, mode);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (ClosedByInterruptException e) &#123;</span><br><span class="line">        <span class="comment">// This called by user to kill a task (e.g: speculative task).</span></span><br><span class="line">        logger.error(<span class="string">"error while calling spill() on "</span> + consumer, e);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e.getMessage());</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        logger.error(<span class="string">"error while calling spill() on "</span> + consumer, e);</span><br><span class="line">        <span class="comment">// checkstyle.off: RegexpSinglelineJava</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> SparkOutOfMemoryError(<span class="string">"error while calling spill() on "</span> + consumer + <span class="string">" : "</span></span><br><span class="line">          + e.getMessage());</span><br><span class="line">        <span class="comment">// checkstyle.on: RegexpSinglelineJava</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    consumers.add(consumer);</span><br><span class="line">    logger.debug(<span class="string">"Task &#123;&#125; acquired &#123;&#125; for &#123;&#125;"</span>, taskAttemptId, Utils.bytesToString(got), consumer);</span><br><span class="line">    <span class="keyword">return</span> got;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该方法是为一个task新的consumer分配内存，一进来会先尝试使用ExecutorPool申请<code>required</code>大小的内存，如果能直接获取到就结束。否则的话需要从consumer中挑选合适的consumer进行spill操作（也就是将内存中的数据冲写到硬盘上）来释放足够多的内存。</p>
<p>挑选的过程也很常规，会选出大于需要的内存的consumer中最小的一个，如果不存在则从大到小依次spill，直到释放的内存达到需求。不过筛选大于需要的内存中最小的一个用了一个很简洁快速的方式，创建了一个<code>memory -&gt; List&lt;MemoryConsumer&gt;</code>的TreeMap，直接使用<code>TreeMap.ceilingEntry</code>方法。每次释放完成以后都再重新申请更多的内存，直到申请到了足够多的内存。</p>
<p>如果在上面的操作执行完成以后（也就是能释放的都释放掉了）还是不够，那么就将这个要加入的新的consumer的部分数据冲写到硬盘上，使他能被放入MemoryPool中。</p>
<h4 id="Allocate-page"><a href="#Allocate-page" class="headerlink" title="Allocate page"></a>Allocate page</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> MemoryBlock <span class="title">allocatePage</span><span class="params">(<span class="keyword">long</span> size, MemoryConsumer consumer)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span>(consumer != <span class="keyword">null</span>);</span><br><span class="line">  <span class="keyword">assert</span>(consumer.getMode() == tungstenMemoryMode);</span><br><span class="line">  <span class="keyword">if</span> (size &gt; MAXIMUM_PAGE_SIZE_BYTES) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> TooLargePageException(size);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">long</span> acquired = acquireExecutionMemory(size, consumer);</span><br><span class="line">  <span class="keyword">if</span> (acquired &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> pageNumber;</span><br><span class="line">  <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">    pageNumber = allocatedPages.nextClearBit(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (pageNumber &gt;= PAGE_TABLE_SIZE) &#123;</span><br><span class="line">      releaseExecutionMemory(acquired, consumer);</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(</span><br><span class="line">        <span class="string">"Have already allocated a maximum of "</span> + PAGE_TABLE_SIZE + <span class="string">" pages"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    allocatedPages.set(pageNumber);</span><br><span class="line">  &#125;</span><br><span class="line">  MemoryBlock page = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    page = memoryManager.tungstenMemoryAllocator().allocate(acquired);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">    logger.warn(<span class="string">"Failed to allocate a page (&#123;&#125; bytes), try again."</span>, acquired);</span><br><span class="line">    <span class="comment">// there is no enough memory actually, it means the actual free memory is smaller than</span></span><br><span class="line">    <span class="comment">// MemoryManager thought, we should keep the acquired memory.</span></span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">      acquiredButNotUsed += acquired;</span><br><span class="line">      allocatedPages.clear(pageNumber);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// this could trigger spilling to free some pages.</span></span><br><span class="line">    <span class="keyword">return</span> allocatePage(size, consumer);</span><br><span class="line">  &#125;</span><br><span class="line">  page.pageNumber = pageNumber;</span><br><span class="line">  pageTable[pageNumber] = page;</span><br><span class="line">  <span class="keyword">if</span> (logger.isTraceEnabled()) &#123;</span><br><span class="line">    logger.trace(<span class="string">"Allocate page number &#123;&#125; (&#123;&#125; bytes)"</span>, pageNumber, acquired);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> page;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>页管理主要由一个 <code>BitSet</code>（标示页位情况）和<code>MemoryBlock[]</code>（）实现，true表示页位被占。该方法会先调用<code>acquireExecutionMemory</code>申请实际的物理内存，然后通过<code>BitSet.nextClearBit（）</code>函数获取第一个空位置，并进行占位。完成以后就会通过<code>tungstenMemoryAllocator</code>来真正进行内存申请，下面会分析一下on-heap和off-heap两种不同的内存申请：</p>
<p>::Unsafe memory allocate::</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> MemoryBlock <span class="title">allocate</span><span class="params">(<span class="keyword">long</span> size)</span> <span class="keyword">throws</span> OutOfMemoryError </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> address = Platform.allocateMemory(size);</span><br><span class="line">  MemoryBlock memory = <span class="keyword">new</span> MemoryBlock(<span class="keyword">null</span>, address, size);</span><br><span class="line">  <span class="keyword">if</span> (MemoryAllocator.MEMORY_DEBUG_FILL_ENABLED) &#123;</span><br><span class="line">    memory.fill(MemoryAllocator.MEMORY_DEBUG_FILL_CLEAN_VALUE);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> memory;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Off-heap的所有内存操作都是通过Unsafe工具类来完成，这个方法非常的简单。会先通过<code>Unsafe.allocateMemory</code>申请内存，然后初始化一个页结构，off-heap不会映射对象，所以obj传入null即可。</p>
<p>::Heap memory allocate::</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> MemoryBlock <span class="title">allocate</span><span class="params">(<span class="keyword">long</span> size)</span> <span class="keyword">throws</span> OutOfMemoryError </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> numWords = (<span class="keyword">int</span>) ((size + <span class="number">7</span>) / <span class="number">8</span>);</span><br><span class="line">  <span class="keyword">long</span> alignedSize = numWords * <span class="number">8L</span>;</span><br><span class="line">  <span class="keyword">assert</span> (alignedSize &gt;= size);</span><br><span class="line">  <span class="keyword">if</span> (shouldPool(alignedSize)) &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">      <span class="keyword">final</span> LinkedList&lt;WeakReference&lt;<span class="keyword">long</span>[]&gt;&gt; pool = bufferPoolsBySize.get(alignedSize);</span><br><span class="line">      <span class="keyword">if</span> (pool != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">while</span> (!pool.isEmpty()) &#123;</span><br><span class="line">          <span class="keyword">final</span> WeakReference&lt;<span class="keyword">long</span>[]&gt; arrayReference = pool.pop();</span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">long</span>[] array = arrayReference.get();</span><br><span class="line">          <span class="keyword">if</span> (array != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">assert</span> (array.length * <span class="number">8L</span> &gt;= size);</span><br><span class="line">            MemoryBlock memory = <span class="keyword">new</span> MemoryBlock(array, Platform.LONG_ARRAY_OFFSET, size);</span><br><span class="line">            <span class="keyword">if</span> (MemoryAllocator.MEMORY_DEBUG_FILL_ENABLED) &#123;</span><br><span class="line">              memory.fill(MemoryAllocator.MEMORY_DEBUG_FILL_CLEAN_VALUE);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> memory;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        bufferPoolsBySize.remove(alignedSize);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">long</span>[] array = <span class="keyword">new</span> <span class="keyword">long</span>[numWords];</span><br><span class="line">  MemoryBlock memory = <span class="keyword">new</span> MemoryBlock(array, Platform.LONG_ARRAY_OFFSET, size);</span><br><span class="line">  <span class="keyword">if</span> (MemoryAllocator.MEMORY_DEBUG_FILL_ENABLED) &#123;</span><br><span class="line">    memory.fill(MemoryAllocator.MEMORY_DEBUG_FILL_CLEAN_VALUE);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> memory;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里多大内存有一个优化机制，类中有一个Map会保存大内存块的引用，减少GC和申请内存的时间。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GuardedBy</span>(<span class="string">"this"</span>)</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Map&lt;Long, LinkedList&lt;WeakReference&lt;<span class="keyword">long</span>[]&gt;&gt;&gt; bufferPoolsBySize = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br></pre></td></tr></table></figure>

<p>触发这个机制的内存大小是<code>1024 * 1024</code>，所以我们能看到在allocate方法中会先判断是否触发该机制，如果触发则从未被回收的大内存块中取出相应的块进行存储，否则会重新申请内存。</p>
<h4 id="Free-page"><a href="#Free-page" class="headerlink" title="Free page"></a>Free page</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">freePage</span><span class="params">(MemoryBlock page, MemoryConsumer consumer)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> (page.pageNumber != MemoryBlock.NO_PAGE_NUMBER) :</span><br><span class="line">    <span class="string">"Called freePage() on memory that wasn't allocated with allocatePage()"</span>;</span><br><span class="line">  <span class="keyword">assert</span> (page.pageNumber != MemoryBlock.FREED_IN_ALLOCATOR_PAGE_NUMBER) :</span><br><span class="line">    <span class="string">"Called freePage() on a memory block that has already been freed"</span>;</span><br><span class="line">  <span class="keyword">assert</span> (page.pageNumber != MemoryBlock.FREED_IN_TMM_PAGE_NUMBER) :</span><br><span class="line">          <span class="string">"Called freePage() on a memory block that has already been freed"</span>;</span><br><span class="line">  <span class="keyword">assert</span>(allocatedPages.get(page.pageNumber));</span><br><span class="line">  pageTable[page.pageNumber] = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">    allocatedPages.clear(page.pageNumber);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (logger.isTraceEnabled()) &#123;</span><br><span class="line">    logger.trace(<span class="string">"Freed page number &#123;&#125; (&#123;&#125; bytes)"</span>, page.pageNumber, page.size());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">long</span> pageSize = page.size();</span><br><span class="line">  <span class="comment">// Clear the page number before passing the block to the MemoryAllocator's free().</span></span><br><span class="line">  <span class="comment">// Doing this allows the MemoryAllocator to detect when a TaskMemoryManager-managed</span></span><br><span class="line">  <span class="comment">// page has been inappropriately directly freed without calling TMM.freePage().</span></span><br><span class="line">  page.pageNumber = MemoryBlock.FREED_IN_TMM_PAGE_NUMBER;</span><br><span class="line">  memoryManager.tungstenMemoryAllocator().free(page);</span><br><span class="line">  releaseExecutionMemory(pageSize, consumer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对应于申请页也会有释放页的操作，这个过程比较简单，就是对页相关的数据结构进行更新，做一些清空操作。最后会调用<code>tungstenMemoryAllocator.free</code>进行真正的释放，并且调用底层的Executor区的pool进行释放。下面也会分析一下on-heap和off-heap的不同释放操作。</p>
<p>::Unsafe memory free::</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">free</span><span class="params">(MemoryBlock memory)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> (memory.obj == <span class="keyword">null</span>) :</span><br><span class="line">    <span class="string">"baseObject not null; are you trying to use the off-heap allocator to free on-heap memory?"</span>;</span><br><span class="line">  <span class="keyword">assert</span> (memory.pageNumber != MemoryBlock.FREED_IN_ALLOCATOR_PAGE_NUMBER) :</span><br><span class="line">    <span class="string">"page has already been freed"</span>;</span><br><span class="line">  <span class="keyword">assert</span> ((memory.pageNumber == MemoryBlock.NO_PAGE_NUMBER)</span><br><span class="line">          || (memory.pageNumber == MemoryBlock.FREED_IN_TMM_PAGE_NUMBER)) :</span><br><span class="line">    <span class="string">"TMM-allocated pages must be freed via TMM.freePage(), not directly in allocator free()"</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (MemoryAllocator.MEMORY_DEBUG_FILL_ENABLED) &#123;</span><br><span class="line">    memory.fill(MemoryAllocator.MEMORY_DEBUG_FILL_FREED_VALUE);</span><br><span class="line">  &#125;</span><br><span class="line">  Platform.freeMemory(memory.offset);</span><br><span class="line">  <span class="comment">// As an additional layer of defense against use-after-free bugs, we mutate the</span></span><br><span class="line">  <span class="comment">// MemoryBlock to reset its pointer.</span></span><br><span class="line">  memory.offset = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// Mark the page as freed (so we can detect double-frees).</span></span><br><span class="line">  memory.pageNumber = MemoryBlock.FREED_IN_ALLOCATOR_PAGE_NUMBER;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>整个过程也很简单，调用<code>Unsafe.freeMemory</code>进行内存释放，将页对象设置为一个清空后的状态。</p>
<p>::Heap memory free::</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">free</span><span class="params">(MemoryBlock memory)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> (memory.obj != <span class="keyword">null</span>) :</span><br><span class="line">    <span class="string">"baseObject was null; are you trying to use the on-heap allocator to free off-heap memory?"</span>;</span><br><span class="line">  <span class="keyword">assert</span> (memory.pageNumber != MemoryBlock.FREED_IN_ALLOCATOR_PAGE_NUMBER) :</span><br><span class="line">    <span class="string">"page has already been freed"</span>;</span><br><span class="line">  <span class="keyword">assert</span> ((memory.pageNumber == MemoryBlock.NO_PAGE_NUMBER)</span><br><span class="line">          || (memory.pageNumber == MemoryBlock.FREED_IN_TMM_PAGE_NUMBER)) :</span><br><span class="line">    <span class="string">"TMM-allocated pages must first be freed via TMM.freePage(), not directly in allocator "</span> +</span><br><span class="line">      <span class="string">"free()"</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> size = memory.size();</span><br><span class="line">  <span class="keyword">if</span> (MemoryAllocator.MEMORY_DEBUG_FILL_ENABLED) &#123;</span><br><span class="line">    memory.fill(MemoryAllocator.MEMORY_DEBUG_FILL_FREED_VALUE);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Mark the page as freed (so we can detect double-frees).</span></span><br><span class="line">  memory.pageNumber = MemoryBlock.FREED_IN_ALLOCATOR_PAGE_NUMBER;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// As an additional layer of defense against use-after-free bugs, we mutate the</span></span><br><span class="line">  <span class="comment">// MemoryBlock to null out its reference to the long[] array.</span></span><br><span class="line">  <span class="keyword">long</span>[] array = (<span class="keyword">long</span>[]) memory.obj;</span><br><span class="line">  memory.setObjAndOffset(<span class="keyword">null</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">long</span> alignedSize = ((size + <span class="number">7</span>) / <span class="number">8</span>) * <span class="number">8</span>;</span><br><span class="line">  <span class="keyword">if</span> (shouldPool(alignedSize)) &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">      LinkedList&lt;WeakReference&lt;<span class="keyword">long</span>[]&gt;&gt; pool = bufferPoolsBySize.get(alignedSize);</span><br><span class="line">      <span class="keyword">if</span> (pool == <span class="keyword">null</span>) &#123;</span><br><span class="line">        pool = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        bufferPoolsBySize.put(alignedSize, pool);</span><br><span class="line">      &#125;</span><br><span class="line">      pool.add(<span class="keyword">new</span> WeakReference&lt;&gt;(array));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Do nothing</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>将内存区域置为空，如果是一个大内存块的话就保留弱引用，以供下次需要的时候直接进行使用。为了加大命中概率可以看到在计算占用内存的时候都会找到比当前内存大的最近的一个8的倍数，保证了从弱引用区域中找到的一定是足够能装的下数据中最小的一块。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/johnny666888/p/11197519.html" target="_blank" rel="noopener">spark 源码分析之十五 — Spark内存管理剖析 - JohnnyBai - 博客园</a><br><a href="https://github.com/hustnn/TungstenSecret" target="_blank" rel="noopener">GitHub - hustnn/TungstenSecret: Explore the project Tungsten</a><br><a href="https://www.uml-diagrams.org/examples/java-6-thread-state-machine-diagram-example.html" target="_blank" rel="noopener">Java 6 thread states and life cycle UML protocol state machine diagram example.</a></p>

	
	</div>
  <a type="button" href="/2020/09/10/a18/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2020/03/22/a17/" >Mongodb CDC链路中的有序性</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2020-03-22  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<p>在我们的业务当中有这样一个场景，用户每收到一笔转账以后，就会通过推送服务给用户发送一个通知，而这些通知之间需要保证先后顺序（即帐单的产生时序）。假设我们有一个订单数据结构<code>Bill</code>：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">"_id"</span>: ObjectId</span><br><span class="line">	<span class="string">"fromUserId"</span>: String,</span><br><span class="line">	<span class="attr">"toUserId"</span>: String,</span><br><span class="line">	<span class="attr">"amount"</span>: Double,</span><br><span class="line">	<span class="attr">"createdAt"</span>: Long</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>fromUserId</code>是转账用户的id，<code>toUserId</code>是收款用户的id，<code>amount</code>是转账金额，<code>createdAt</code>是记录创建的日期。</p>
<p>系统中使用安装了<code>debezium connector for mongodb</code>插件的<code>kafka connect</code>来将mongodb oplog收集到kafka中，下游使用<code>flink streaming task</code>来进行消费并触发推送服务。整个过程中数据会流过多个分布式系统，如何保证在流经这些系统以后还能保证记录的产生顺序就是今天要讨论的问题。</p>
<h2 id="Kafka-connect-amp-amp-Kafka"><a href="#Kafka-connect-amp-amp-Kafka" class="headerlink" title="Kafka connect &amp;&amp; Kafka"></a>Kafka connect &amp;&amp; Kafka</h2><p>所有的<code>Bill oplog</code>都会被发送到同一个<code>Kafka topic</code>中，所以只需要保证在发往Kafka的过程当中使用<code>toUserId</code>作为 Partition Key即可。但是由于使用了开源组件来帮助我们完成了收集oplog的任务，所以需要保证<code>debezium connector for mongodb</code>能如我们的愿。</p>
<p>首先需要知道的是<code>Kafka connect</code>默认情况下使用的分区策略是<code>org.apache.kafka.clients.producer.DefaultPartitioner</code>，其中<code>partition</code>方法的实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Compute the partition for the given record.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> topic The topic name</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> key The key to partition on (or null if no key)</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> keyBytes serialized key to partition on (or null if no key)</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> value The value to partition on or null</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> valueBytes serialized value to partition on or null</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> cluster The current cluster metadata</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">    List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">    <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">    <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> nextValue = nextValue(topic);</span><br><span class="line">        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">        <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> part = Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">            <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">            <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">        <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">nextValue</span><span class="params">(String topic)</span> </span>&#123;</span><br><span class="line">    AtomicInteger counter = topicCounterMap.get(topic);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == counter) &#123;</span><br><span class="line">        counter = <span class="keyword">new</span> AtomicInteger(ThreadLocalRandom.current().nextInt());</span><br><span class="line">        AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);</span><br><span class="line">        <span class="keyword">if</span> (currentCounter != <span class="keyword">null</span>) &#123;</span><br><span class="line">            counter = currentCounter;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> counter.getAndIncrement();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果key是空的，则以轮训的方式来分配<code>partition</code>，否则则使用一种<code>murmur2</code>的HASH算法来分配<code>partition</code>。所以我们只需要将message key设置为<code>toUserId</code>即可达成我们的目的。但是 <a href="https://debezium.io/documentation/reference/1.0/connectors/mongodb.html#mongodb-change-events-key" target="_blank" rel="noopener">Debezium Connector for MongoDB :: Change event’s key</a> 中写道，message key只能是<code>_id</code>，而<code>toUserId</code>不具有唯一性，所以不能作为<code>_id</code>；如果加上时间戳或者其他的字段保证了唯一性，又失去了要将相同<code>toUserId</code>放在一个分区的语义，所以这条路基本是走不通的。</p>
<blockquote>
<p>The MongoDB connector does not make any explicit determination of the topic partitions for events. Instead, it allows Kafka to determine the partition based upon the key. You can change Kafka’s partitioning logic by defining in the Kafka Connect worker configuration the name of the Partitioner implementation.<br>Be aware that Kafka only maintains total order for events written to a single topic partition. Partitioning the events by key does mean that all events with the same key will always go to the same partition, ensuring that all events for a specific document are always totally ordered.</p>
</blockquote>
<p>继续寻找其他的变通方法，<a href="https://debezium.io/documentation/reference/1.0/connectors/mongodb.html#partitions" target="_blank" rel="noopener">Debezium Connector for MongoDB :: Partitions</a> 文档中写到可以通过设置 Kafka connect worker 的<code>Partitioner</code>设置来指定分区策略。也就是 <a href="http://kafka.apache.org/documentation.html#producerconfigs" target="_blank" rel="noopener">Apache Kafka</a> 文档中提到的<code>partitioner.class</code>：</p>
<blockquote>
<p>partitioner.class: Partitioner class that implements the org.apache.kafka.clients.producer.Partitioner interface.<br>Type: classDefault: org.apache.kafka.clients.producer.internals.DefaultPartitioner</p>
</blockquote>
<p>即需要自己通过继承<code>Partitioner</code>接口来实现自己的分区策略，要实现<code>partition方法</code>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实现了之后将包含该类的JAR包放入Kafka connect能扫描的路径下，再在<code>connect-standalone.properties</code>或者<code>connect-distributed.properties</code>配置文件中进行全局的设定。可以参见下面两个链接👇：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/55188508/custom-partition-assignment-in-kafka-jdbc-connector" target="_blank" rel="noopener">java - Custom partition assignment in Kafka JDBC connector - Stack Overflow</a></li>
<li><a href="https://stackoverflow.com/questions/44810221/setting-partition-strategy-in-a-kafka-connector" target="_blank" rel="noopener">java - Setting Partition Strategy in a Kafka Connector - Stack Overflow</a></li>
</ul>
<p>那么试想一下我们的方案是不是就可以实现为，将<code>toUserId</code>和时间戳拼接为唯一性的<code>_id</code>，在partition函数中将<code>toUserId</code>提取出来并以此作为partition key进行分区以实现在kafka中保证顺序的目的。但是这样的实现方案也存在问题，比如这个Kafka connect 仅来为这个任务服务，因为这种分区策略并不具有通用性，如果有多个类似的需求则要部署多份Kafka connect。同时也存在一些好处，例如拼接的<code>_id</code>是可以直接作为Mongodb的shard key来对该场景的上游进行横向扩展的。可惜的是debezium的实现并不能保证shard cluster传入kafka时保证事件的发生顺序，虽然能将拼接的<code>_id</code>作为shard key，但是由于这种架构并没有能力保证顺序性，所以这种扩展也是无效的，参见👇：<br><a href="https://debezium.io/documentation/reference/1.0/connectors/mongodb.html#mongodb-sharded-cluster" target="_blank" rel="noopener">Debezium Connector for MongoDB :: MongoDB sharded cluster</a></p>
<p>综上在该架构中如果想在Kafka层保证事件的有序性是非常困难，并且很不经济实惠。</p>
<h2 id="Flink-streaming"><a href="#Flink-streaming" class="headerlink" title="Flink streaming"></a>Flink streaming</h2><p>通过上文的分析，我们不得不接受一个事实，<code>Flink</code>消费到的是乱序数据。但是因为其特性，能较为方便的对乱序数据进行处理。<br>在debezium收集到的oplog中，包含两个时间戳，一个是在Value payload中的<code>ts_ms</code>，表示的是debezium收集该oplog时的系统时间；另外一个是在Value payload中的<code>source.ts_ms</code>，表示的是mongodb产生oplog的时间。而我们的实体类中也写入了Create bill的时间<code>createdAt</code>，由于只关心<code>Insert</code>事件，所以在Value payload的<code>after.createdAt</code>中能获取Bill创建的真实时间。在使用过程中一般以第二个时间或者第三个时间为准，在没有采用shard cluster的mongodb中，我认为第二个时间的先后次序应该与第三个时间的先后次序相同；采用了shard cluster的mongodb中，应该以第三个时间为准。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">"payload": &#123;</span><br><span class="line">      "after": ...,</span><br><span class="line">      "patch": null,</span><br><span class="line">      "source": &#123;</span><br><span class="line">        "version": "1.0.3.Final",</span><br><span class="line">        "connector": "mongodb",</span><br><span class="line">        "name": "cdc_test",</span><br><span class="line">        "ts_ms": 1558965508000,</span><br><span class="line">        "snapshot": true,</span><br><span class="line">        "db": "inventory",</span><br><span class="line">        "rs": "rs0",</span><br><span class="line">        "collection": "bill",</span><br><span class="line">        "ord": 31,</span><br><span class="line">        "h": 1546547425148721999</span><br><span class="line">      &#125;,</span><br><span class="line">      "op": "r",</span><br><span class="line">      "ts_ms": 1558965515240</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>在Flink的时间概念中也有三种时间：</p>
<ul>
<li>事件时间：独立事件在产生它的设备上发生的事件，通常在进入Flink之前就已经嵌入到事件中。</li>
<li>接入时间：数据进入Flink的时间，取决于Source Operator所在主机的系统时钟。</li>
<li>处理时间：数据在操作算子计算过程中获取到的所在主机时间。</li>
</ul>
<p>显然在该场景下应该选择<code>Bill</code>的创建时间作为Flink的事件时间：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">env.addSource(<span class="type">Utils</span>.providesAvroKafkaConsumer(kafkaConfig))</span><br><span class="line">    .map(recordTuple =&gt; <span class="type">AvroMongoOplog</span>.newInstance(recordTuple._1.asInstanceOf[<span class="type">Record</span>], recordTuple._2.asInstanceOf[<span class="type">Record</span>]))</span><br><span class="line">    .filter(mongoOplog =&gt; mongoOplog.getOpType.eq(<span class="type">MongoOpType</span>.<span class="type">Insert</span>))</span><br><span class="line">    .assignAscendingTimestamps(mongoOplog =&gt; mongoOplog.getDocument.getLong(<span class="string">"createdAt"</span>))</span><br><span class="line">	  .keyBy(mongoOplog =&gt; mongoOplog.getDocument.get(<span class="string">"toUserId"</span>))</span><br><span class="line">    .window(<span class="type">TumblingProcessingTimeWindows</span>.of(<span class="type">Time</span>.seconds(<span class="number">10</span>)))</span><br><span class="line">    .process(...)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>连接Kafka，使用实现的<code>KeyedAvroDeserializationSchema</code>进行反序列化</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io.confluent.kafka.schemaregistry.client.CachedSchemaRegistryClient</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.generic.GenericRecord</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.typeinfo.TypeInformation</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.formats.avro.registry.confluent.ConfluentRegistryAvroDeserializationSchema</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.KafkaDeserializationSchema</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord</span><br><span class="line"></span><br><span class="line"><span class="meta">@SerialVersionUID</span>(<span class="number">1584533572114L</span>)</span><br><span class="line">class KeyedAvroDeserializationSchema extends KafkaDeserializationSchema[(GenericRecord, GenericRecord)] &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> keyDeserializer: ConfluentRegistryAvroDeserializationSchema[GenericRecord] = _</span><br><span class="line">    <span class="keyword">var</span> valueDeserializer: ConfluentRegistryAvroDeserializationSchema[GenericRecord] = _</span><br><span class="line"></span><br><span class="line">    <span class="function">def <span class="title">this</span><span class="params">(topic: String, schemaRegistry: String)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>()</span><br><span class="line">        val keySubject = topic + <span class="string">"-key"</span></span><br><span class="line">        val valueSubject = topic + <span class="string">"-value"</span></span><br><span class="line">        val schemaRegistryClient = <span class="keyword">new</span> CachedSchemaRegistryClient(schemaRegistry, <span class="number">1000</span>)</span><br><span class="line">        val keySchema = schemaRegistryClient.getByID(schemaRegistryClient.getLatestSchemaMetadata(keySubject).getId)</span><br><span class="line">        val valueSchema = schemaRegistryClient.getByID(schemaRegistryClient.getLatestSchemaMetadata(valueSubject).getId)</span><br><span class="line">        keyDeserializer = ConfluentRegistryAvroDeserializationSchema.forGeneric(keySchema, schemaRegistry)</span><br><span class="line">        valueDeserializer = ConfluentRegistryAvroDeserializationSchema.forGeneric(valueSchema, schemaRegistry)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">override def <span class="title">isEndOfStream</span><span class="params">(t: (GenericRecord, GenericRecord)</span>): Boolean </span>= <span class="keyword">false</span></span><br><span class="line"></span><br><span class="line">    <span class="function">override def <span class="title">deserialize</span><span class="params">(consumerRecord: ConsumerRecord[Array[Byte], Array[Byte]])</span>: <span class="params">(GenericRecord, GenericRecord)</span></span></span><br><span class="line"><span class="function">    </span>= (keyDeserializer.deserialize(consumerRecord.key()), valueDeserializer.deserialize(consumerRecord.value()))</span><br><span class="line"></span><br><span class="line">    override def getProducedType: TypeInformation[(GenericRecord, GenericRecord)] = createTypeInformation[(GenericRecord, GenericRecord)]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过一个工具类将<code>(Record,Record)</code>转化为更好处理的<code>MongoOplogEntry</code>类型</p>
</li>
<li><p>过滤出所有的<code>Insert</code>事件</p>
</li>
<li><p>将<code>Bill</code>的创建时间作为Flink的事件时间</p>
</li>
<li><p>按照<code>toUserId</code>进行分区</p>
</li>
<li><p>设置10秒的时间窗口</p>
</li>
<li><p>在窗口处理函数中对所有<code>MongoOplogEntry</code>对象按照<code>createdAt</code>再排序后依次触发推送服务</p>
</li>
</ul>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>以上介绍了在Mongodb CDC过程中保证数据有序性的两种思路，一种是在Kafka中就保证<code>toUserId</code>相同的数据均有序，这样在消费过程中不需要做窗口计算，只要在需要partition的地方继续使用<code>toUserId</code>进行partition，就能保证数据有序性。这种方案在Kafka connect侧需要做很多的工作，但是能为流式任务带来更好的消费性能，但是由于debezium的局限性，在shard cluster的Mongodb中不能发挥作用。第二种是让Flink消费乱序数据，使用其本身的事件时间窗口计算来重新纠正数据。这种方案会让Flink的效率大打折扣，并且需要保证窗口缓存数据不能超过限制，但是比较通用，使用的时候也需要注意迟到的数据该如何处理。大家可以根据自己的场景来挑选方案，或者如果有更好的方案欢迎一起交流。</p>

	
	</div>
  <a type="button" href="/2020/03/22/a17/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2020/01/20/a16/" >URLEncoder in JAVA</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2020-01-20  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<p>发现<code>Webclient</code>的<code>URLEncoder</code>的表现非常不稳定，所以找了一下正确的使用方式，首先是一个issue <a href="https://github.com/spring-projects/spring-boot/issues/8888" target="_blank" rel="noopener">TestRestTemplate does the url encoding twice if I pass the URI as a string · Issue #8888 · spring-projects/spring-boot · GitHub</a> ，一个老哥发现当<code>exchange</code> 里传入 <code>URI</code> 类的时候，<code>exchange</code>不会有任何encode行为，但是在传入一个字符串的时候会被encode。</p>
<p>下面有<code>bclozel</code>的回答👇：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Hi  [@georgmittendorfer](https://github.com/georgmittendorfer) ,</span><br><span class="line">I think this is the expected behavior in Spring Framework (see  [SPR-16202](https://jira.spring.io/browse/SPR-16202)  and  [SPR-14828](https://jira.spring.io/browse/SPR-14828)  for some background on this).</span><br><span class="line">As a general rule, providing a URI String to RestTemplate means that this String should be expanded (using optional method parameters) and then encoded. If you want to take full control over the encoding, you should then use the method variant taking a URI as a parameter.</span><br><span class="line">The Spring Framework team recently added  [some more documentation on the subject of URI encoding](https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/web.html#web-uri-encoding) . Does that help?</span><br></pre></td></tr></table></figure>

<p>看来Spring认为这是一个正常的行为，即<strong>传入字符串的时候我就要对你进行encode，你传URI对象的时候我不管</strong>。继续点进去看看官方文档 <a href="https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/web.html#web-uri-encoding" target="_blank" rel="noopener">Web on Servlet Stack</a>：<br>1.5.3 中被补上了详细的使用细节，首先它将<code>URI</code>的组成分为两个部分，一个叫做<code>URI template</code>，一个叫做<code>URI variables</code>。然后提供了4种encode的模式：</p>
<ul>
<li><code>TEMPLATE_AND_VALUES</code>：会先对template进行encode，然后在扩展的时候再对variables进行encode。</li>
<li><code>VALUES_ONLY</code>：不会对template进行encode，在扩展之前对variables进行encode。</li>
<li><code>URI_COMPONENTS</code>：和第二种类似，不过是在扩展之后对values进行encode。</li>
<li><code>NONE</code>：不做任何的encode。</li>
</ul>
<p>再来看看我们遇到的问题，在我们的一个库中，用错误的姿势使用的<code>URI</code>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> webClient</span><br><span class="line">    .get()</span><br><span class="line">    .uri(<span class="string">"/doItemHighCommissionPromotionLinkByAll?"</span> + Utils.pojo2UrlQuery(request))</span><br><span class="line">    .exchange();</span><br></pre></td></tr></table></figure>

<p>直接传入了一个字符串，会发现调用的方法是：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RequestBodySpec <span class="title">uri</span><span class="params">(String uriTemplate, Object... uriVariables)</span> </span>&#123;</span><br><span class="line">	attribute(URI_TEMPLATE_ATTRIBUTE, uriTemplate);</span><br><span class="line">	<span class="keyword">return</span> uri(uriBuilderFactory.expand(uriTemplate, uriVariables));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>原来我们传入的是一个没有任何占位符的<code>uriTemplate</code>，而现在依赖的<code>WebClient</code>版本中默认的encode模式是<code>EncodingMode.URI_COMPONENTS</code>，也就是根本不会管template部分。所以我们发现为什么传入一个字符串的时候没有被自动encode。</p>
<p>那么是不是把encode模式改为<code>EncodingMode. TEMPLATE_AND_VALUES</code>，让它会encode template就没问题了呢？也不是，比如<code>http://api.vephp.com/hcapi?detail=1&amp;vekey=V00003484Y95498091&amp;para=https://uland.taobao.com/coupon/edetail?activityId=8932eb9980234090851d448195fe363c&amp;itemId=578614572836</code><br>这个url，para传入的又是一个url，跟了一下解析代码，会发现template在解析的时候会把query map解成：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">"detail"</span>: <span class="number">1</span>,</span><br><span class="line">	<span class="attr">"vekey"</span>: <span class="string">"V00003484Y95498091"</span>,</span><br><span class="line">	<span class="attr">"para"</span>: <span class="string">"https://uland.taobao.com/coupon/edetail?activityId=8932eb9980234090851d448195fe363c"</span>,</span><br><span class="line">	<span class="attr">"itemId"</span>: <span class="string">"578614572836"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>因为它解析query params的正则长这样：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"([^&amp;=]+)(=?)([^&amp;]+)?"</span></span><br></pre></td></tr></table></figure>

<p>所以后果是<code>para</code>会被encode（而且还是错误的encode，这是一个针对template的encode，不是正紧的urlEncode），但是<code>itemId</code>部分不会。所以最终也只是得到了一个错误的encode结果。</p>
<p>综上所述有三种使用方式：</p>
<ul>
<li><p>传入的还是一个字符串，不过在构造的时候自己去做urlEncode，然后在WebClient的设置里将encode模式设为后三种。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> WebClient</span><br><span class="line">    .builder()</span><br><span class="line">    .exchangeStrategies(strategies)</span><br><span class="line">    .baseUrl(endpoint)</span><br><span class="line">    .uriBuilderFactory(providesUriBuilderFactory(endpoint));</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> DefaultUriBuilderFactory <span class="title">providesUriBuilderFactory</span><span class="params">(String endpoint)</span> </span>&#123;</span><br><span class="line">    DefaultUriBuilderFactory factory = <span class="keyword">new</span> DefaultUriBuilderFactory(endpoint);</span><br><span class="line">    factory.setEncodingMode(EncodingMode.NONE);</span><br><span class="line">    <span class="keyword">return</span> factory;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>传入一个<code>URI</code>对象，构造的时候自己去做urlEncode，不用关心WebClient里的设置。</p>
</li>
<li><p>正确的使用<code>url template</code>和<code>url variables</code>进行构造，那就不用自己去做urlEncode。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">URI uri = UriComponentsBuilder.fromPath(<span class="string">"/hotel list/&#123;city&#125;"</span>)</span><br><span class="line">        .queryParam(<span class="string">"q"</span>, <span class="string">"&#123;q&#125;"</span>)</span><br><span class="line">        .build(<span class="string">"New York"</span>, <span class="string">"foo+bar"</span>)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>最后你可能会发现自己在进行urlEncode的时候，还是会有问题。可以阅读下 <a href="https://stackoverflow.com/questions/14321873/java-url-encoding-urlencoder-vs-uri" target="_blank" rel="noopener">Java URL encoding: URLEncoder vs. URI - Stack Overflow</a> 和  <a href="https://stackoverflow.com/questions/607176/java-equivalent-to-javascripts-encodeuricomponent-that-produces-identical-outpu" target="_blank" rel="noopener">Java equivalent to JavaScript’s encodeURIComponent that produces identical output? - Stack Overflow</a><br>简单点说就是 <code>URLEncoder.encode()</code> 方法不是你真正想用到的方法，你可以这样：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">encodeURIComponent</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">    String result;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        result = URLEncoder.encode(s, <span class="string">"UTF-8"</span>)</span><br><span class="line">                .replaceAll(<span class="string">"\\+"</span>, <span class="string">"%20"</span>)</span><br><span class="line">                .replaceAll(<span class="string">"\\%21"</span>, <span class="string">"!"</span>)</span><br><span class="line">                .replaceAll(<span class="string">"\\%27"</span>, <span class="string">"'"</span>)</span><br><span class="line">                .replaceAll(<span class="string">"\\%28"</span>, <span class="string">"("</span>)</span><br><span class="line">                .replaceAll(<span class="string">"\\%29"</span>, <span class="string">")"</span>)</span><br><span class="line">                .replaceAll(<span class="string">"\\%7E"</span>, <span class="string">"~"</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">        result = s;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（好傻啊</p>

	
	</div>
  <a type="button" href="/2020/01/20/a16/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/11/08/a15/" >KV分布式事务</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-11-08  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h2 id="Percolator"><a href="#Percolator" class="headerlink" title="Percolator"></a>Percolator</h2><p><code>Percolator</code>主要使用在Bigtable系统中提供分布式事务能力，其本身的实现是利用Bigtable的单行事务能力以及在行内设置lock列来进行悲观事务。数据结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;key, version&gt;: &lt;data&gt;, &lt;lock&gt;, &lt;write&gt;</span><br></pre></td></tr></table></figure>

<h3 id="Transaction-Write"><a href="#Transaction-Write" class="headerlink" title="Transaction Write"></a>Transaction Write</h3><ul>
<li>开启事务：向集中的<code>Timestamp server oracle(TSO)</code>节点申请一个事务开始时间戳<code>t(s)</code>，并且以此时间戳做为事务id</li>
<li>2PC第一阶段：<code>Percolator</code>在一些Write set当中选择一行做为Primary，其他的行做为Secondaries。先对Primary做<code>prewrite</code>操作，如果成功则对其他的Secondaries做<code>prewrite</code>操作。<ul>
<li>Prewrite：这个操作当中有多个原子操作，被封装在一个事务当中，由Bigtable的单行事务性来保证。<ul>
<li>首先检查<code>write</code>是否有时间戳大于<code>t(s)</code>的版本，如果有则说明这行数据已经被新的事务提交过了，直接返回事务冲突</li>
<li>然后检查<code>lock</code>是否有任意版本的数据存在，如果有则说明这行资源还被别的事务持有，返回事务冲突</li>
<li>如果前面的操作都成功了，那么在<code>data</code>写入版本为<code>t(s)</code>的value数据</li>
<li>并且在<code>lock</code>中写入版本为<code>t(s)</code>值为primary位置的数据<br>在<code>prewrite</code>的第二部检查当中，发生冲突是有三种情况：</li>
</ul>
</li>
</ul>
<ul>
<li>获得锁的版本小于<code>t(s)</code>，该资源正在被一个事务持有</li>
<li>获得锁的版本小于<code>t(s)</code>，有一个老事务因为某种原因没有成功的还掉锁</li>
<li>获得锁的版本大于<code>t(s)</code>，该资源正在被一个事务持有<br>上述情况当中的1，3都是典型的写-写冲突，client就进行正常的backoff重试即可。而第2种情况是客户端在2PC的第二阶段发生了异常导致，这时需要rollback之前的事务来释放掉这个异常的锁。并且这里是很难区分1，2的，毕竟锁的版本都小于<code>t(s)</code>，所以需要一个附件条件锁的ttl时间，如果锁处于ttl时间内则说明是第1种情况，在ttl时间外则是第2种情况。</li>
</ul>
</li>
</ul>
<ul>
<li>2PC第二阶段：向集中的<code>TSO</code>节点申请一个事务提交时间戳<code>t(c)</code>，之后检查Primary的<code>lock</code>是否还存在<code>t(s)</code>版本的数据，如果不存在则说明该事务锁已经超过ttl时长，被其他的事务中断了。如果存在的话，则向<code>write</code>写入版本为<code>t(c)</code>值为<code>t(s)</code>的数据并且清掉锁，这时整个事务已经成功。最后异步的完成Secondaries写<code>write</code>并且释放锁的操作。这个阶段当中检查、写入、清锁的过程被包装在一个事务当中。</li>
</ul>
<h3 id="Transaction-Read"><a href="#Transaction-Read" class="headerlink" title="Transaction Read"></a>Transaction Read</h3><p>读事务就要简单很多，<code>Percolator</code>向集中的<code>TSO</code>节点申请一个事务开始的时间戳<code>t(s)</code>，然后检查所有的Read set中的锁，如果存在时间戳小于<code>t(s)</code>的锁：</p>
<ul>
<li>锁还处于TTL时间内，说明该资源正在被另外一个事务持有，Client进行backoff操作</li>
<li>锁已经超时，这时可以通过锁中记录的primary位置找到primary行的<code>write</code>列，检查是否存在锁版本的数据。如果存在则说明该事务已经成功，只是没有正常的还锁，这时将锁对应的事务进行提交，如果不存在则说明该事务2PC第二阶段出现问题，将该事务进行rollback</li>
</ul>
<p>下面是论文源码👇：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transaction</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Write</span>&#123;</span> Row row; Column: col; <span class="built_in">string</span> value;&#125;;</span><br><span class="line">    <span class="built_in">vector</span>&lt;Write&gt; writes_;</span><br><span class="line">    <span class="keyword">int</span> start_ts_;</span><br><span class="line"></span><br><span class="line">    Transaction():start_ts_(orcle.GetTimestamp()) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Set</span><span class="params">(Write w)</span> </span>&#123;writes_.push_back(w);&#125;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Get</span><span class="params">(Row row, Column c, <span class="built_in">string</span>* value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">            bigtable::Txn = bigtable::StartRowTransaction(row);</span><br><span class="line">            <span class="comment">// Check for locks that signal concurrent writes.</span></span><br><span class="line">            <span class="keyword">if</span> (T.Read(row, c+<span class="string">"locks"</span>, [<span class="number">0</span>, start_ts_])) &#123;</span><br><span class="line">                <span class="comment">// There is a pending lock; try to clean it and wait</span></span><br><span class="line">                BackoffAndMaybeCleanupLock(row, c);</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Find the latest write below our start_timestamp.</span></span><br><span class="line">        latest_write = T.Read(row, c+<span class="string">"write"</span>, [<span class="number">0</span>, start_ts_]);</span><br><span class="line">        <span class="keyword">if</span>(!latest_write.found()) <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// no data</span></span><br><span class="line">        <span class="keyword">int</span> data_ts = latest_write.start_timestamp();</span><br><span class="line">        *value = T.Read(row, c+<span class="string">"data"</span>, [data_ts, data_ts]);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// prewrite tries to lock cell w, returning false in case of conflict.</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Prewrite</span><span class="params">(Write w, Write primary)</span> </span>&#123;</span><br><span class="line">        Column c = w.col;</span><br><span class="line">        bigtable::Txn T = bigtable::StartRowTransaction(w.row);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// abort on writes after our start stimestamp ...</span></span><br><span class="line">        <span class="keyword">if</span> (T.Read(w.row, c+<span class="string">"write"</span>, [start_ts_, max])) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="comment">// ... or locks at any timestamp.</span></span><br><span class="line">        <span class="keyword">if</span> (T.Read(w.row, c+<span class="string">"lock"</span>, [<span class="number">0</span>, max])) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        T.Write(w.row, c+<span class="string">"data"</span>, start_ts_, w.value);</span><br><span class="line">        T.Write(w.row, c+<span class="string">"lock"</span>, start_ts_, </span><br><span class="line">            &#123;primary.row, primary.col&#125;);  <span class="comment">// The primary's location.</span></span><br><span class="line">        <span class="keyword">return</span> T.Commit();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">Commit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Write primary = write_[<span class="number">0</span>];</span><br><span class="line">        <span class="built_in">vector</span>&lt;Write&gt; secondaries(write_.begin() + <span class="number">1</span>, write_.end());</span><br><span class="line">        <span class="keyword">if</span> (!Prewrite(primary, primary)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span> (Write w : secondaries)</span><br><span class="line">            <span class="keyword">if</span> (!Prewrite(w, primary)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> commit_ts = orcle.GetTimestamp();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Commit primary first.</span></span><br><span class="line">        Write p = primary;</span><br><span class="line">        bigtable::Txn T = bigtable::StartRowTransaction(p.row);</span><br><span class="line">        <span class="keyword">if</span> (!T.Read(p.row, p.col+<span class="string">"lock"</span>, [start_ts_, start_ts_]))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// aborted while working</span></span><br><span class="line">        T.Write(p.row, p.col+<span class="string">"write"</span>, commit_ts,</span><br><span class="line">            start_ts_); <span class="comment">// Pointer to data written at start_ts_</span></span><br><span class="line">        T.Erase(p.row, p.col+<span class="string">"lock"</span>, commit_ts);</span><br><span class="line">        <span class="keyword">if</span>(!T.Commit()) <span class="keyword">return</span> <span class="literal">false</span>;  <span class="comment">// commit point</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// Second phase: write our write records for secondary cells.</span></span><br><span class="line">        <span class="keyword">for</span> (Write w:secondaries) &#123;</span><br><span class="line">            bigtable::write(w.row, w.col+<span class="string">"write"</span>, commit_ts, start_ts_);</span><br><span class="line">            bigtable::Erase(w.row, w.col+<span class="string">"lock"</span>, commit_ts);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;; <span class="comment">// class Transaction</span></span><br></pre></td></tr></table></figure>

<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><ol>
<li>初始化Bob和Joe的账户，Bob有10元，Joe有2元<br><img src="/images/a15-1.png" alt="a15-1"></li>
<li>有一个事务出现，这个事务要将Bob的7元给Joe，这时获得了一个新的时间戳7，选择Bob做为primary，锁住该行写入Bob减掉7元以后的数据<br><img src="/images/a15-2.png" alt="a15-2"></li>
<li>将Joe选为Secondary，并指向Primary的Bob，锁住该行写入Joe加7元以后的数据<br><img src="/images/a15-3.png" alt="a15-3"></li>
<li>这时候2PC第一阶段完成，开始第二阶段，申请一个提交时间戳8，将时间戳7写入Bob的<code>write</code>的8版本中<br><img src="/images/a15-4.png" alt="a15-4"></li>
<li>将时间戳7写入Joe的<code>write</code>的8版本中<br><img src="/images/a15-5.png" alt="a15-5"></li>
</ol>
<h2 id="Percolator-in-TiDB"><a href="#Percolator-in-TiDB" class="headerlink" title="Percolator in TiDB"></a>Percolator in TiDB</h2><p>有了上面对<code>Percolator</code>的解释，我们现在很容易理解在TiDB中是如果使用<code>Percolator</code>来实现事务逻辑。首先我们来看其乐观事务的实现：<br><img src="/images/a15-6.jpg" alt="a15-6"><br>我们从图上可以看出，<code>Percolator</code>是被使用在TiDB和其下面的TiKV进行事务通信的协议。最开始的时候我很奇怪，<code>Percolator</code>的实现不是一个悲观事务模型吗？但是为什么TiDB里称其为乐观事务，是因为暴露给Client的不是底层的KV而是DB这一层，而加锁的过程被放在了Commit阶段，所以对于Client来说，这就是一个乐观事务模型。当事务开始以后，首先执行DML操作，得到Write set，然后将Write set放到<code>Percolator</code>中执行2PC，在第一阶段上锁。</p>
<p>下面再看看他们在这基础上修改的悲观事务模型，很巧妙：<br><img src="/images/a15-7.jpg" alt="a15-7"><br>将上锁的过程提前到开始执行<code>Percolator</code>事务之前，先对所有的Write set上一个和<code>Percolator</code>同样的锁，不过锁里面没有记录Primary的位置，而是空的，仅做占位符使用。等开始执行<code>Percolator</code>事务以后，锁会被写入正确的值。这样做的好处是，在数据真正开始发生变更之前就锁住了所有资源。不会发生回滚行为，在资源竞争密集的场景下效率大大优于乐观事务。写请求看到这个空锁直接等锁，读请求可以直接从TiKV中读取数据即可。</p>
<h2 id="Omid"><a href="#Omid" class="headerlink" title="Omid"></a>Omid</h2><p><code>Omid</code>主要使用在Phoenix系统中提供分布式事务能力，其本身的实现是利用Hbase的单行事务能力以及在行内设置version, commit列来进行乐观事务，数据结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Data table   &lt;key, version&gt;: &lt;value&gt; &lt;commit&gt;</span><br><span class="line">Commit table      &lt;version&gt;: &lt;commit&gt;</span><br></pre></td></tr></table></figure>

<h3 id="Transaction-Write-1"><a href="#Transaction-Write-1" class="headerlink" title="Transaction Write"></a>Transaction Write</h3><ul>
<li>开启事务：向集中的<code>Timestamp server oracle(TSO)</code>节点申请一个事务开始时间戳<code>t(s)</code>，并且以此时间戳做为事务id</li>
<li>2PC第一阶段：Client将Write set中的每行的修改数据写入Data table版本为<code>t(s)</code>，对应的key的<code>value</code>当中，需要注意的是这时候的<code>commit</code>均为null</li>
<li>2PC第二阶段：Client带上Write set和<code>t(s)</code>向<code>TSO</code>提交commit请求，<code>TSO</code>会进行冲突检查，如果检查成功则返回<code>t(c)</code>给Client，否则的话整个事务被中断。Client拿到<code>t(c)</code>以后向Commit Table发起<code>CAS(t(s), commit, null, t(c))</code>操作，如果返回<code>ABORT</code>则将事务终止，并且异步的清除Data table中之前写入的数据。如果成功，则进行Post-commit流程，将写入Commit table中的<code>t(c)</code>异步复制到Data table的版本为<code>t(s)</code>的<code>commit</code>当中。完成所有的异步复制以后进行垃圾回收，将Commit table当中的数据清除掉，完成整个事务。<ul>
<li>TSO如何进行冲突检查：原理非常的简单，就是检查Write set当中的每一行是否有<code>lastCommit &gt; t(s)</code>的数据，lastCommit是这一行最新的一个<code>t(c)</code>。如果有则说明在该事务执行过程当中已经有其他的事务完成，出现了写-写冲突，则中断该事务。但是要执行这个操作需要在TSO当中保存所有行的lastCommit数据才行，这个存储开销太大了，所以需要想办法优化。优化的手段也比较简单，就是维护一个LRU队列即可，只保存一定数量的行的lastCommit即可。那么不在队列当中的行的lastCommit一定小于等于队列中最小的一个lastCommit时间，这样可以检查<code>lastCommit&lt;=Smallest(lastCommit)&lt;=t(s)</code>的偏序关系，以检查冲突情况。但是由于队列中没有保存所有的数据，还是会有漏网之鱼，比如说现在队列里的<code>Smallest(lastCommit) &gt; t(s)</code>，并且要检查的行没有在队列当中，那么偏序关系就无从可知，这时候就直接将事务中断即可，也不会影响正确性。</li>
<li>CAS函数：这是一个在实现乐观锁当中经常会使用到的函数，<code>CAS(a,b,c,d)</code>是指比较a行b列，如果它现在的值等于c，则将其修改为d。并且这个函数需要保证原子性。在HBase当中可以使用行级事务来实现CAS函数，并保证其原子性。</li>
</ul>
</li>
</ul>
<h3 id="Transaction-Read-1"><a href="#Transaction-Read-1" class="headerlink" title="Transaction Read"></a>Transaction Read</h3><ul>
<li>向集中的<code>Timestamp server oracle(TSO)</code>节点申请一个事务开始时间戳<code>t(s)</code>，并且以此时间戳做为事务id</li>
<li>扫描所有的Read set，每一行从大版本到小版本扫描，找到第一个提交版本小于<code>t(s)</code>的value和对应的版本<code>t(s2)</code>。如果发现其<code>commit==null</code>，这时候有两种情况：<ul>
<li>这一次事务已经成功，只是正在进行Post-commit流程，从Commit table当中将<code>t(c)</code>复制过来</li>
<li>这一次事务没有成功<br>为了区分这两种情况，<code>Omid</code>会去Commit table当中检查版本<code>t(s2)</code>对应的<code>commit</code>是否有值，如果有值则说明是情况1，如果没有则说明是情况2。情况1的话很好办，继续向下遍历更小的版本。情况2的话就比较麻烦：</li>
<li>Client调用<code>CAS(t(s2), commit, null, ABORT)</code>来将其对应的事务设置为ABORT，这样在其重试的Commit环节会发现ABORT标志而使其事务进行中断操作</li>
<li>如果设置成功，还需要检查一下是否是因为读事务太慢而导致的错误中断，去Data table读<code>t(s2)</code>版本的commit，如果发现存在值<code>t(c2)</code>，并且<code>t(c2)&lt;t(s)</code>，则返回其value和版本。否则继续向下遍历更小的版本。</li>
</ul>
</li>
</ul>
<p>下面是论文源码👇：<br><img src="/images/a15-8.png" alt="a15-8"></p>
<p><img src="/images/a15-9.png" alt="a15-9"></p>
<h2 id="End"><a href="#End" class="headerlink" title="End"></a>End</h2><p>通过上文的分析我们可以看出，<code>Percolator</code>的优点是分布式的Commit table，TSO逻辑简单，缺点是锁检查时需要扫描所有Write set的锁情况，并且需要额外的存储开销来记录锁。<code>Omid</code>的优点是执行效率上优于<code>Percolator</code>，但是又多了一个中心系统Commit table。大家可以根据自己的使用场景来进行选择。</p>
<p>参考资料：</p>
<ul>
<li><a href="https://www.usenix.org/system/files/conference/fast17/fast17-shacham.pdf" target="_blank" rel="noopener">Omid, Reloaded: Scalable and Highly-Available Transaction Processing</a></li>
<li><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36726.pdf" target="_blank" rel="noopener">Large-scale Incremental Processing Using Distributed Transactions and Notifications</a></li>
<li><a href="http://kaiyuan.me/2019/01/19/2pc/" target="_blank" rel="noopener">基于 KV 的分布式事务方案</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/79034576?utm_source=wechat_session&utm_medium=social&utm_oi=956566129104080896&from=singlemessage&isappinstalled=0&wechatShare=1&s_r=0" target="_blank" rel="noopener">TiDB 新特性漫谈：悲观事务</a></li>
</ul>

	
	</div>
  <a type="button" href="/2019/11/08/a15/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/10/18/a14/" >锁</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-10-18  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<p>在很多的多线程编程场景下都会遇到多个线程对一个资源进行操作访问的情况，这种场景一旦发生就会牵扯到线程安全问题。为了保证程序的正确性，我们不得不花很大的力气去解决这些线程安全问题。在Java中解决线程安全问题的办法被分为了三种，其一是互斥同步，其二是非阻塞同步，其三是无同步方案。前两种的实现形式都是锁，第三种是通过设计模式的转变来将代码转变为不共享变量的形式，这不在这篇博客的讨论范围中。</p>
<h2 id="线程不安全"><a href="#线程不安全" class="headerlink" title="线程不安全"></a>线程不安全</h2><p>首先我们来分析一下线程安全问题产生的底层原因到底是什么？先看下面的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiThreadIncrease</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        race = race + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> THREAD_COUNT = <span class="number">20</span>;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[THREAD_COUNT];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREAD_COUNT; i++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                System.out.format(<span class="string">"This is %d thread.\n"</span>, Thread.currentThread().getId());</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">10000</span>; j++) &#123;</span><br><span class="line">                    increase();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">2</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(race);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>首先解释一个细节，因为我的代码是在Idea里跑的，所以不仅是有<code>Main thread</code>，还有一个<code>Monitor Ctrl-Break</code>的守护线程。所以代码中是<code>Thread.activeCount() &gt; 2</code>。如果直接使用<code>java</code>执行的话，这里是1即可。然后上面的代码做了一个很简单的事情，开了20个线程，每个线程做一件事情，对<code>race</code>这个变量累加10000次，最后输出。最后的结果显然不是200000，会小很多并且每次都不一样。这是为什么呢？</p>
<p>是因为<code>race = race + 1</code>这一行代码其实做了三件事情：</p>
<ul>
<li><ol>
<li>取出<code>race</code>现有的值</li>
</ol>
</li>
<li><ol start="2">
<li>给<code>race</code>现有的值加上1</li>
</ol>
</li>
<li><ol start="3">
<li>将更新后的值再附给<code>race</code></li>
</ol>
</li>
</ul>
<p>我们理想的状态是，每个线程顺序的做完这三件事：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">thread1.1  // race=0</span><br><span class="line">thread1.2  // race=0</span><br><span class="line">thread1.3  // race=1</span><br><span class="line">thread2.1  // race=1</span><br><span class="line">thread2.2  // race=1</span><br><span class="line">thread2.3  // race=2</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>但实际是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">thread1.1  // race=0</span><br><span class="line">thread2.1  // race=0</span><br><span class="line">thread2.2  // race=0</span><br><span class="line">thread1.2  // race=0</span><br><span class="line">thread1.3  // race=1</span><br><span class="line">thread2.3  // race=1</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>甚至更加的混乱，这就造成代码运行结果错误的现象，也就是出现了线程不安全行为。那么为了规避这样的行为，就需要引出锁的概念，悲观锁就是互斥同步的实现，乐观锁是非阻塞同步的实现。</p>
<h2 id="互斥同步-悲观锁"><a href="#互斥同步-悲观锁" class="headerlink" title="互斥同步 悲观锁"></a>互斥同步 悲观锁</h2><p>首先我们看看《深入理解JVM》中对互斥同步的定义，”互斥同步是常见的一种并发正确性保障手段。同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个（或者一些，使用信号量的时候）线程使用。而互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。因此，在这4个字里面，互斥是因，同步是果；互斥是方法，同步是目的。“</p>
<h3 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h3><p>而如何保证共享数据在同一个时刻只被一个线程使用？那么就需要在这个数据被使用之前就为期加上锁，只有获得锁的线程能够对其进行操作，而这样的锁就被称为悲观锁。在Java中，最基本的实现就是<code>synchronized</code>关键字。其实现的原理是在编译后会在同步块的前后分别形成<code>monitorenter</code>和<code>monitorexit</code>这两个字节码指令，这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。如果指明的是对象参数，那就是这个对象的reference；如果没有明确指定，那就根据<code>synchronized</code>的是实例还是类方法，去取对应的对象实例或Class对象来作为锁对象。先看下面的例子，对比一下添加<code>synchronized</code>关键字前后的字节码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NoSynchronized</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        race = race + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> NoSynchronized().increase();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过javap工具来获取字节码：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> javap -verbose -p io.talkwithkeyboard.code.NoSynchronized</span><br></pre></td></tr></table></figure>

<p>我们只关注<code>increase</code>方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public void increase();</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=1, args_size=1</span><br><span class="line">         0: getstatic     #2                  // Field race:I</span><br><span class="line">         3: iconst_1</span><br><span class="line">         4: iadd</span><br><span class="line">         5: putstatic     #2                  // Field race:I</span><br><span class="line">         8: return</span><br></pre></td></tr></table></figure>

<p>那么在添加<code>synchronized</code>关键字后：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WithSynchronized</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">            race = race + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> WithSynchronized().increase();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>还是只关注<code>increase</code>方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public void increase();</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=3, args_size=1</span><br><span class="line">         0: aload_0</span><br><span class="line">         1: dup</span><br><span class="line">         2: astore_1</span><br><span class="line">         3: monitorenter</span><br><span class="line">         4: getstatic     #2                  // Field race:I</span><br><span class="line">         7: iconst_1</span><br><span class="line">         8: iadd</span><br><span class="line">         9: putstatic     #2                  // Field race:I</span><br><span class="line">        12: aload_1</span><br><span class="line">        13: monitorexit</span><br><span class="line">        14: goto          22</span><br><span class="line">        17: astore_2</span><br><span class="line">        18: aload_1</span><br><span class="line">        19: monitorexit</span><br><span class="line">        20: aload_2</span><br><span class="line">        21: athrow</span><br><span class="line">        22: return</span><br></pre></td></tr></table></figure>

<p>字节码描述的过程是：</p>
<ul>
<li><ol start="0">
<li>将类对象入栈</li>
</ol>
</li>
<li><ol>
<li>复制栈顶元素（即类对象的引用）</li>
</ol>
</li>
<li><ol start="2">
<li>将栈顶元素（类对象）存储到局部变量表Slot 1中</li>
</ol>
</li>
<li><ol start="3">
<li>以栈顶元素做为锁开始同步</li>
</ol>
</li>
<li><ol start="4">
<li>取获取类的静态字段（race），将其值压入栈顶</li>
</ol>
</li>
<li><ol start="7">
<li>int型常量1进栈</li>
</ol>
</li>
<li><ol start="8">
<li>对操作数栈上的两个数值进行加法，结果压入栈顶</li>
</ol>
</li>
<li><ol start="9">
<li>用栈顶元素给类的静态字段（race）赋值</li>
</ol>
</li>
<li><ol start="12">
<li>将局部变量表Slot 1中的类对象入栈</li>
</ol>
</li>
<li><ol start="13">
<li>退出同步</li>
</ol>
</li>
<li><ol start="14">
<li>方法正常结束，跳转到22返回</li>
</ol>
</li>
<li><ol start="17">
<li>从这步开始是异常路径，暂不赘述</li>
</ol>
</li>
</ul>
<p>在展示了整个<code>synchronized</code>关键字的代码流程以后，我们再深究一下<code>monitorenter</code>指令和<code>monitorexit</code>指令在机器码成面到底做了什么。为了阅读方便，我们先不展示机器码的内容，而是从虚拟机规范出发，在执行<code>monitorenter</code>指令的时，首先要尝试获取对象的锁。如果这个对象没有被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1。相应的，在执行<code>monitorexit</code>指令的时候，把锁的计数器减1，当计数器为0的时候，锁就被释放掉。</p>
<h3 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h3><p>以上就是锁的整个低层实现过程，在Java中其实还有更上层的锁封装能实现更多特性的锁，那就是<code>ReentrantLock</code>类，它和<code>synchronized</code>关键字一样都是悲观锁的实现。但是相比<code>synchronized</code>，增加了一些高级功能，主要是以下三点：</p>
<ul>
<li>等待可中断：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// lock() 实现</span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">acquireQueued</span><span class="params">(<span class="keyword">final</span> Node node, <span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> failed = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">boolean</span> interrupted = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                <span class="keyword">final</span> Node p = node.predecessor();</span><br><span class="line">                <span class="keyword">if</span> (p == head &amp;&amp; tryAcquire(arg)) &#123;</span><br><span class="line">                    setHead(node);</span><br><span class="line">                    p.next = <span class="keyword">null</span>; <span class="comment">// help GC</span></span><br><span class="line">                    failed = <span class="keyword">false</span>;</span><br><span class="line">                    <span class="keyword">return</span> interrupted;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (shouldParkAfterFailedAcquire(p, node) &amp;&amp;</span><br><span class="line">                    parkAndCheckInterrupt())</span><br><span class="line">                    interrupted = <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (failed)</span><br><span class="line">                cancelAcquire(node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// lockInterruptibly() 实现</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doAcquireInterruptibly</span><span class="params">(<span class="keyword">int</span> arg)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Node node = addWaiter(Node.EXCLUSIVE);</span><br><span class="line">        <span class="keyword">boolean</span> failed = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                <span class="keyword">final</span> Node p = node.predecessor();</span><br><span class="line">                <span class="keyword">if</span> (p == head &amp;&amp; tryAcquire(arg)) &#123;</span><br><span class="line">                    setHead(node);</span><br><span class="line">                    p.next = <span class="keyword">null</span>; <span class="comment">// help GC</span></span><br><span class="line">                    failed = <span class="keyword">false</span>;</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (shouldParkAfterFailedAcquire(p, node) &amp;&amp;</span><br><span class="line">                    parkAndCheckInterrupt())</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> InterruptedException();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (failed)</span><br><span class="line">                cancelAcquire(node);</span><br><span class="line">        &#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>可以看到在<code>lock()</code>和<code>lockInterruptibly()</code>源码的实现中，唯一的区别是在一直等待锁的过程中，<code>lock()</code>会吞掉中断，近记录中断状态，而<code>lockInterruptibly()</code>会抛异常到上层，交给上面的业务逻辑进行处理。</p>
<ul>
<li>公平锁：多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁，而非公平锁是不能保证这一点的。<code>synchronized</code>就是非公平锁，可以通过 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> ReentrantLock lock = <span class="keyword">new</span> ReentrantLock(<span class="keyword">true</span>);</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>来创建公平锁。</p>
<ul>
<li>可以绑定多个条件：主要是处理生产者消费者模型，由于篇幅这里暂不赘述。</li>
</ul>
<h3 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h3><p><code>volatile</code>可以说是Java中最轻量化级的同步机制，在一定程度上也是可以当作对象的锁来进行使用的，但是在功能上还是不能完全替代被<code>synchronized</code>作用的对象。当一个变量定义为<code>volatile</code>之后，它将具备两种特性，第一是当一个线程修改了这个变量的值，新值对于其他线程来说是立即得知的，这就是可见性。第二个语义是禁止指令重排序优化。</p>
<p>首先介绍一下可见性是如何实现的？普通变量在被一个线程修改之后，会向主内存进行回写，只有等到主内存回写完成以后，其他的线程才能读到新的值。 而被<code>volatile</code>修饰的变量在赋值后会产生一个<code>lock addl $0x0,(%esp)</code>向寄存器中加0的空操作，这个操作能使用本CPU的Cache写入内核，并使别的CPU或者别的内核无效化Cache。相当于将工作内存中的变量拿到了主内存当中，正是因为此让<code>volatile</code>修饰的变量马上对其他线程可见。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileControl</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> <span class="keyword">boolean</span> shutdownRequested = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        shutdownRequested = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> loopCount = <span class="number">100000000</span>;</span><br><span class="line">        System.out.println(Thread.currentThread().getId() + <span class="string">":"</span> + loopCount);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; loopCount; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (shutdownRequested) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(Thread.currentThread().getId() + <span class="string">":"</span> + <span class="string">"shutdown!"</span>);</span><br><span class="line">        shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> THREAD_COUNT = <span class="number">10</span>;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[THREAD_COUNT];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREAD_COUNT; i ++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(() -&gt; <span class="keyword">new</span> VolatileControl().doWork());</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">2</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>比如在这个例子当中，让每个线程都循环100000000次，在大多数情况下最后可以看到<code>shutdown!</code>只被打印了一次。但是一旦去掉<code>volatile</code>修饰以后，就会看到很多个<code>shutdown!</code>被打印出来，这就是因为很多线程在<code>shutdownRequested</code>被修改以后，都读到了老版本的值，出现了线程不安全的情况。而<code>volatile</code>从表现来看基本上达到了为<code>shutdownRequested</code>加锁的效果。但是刚才也提到了我们是在大多数情况下是只看到一次<code>shutdown!</code>，这是为什么呢？可以先看一个更加容易复现的例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileIncrease</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        race = race + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> THREAD_COUNT = <span class="number">20</span>;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[THREAD_COUNT];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREAD_COUNT; i++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">10000</span>; j++) &#123;</span><br><span class="line">                    increase();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">2</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(race);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>还是上面出现过的，每个线程都给<code>race</code>累加值的代码，只不过现在会用<code>volatile</code>进行修饰。<code>volatile</code>的特性又是值被修改后立即能被其他线程看见，那么这个例子就应该输出正确的结果200000，但是运行后会发现还是出现了上面提到的线程不安全的问题。那么这是不是和<code>volatile</code>的描述不符呢？我们还是输出字节码来看看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public static void increase();</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=0, args_size=0</span><br><span class="line">         0: getstatic     #2                  // Field race:I</span><br><span class="line">         3: iconst_1</span><br><span class="line">         4: iadd</span><br><span class="line">         5: putstatic     #2                  // Field race:I</span><br><span class="line">         8: return</span><br></pre></td></tr></table></figure>

<p>可以看到问题是出在<code>race = race + 1</code>上面，到字节码层面上这个操作已经被拆分成了4条指令，并且不具备事务性了。<code>volatile</code>能保证的是<code>getstatic</code>能取到最新的值，但是在<code>iadd</code>操作的时候其他线程可能已经把这个值加大了。在上面的例子当中同理，在将<code>shutdownRequested</code>赋值为true的时候，可能其他线程已经赋值成功，但是当前线程不可见。所以<code>volatile</code>的作用是非常轻微的，只能够保证在取值的时候能取到最新值，当一个操作的事务性无法保证的时候，<code>volatile</code>也不能提供锁的性质。至于防止指令重拍和题目相关性不强，这里先不做赘述。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在《深入理解JVM虚拟机》中，有对<code>synchronized</code>和<code>ReentrantLock</code>进行性能对比，通过对<code>synchronized</code>的优化，性能基本上持平。并且提供因为团队会更偏向于优化原生的<code>synchronized</code>关键字，所以当两个都能使用的时候可以优先使用<code>synchronized</code>关键字，需要更高阶的功能时，再选择<code>ReentrantLock</code>。但是因为阻塞的实现方式，这两种实现都会阻塞后面其他的线程进入，而Java的线程是映射到操作系统的原生线程之上的，如果一个线程要阻塞或唤醒，都是需要操作系统从用户态切换到核心态来进行帮忙的，所以需要非常谨慎的时候，在一定情况下是可以使用<code>volatile</code>关键字来进行替代的，以提高性能。</p>
<h2 id="非阻塞同步-乐观锁"><a href="#非阻塞同步-乐观锁" class="headerlink" title="非阻塞同步 乐观锁"></a>非阻塞同步 乐观锁</h2><p>由于悲观锁的实现中涉及到加锁、用户态核心态切换、维护锁计数器和检查是否有被阻塞线程需要被唤醒等复杂的操作，在执行效率上大打折扣。随着硬件指令集的发展，又多了一种锁实现方案，也就是乐观锁，其主要的思想是：先进行操作，如果没有竞争则操作成功，如果有竞争，那就再采取其他的补偿措施。这种实现方式下，不需要将线程挂起，因此也称为非阻塞同步。</p>
<h3 id="Compare-and-Swap"><a href="#Compare-and-Swap" class="headerlink" title="Compare-and-Swap"></a>Compare-and-Swap</h3><p>乐观锁的一个实现关键是需要让“现在的值等于旧预期值时，将新预期值写入”这个操作原子化，而这也依赖于硬件指令集的发展，出现了<code>CAS(Compare-and-Swap)</code>指令来完成这个任务。CAS指令需要三个操作数，分别是内存位置V、旧的预期值A、新的预期值B。CAS指令执行时，当且仅当V符合旧的预期值A的时候，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新了V的值，都会返回V的旧值，并且上述的过程是原子性的。在JDK1.5之后，<code>sun.misc.Unsafe</code>类的<code>compareAndSwapInt()</code>和<code>compareAndSwapLong()</code>等几个操作都依靠CAS指令执行，虚拟机内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令。在更上层中的接口中，<code>AtomicInteger.incerementAndGet()</code>等使用了<code>Unsafe</code>的低层接口。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiThreadAtomicIncrease</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> AtomicInteger race = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        race.incrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> THREAD_COUNT = <span class="number">20</span>;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[THREAD_COUNT];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREAD_COUNT; i++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">10000</span>; j++) &#123;</span><br><span class="line">                    insert();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">2</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(race.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用乐观锁来对上面多线程累加的程序进行优化，运行程序可以看到正确的结果。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">incrementAndGet</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> unsafe.getAndAddInt(<span class="keyword">this</span>, valueOffset, <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>incrementAndGet</code>方法就是对<code>Unsafe</code>类的<code>getAndAddInt</code>方法进行了封装，而<code>getAndAddInt</code>在低层使用了和CAS类似的指令<code>Fetch-and-Increment</code>，将获取值和累加两个操作进行原子化封装。而在早期的JDK实现中，是使用CAS指令进行完成，不断尝试将比现在值大1的值写入。这个优化也是硬件指令集的进一步丰富带来的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getAndIncrement</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">int</span> current = get();</span><br><span class="line">        <span class="keyword">int</span> next = current + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (compareAndSet(current, next))</span><br><span class="line">            <span class="keyword">return</span> current;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h2><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><p>因为互斥同步对性能的消耗非常大，并且JVM团队发现大量的锁定状态只会持续很短的一段时间，这个时间远小于对CPU的用户态和内核态切换时间。所以就想出来一个办法不轻易的对线程进行阻塞，而使用忙循环（自旋）来替代。不过自旋也不是完全优于阻塞的，虽然省下了线程切换的开销，不过忙循环会占用处理器时间，所以如果锁定状态时间较短使用自旋是划算的，锁定状态时间较长就会浪费处理器资源，带来性能的消耗。因此现在的实现中，会规定一个自旋的上限，当达到上限以后就转为重锁的方式挂起线程。现在高版本的JDK中自旋是默认开启的，Java用户可以通过<code>-XX:PreBlockSpin</code>来修改自旋的次数。</p>
<p>并且为了进一步的提高自旋锁的性能，在JDK1.6提出了自适应的自旋锁，每次自旋的时间不固定，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态决定。如果在一个锁对象上，通过自旋的方式经常成功获得过锁，并且持有锁的进程正在运行中，那么这次自旋有较大可能获得锁，就可以等待较多的自旋次数。如果在一个锁对象上从来没有成功通过自旋获得锁，那么就直接省去自旋步骤，直接进入重锁。</p>
<h3 id="锁消除"><a href="#锁消除" class="headerlink" title="锁消除"></a>锁消除</h3><p>锁消除是指开发人员虽然要求一段代码块需要上锁，同步执行。但是被JVM检测到存在不可能存在共享数据竞争的锁，就会自动将其消除掉。这个检测主要依赖逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它当作栈上数据对待，认为他们是线程私有的，就不用加锁。</p>
<h3 id="锁粗化"><a href="#锁粗化" class="headerlink" title="锁粗化"></a>锁粗化</h3><p>很多时候我们都希望加锁的作用范围限制的尽可能的小，这样可以缩短锁状态的持续时间，让等待的线程尽快的获得锁。但是偶尔会出现一系列连续的操作都对同一个对象反复加锁和解锁，甚至加锁操作出现在循环体中的，这样频繁的进行互斥同步会极大的降低执行效率，这时候虚拟机探测到有这样一串零碎的操作都对一个对象加锁，就会把加锁的范围粗化到整个操作序列的外部，这样加锁一次就可以了。就还是用上面的例子举例，每次<code>increase</code>操作都有加锁解锁的步骤，这时就会把锁粗化到for循环的外部。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> io.talkwithkeyboard.code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiThreadIncreaseSync</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> race = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        race = race + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> THREAD_COUNT = <span class="number">20</span>;</span><br><span class="line">        Thread[] threads = <span class="keyword">new</span> Thread[THREAD_COUNT];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; THREAD_COUNT; i++) &#123;</span><br><span class="line">            threads[i] = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">10000</span>; j++) &#123;</span><br><span class="line">                    increase();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            threads[i].start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (Thread.activeCount() &gt; <span class="number">2</span>) &#123;</span><br><span class="line">            Thread.yield();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(race);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>轻量级锁的优化方向是使用CAS代替互斥量的开销，并且依据经验“对于绝大多数的锁，在整个同步周期内都是不存在竞争的”，假设没有竞争那么CAS操作就避免了互斥量的开销，但是如果存在竞争，轻量锁最终会膨胀为重量锁，不仅有互斥量的开销，还多了CAS操作。在HotSpot虚拟机中，对象头由两部分组成，一部分是非固定数据结构的，用来储存对象自身的运行时数据，如哈希值，GC分带年龄等数据，官方称为”Mark word”；另一部分用于储存指向方法区对象类型数据的指针，这一部分先不关注。而“Mark word”就是锁实现的关键，我们以32位的HotSpot举例，32bit的”Mark word”中除了2bit用于存储锁标志位外，其他的30bit所保存的内容都根据锁状态发生变化：</p>
<ul>
<li>当处于未锁定（标志位为01）时，29bit存储了对象哈希值、对象分代年龄等</li>
<li>需要加锁时，先检查是否处于未锁定状态，如果是，在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储当前锁对象”Mark word”的拷贝</li>
<li>使用CAS操作将其余30bit更新为指向锁记录的指针<ul>
<li>这些动作成功了，改变标志位（00是轻量级锁），这个线程就拥有了该对象的锁</li>
<li>如果失败了，虚拟机会检查对象的Mark word是否指向当前线程，如果是则说明当前线程已经获得锁，则直接进入同步块执行。否则这个锁对象已经被其他的线程抢占了。这时候轻量锁膨胀为重量锁，标志位改为10，Mark word指向重量锁，后面的线程进入阻塞状态。</li>
</ul>
</li>
<li>当执行完同步块，使用CAS操作将对象当前的Mark word与之前存储的老Mark word拷贝进行交换，完成解锁。</li>
</ul>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>偏向锁的优化方向是在不存在竞争时直接去掉同步原语，当锁对象第一次被线程获取的时候，虚拟机会将标志位改为01，即偏向模式，同时使用CAS操作把获取到的锁的线程ID记录在Mark word之中，如果操作成功，这个线程就拥有了该对象的锁。之后当持有偏向锁的线程进入同步块的时候，虚拟机不需要做任何操作，而在轻量锁中，还是需要尝试检查锁定状态，以及对象的Mark word是否指向自己。当有其他线程尝试获取锁的时候，偏向锁就膨胀为轻量锁。偏向锁可以提高带有同步但无竞争的程序性能，但是如果程序中大多数的锁总是被多个不同的线程访问，那偏向模式就是多余的。可以通过<code>-XX:-UseBiasedLocking</code>来进行禁止。</p>
<p><img src="/images/a-14-1.jpg" alt="a-14-1"></p>
<h2 id="End"><a href="#End" class="headerlink" title="End"></a>End</h2><p>参考资料：《深入理解Java虚拟机》</p>

	
	</div>
  <a type="button" href="/2019/10/18/a14/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/09/28/a6/" >Elasticsearch优化思路</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-09-28  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<blockquote>
<p>于9月25日，参加云栖大会elasticsearch专场后对阿里云的优化思路进行整理总结。行文分为两个部分，一个部分是对原生elasticsearch的解决方案进行大致介绍，再对阿里云的优化进行整理。</p>
</blockquote>
<h2 id="原生架构"><a href="#原生架构" class="headerlink" title="原生架构"></a>原生架构</h2><p>在elasticsearch当中<code>index</code>是大家最熟悉的组织结构，它就像传统nosql数据库中的collection，组织着一批有相同数据结构的数据。当一个<code>index</code>中的数据量越来越大，就会很自然的将<code>index</code>进行分片，分到多个shard当中。这样通过水平扩展就能解决数据膨胀的问题，然后同时也引入了副本来提高整个集群的可用性。所以有两个<code>index</code>，每个<code>index</code>有3个shard，每个shard有2个replica的集群就是下面这个样子👇：<br><img src="/images/a6-1.png" alt="a6-1"><br>index A有3个shard：<code>A1</code>、<code>A2</code>、<code>A3</code>，<code>A1’</code>是<code>A1</code>的副本，以此类推。</p>
<p>在这样的架构中，如果想向index A中写入文档，会先通过路由算法分配到一个primary所在的节点（比如<code>A1</code>）进行写入，完成以后会到该primary的副本<code>A1’</code>中进行写入，完成以后再返回成功。可以看出这样的流程中有几个瓶颈所在：</p>
<ul>
<li>如果副本的数量一旦较多，写请求的延时就会成倍增长</li>
<li>副本会保存一份完整的数据，所以集群的存储成本也在成倍地增长</li>
<li>如果副本数量超过了分片数量，会出现有节点只是用来做副本的情况，只能被读，浪费了资源</li>
<li>当主节点出现故障时，会从新在副本当中选举主节点，并新启动一个节点，从新的主节点当中全量拷贝数据。全量拷贝的延时较长，在这一段时间内新副本节点是不可用的，所有的流量会打到主节点和其他副本节点上，可能出现性能问题</li>
</ul>
<h2 id="优化架构"><a href="#优化架构" class="headerlink" title="优化架构"></a>优化架构</h2><p>先来看阿里云的架构图👇：<br><img src="/images/a6-2.png" alt="a6-2"><br>使用了计算与存储分离的架构，通过底层的云储存来提供共享存储。这样主副之间的数据只用存在一个地方即可，而节点上只提供计算能力，由云存储来提供数据的多副本机制以保证数据的可靠性。如果要完整的理解上面这张图，我们需要再介绍一些概念：</p>
<p>在elasticsearch中，一个shard是由多个segment组成的，并对应一个translog文件。那么当写入一个文档时，会先在translong中进行相应的记录，并将其写入到primary节点的buffer当中。然后在primary节点上是有一个每秒执行一次的<code>refresh</code>操作，该操作会把buffer当中的所有document写入到内存中的一个新的segment当中，这时候文档变成了可被检索的状态，所以一个segment实际就是一个倒排索引。最后会有一个<code>flush</code>操作，该操作也会把buffer中的数据写入到一个新的segment中，并进一步将内存中的所有segment冲洗到硬盘上，并清空该shard上的translog。</p>
<p>在对整个索引过程解释了一遍以后就可以清晰的理解上图，NFS表示阿里云提供的分布式云存储。当一个index请求进来的时候，primary节点会先在translog中添加一条记录，并将该文档写入buffer当中。每隔一段时间，primary节点会进行refresh操作将buffer中的所有数据写入到nfs的refresh segment中进行保存。然后会由 <code>nrt segment synchronizer</code>进程定期的复制refresh segment中的数据到临时目录当中。最后会由<code>flush</code>操作，将refresh segment中的数据写入到commit segment中，并删除refresh segment，临时目录，以及translog。而读请求如果从primary节点读会读到refresh segment + commit segment的内容，如果从replica中读会读到临时目录 + commit segment的内容。</p>
<p>这种架构解决了原生架构的一些问题：</p>
<ul>
<li>降低了写请求的延时，因为现在的refresh segment到临时目录的复制没有通过网络传输，直接是同一文件系统中的复制，所以大大降低了主备延时。（据阿里所说从分钟级降低到了毫秒级，但是原生架构也没有分钟级这么夸张吧…）</li>
<li>commit segment只会保存一份，所以不会因为副本数量过多而导致集群的存储成本上升</li>
<li>因为计算与存储分离，当出现主节点故障需要主副切换时，不需要长时间的拷贝全量数据，一个新的副节点启动以后，只要指向原来的临时目录即可</li>
</ul>
<p>但是也引入了一些新的问题：</p>
<ul>
<li>由于现在是共享内存，所以refresh操作多了传输成本，并且在NFS的速度也低于原本机内存中的速度，所以这里的成本有提高。不过应该是小于主从复制的性能提升。</li>
<li>引入了一些传统共享内存型分布式的问题，比如脑裂，双写等。不过在PPT中也看到阿里也实现了IO fencing来避免主从切换时带来的双写问题。</li>
</ul>
<p>下面再简单介绍一下演讲中讲到的主从复制的优化，下面是给出的示意图👇：<br><img src="/images/a6-3.png" alt="a6-3"><br>阿里说是使用了luence-replicator框架进行实现，我现在还没仔细阅读，有兴趣的可以看看<a href="http://shaierera.blogspot.com/2013/05/the-replicator.html" target="_blank" rel="noopener">Code Reduction: The Replicator</a><br>所以我下面的解释主要基于他们的演讲以及一些猜测：<br>在主从复制过程当中，主节点会定时的对meta进行快照，比如生成了图中的snapshot4，然后对它增加引用计数，再发送给从节点。从节点会和自己的快照进行比对，找到落后了多少个版本。将缺少的segment复制到临时目录当中，复制完成以后就可以通知primary节点复制结束，从而减少同步前从节点快照版本的引用计数，删除引用计数为0的文件。</p>
<p>其中还提到了一些针对segment merge的优化，那么还是先介绍一些什么是segment merge：<br>因为每秒都会进行<code>refresh</code>操作，生成一个小的segment文件，这些小的文件对内存的利用率是非常低的，而且每次query请求来的时候都会轮训这些小的segment文件，所以文件数量越多性能越差。elasticsearch会在后台进行异步的合并操作，从小的segment合并成大的segment，并且在合并阶段处理文件的删除和更新。</p>
<p>那么优化的部分是什么呢？就是在合并成大的segment以后会立即进行<code>flush</code>操作，来保证大的segment不会出现在主从复制当中。从而进一步的对主从复制进行提速。</p>
<h2 id="优化索引速度"><a href="#优化索引速度" class="headerlink" title="优化索引速度"></a>优化索引速度</h2><h3 id="离线"><a href="#离线" class="headerlink" title="离线"></a>离线</h3><p>离线全量写入一直是一个痛点问题，传统解决办法是维护两个elasticsearch集群，正常使用A集群，然后收集A集群的translog，并将全量快照写入B集群，完成以后回放translog，保证两边数据一致。完成后从A集群切到B集群，这样的维护成本是非常高的，并且全量快照写入的时间又非常的长。</p>
<p>阿里云针对这个点进行的优化是取消了translog，使用blink checkpoint天生的at least once的语义来保证故障恢复，相当于减少了一半的写工作量。但是这样相当于在elasticsearch外面套上了一个blink，并且需要和外部的blink进行通信，系统复杂度又上升了一个等级（不过反正也是云服务，又不要我们自己做DBA）。第二个是在segment合并上增加了一个limit，只有合并后达到一定的大小才会<code>flush</code>到磁盘当中，这样可以减少磁盘里的小segment再被读入到内存中进行反复的合并，减小IO次数。</p>
<p>前两个我觉得都是较小的优化，第三个优化比较大，如下图👇：<br><img src="/images/a6-4.png" alt="a6-4"><br>优化的核心点是利用更高的并发提前计算好索引，直接让线上的elasticsearch集群来load索引。具体怎么做的呢，就是利用blink的流计算能力来取代client node的计算数据分片能力，然后模拟process，build，merge三个操作并将其分布式化，让这三个操作都可以进行水平扩展，让索引能力可以随着计算资源的提升而提升。原来如果想提高索引的计算能力，是需要对elasticsearch集群的资源进行拓展，但是现在将索引计算的步骤分离了出来，转变成了一个经典分布式计算框架能解决的问题。最后放到OSS当中，让线上的模型进行load。类似的优化之前也有人已经尝试过，有兴趣可以看看<a href="https://elasticsearch.cn/slides/217#page=5" target="_blank" rel="noopener">基于Hadoop快速构建离线elasticsearch索引</a></p>
<h3 id="在线"><a href="#在线" class="headerlink" title="在线"></a>在线</h3><p>在线增量导入的优化也是将client node路由计算的能力放到了blink上，因为他们发现在大数据增量导入的时候，瓶颈出现在了CPU上，所以将计算部分外移，并且blink可以更好的进行针对计算的弹性升缩。</p>
<p>参考材料：<br><a href="https://zhuanlan.zhihu.com/p/33375126" target="_blank" rel="noopener">从Elasticsearch来看分布式系统架构设计 - 知乎</a><br><a href="https://blog.csdn.net/laoyang360/article/details/84727820" target="_blank" rel="noopener">Elasticsearch写入原理深入详解 - 铭毅天下（公众号同名） - CSDN博客</a><br><a href="https://blog.csdn.net/lsgqjh/article/details/83022206" target="_blank" rel="noopener">Elasticsearch 之 commit point | Segment | refresh | flush 索引分片内部原理 - 舒哥的blog - CSDN博客</a></p>

	
	</div>
  <a type="button" href="/2019/09/28/a6/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/05/11/a5/" >RATE LIMIT FOR MONGOSPARK WRITER</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-05-11  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近迁移数据库的时候发现了一个问题，相信也是很多 MongoDB 使用者都会遇到的问题。我在使用 MongoSpark 批量的写入数据的时候会造成严重的数据库抖动。主要的原因是现在大多 MongoDB 的配置都是 replica set 模式，这样写操作只会到 Master 节点上，写操作就会成为整个系统的瓶颈，大量的写操作会使 Master 节点的读操作变慢，并且会让 secondary 节点同步速度变慢，从而出现从 secondary 节点上读到老数据的问题。</p>
<p>而通过对 MongoDB 进行 shard 是一个代价非常昂贵且只能线性提高写吞吐的方法，非常的不经济实惠。所以我们也只能牺牲速率来保证线上服务的稳定。所以解决方案就是在 MongoSpark 中添加上写限速功能。</p>
<h2 id="Guava-RateLimiter"><a href="#Guava-RateLimiter" class="headerlink" title="Guava.RateLimiter"></a>Guava.RateLimiter</h2><p>选择的限速器是 Guava 提供的令牌桶。算法的原理很简单，会定时的向桶中放置令牌，服务只有获得令牌以后才能进行后续的操作，比如希望对一个服务进行每秒10次的限速，那么每秒中就会向桶中放置10个令牌。而获取的方式有两种，一种是阻塞等待令牌或者取不到令牌直接返回失败。</p>
<p>那么下面就简单的介绍一下API，主要是分两个动作，创建桶和获取令牌：</p>
<p><strong>创建令牌桶</strong> </p>
<ul>
<li><code>RateLimiter create(double permitsPerSecond)</code>: 根据一个稳定的速率创建令牌桶，也就是每秒插入 permitsPerSecond 个令牌。</li>
<li><code>RateLimiter create(double permitsPerSecond, long warmupPeriod, TimeUnit unit)</code>: 通过一个预热时间段达到稳定的速率创建令牌桶，在 warmupPeriod 这段时间内每秒令牌数量平稳的爬升至 permitsPerSecond，而后保持稳定。这里的速率也是值每秒插入 permitsPerSecond 个令牌。</li>
</ul>
<p><strong>获取令牌</strong></p>
<ul>
<li><code>void acquire()</code>: 获取一个令牌，会一直阻塞等待直到拿到。</li>
<li><code>void acquire(int permits)</code>: 获取 permits 个令牌，会一直阻塞等到直到全部拿到。</li>
<li><code>boolean tryAcquire()</code>: 获取一个令牌，成功则返回 true，失败直接返回 false。</li>
<li><code>boolean tryAcquire(long timeout, TimeUnit unit)</code>: 获取一个令牌，成功则返回 true，没有足够的令牌时等到 timeout 时间，如果还没有则返回 false。</li>
<li><code>boolean tryAcquire(int permits)</code>: 获取 permits 个令牌，成功则返回 true，失败直接返回 false。</li>
<li><code>boolean tryAcquire(int permits, long timeout, TimeUnit unit)</code>: 获取 permits 个令牌，成功则返回 true，没有足够的令牌时等到 timeout 时间，如果还没有则返回 false。</li>
</ul>
<p>通过上面的API可以很灵活的对 RateLimiter 进行使用，但是在阅读源码的过程中，我也发现了 Guava 的实现中有一个不尽如人意的地方。那就是限制能力只能在每秒多少个令牌桶，但是我想实现将少一秒的剩余令牌留给下一秒继续用，也就是几秒甚至更高时间单位的限流是不行的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Bursty</span> <span class="keyword">extends</span> <span class="title">RateLimiter</span> </span>&#123;</span><br><span class="line">    Bursty(RateLimiter.SleepingTicker ticker) &#123;</span><br><span class="line">        <span class="keyword">super</span>(ticker, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">doSetRate</span><span class="params">(<span class="keyword">double</span> permitsPerSecond, <span class="keyword">double</span> stableIntervalMicros)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span> oldMaxPermits = <span class="keyword">this</span>.maxPermits;</span><br><span class="line">        <span class="keyword">this</span>.maxPermits = permitsPerSecond;</span><br><span class="line">        <span class="keyword">this</span>.storedPermits = oldMaxPermits == <span class="number">0.0</span>D ? <span class="number">0.0</span>D : <span class="keyword">this</span>.storedPermits * <span class="keyword">this</span>.maxPermits / oldMaxPermits;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">storedPermitsToWaitTime</span><span class="params">(<span class="keyword">double</span> storedPermits, <span class="keyword">double</span> permitsToTake)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0L</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面的代码中，<code>Bursty</code> 就是始终保持平稳速率的令牌桶类，其中 <code>maxPermits</code> 是桶中最多有多少的令牌，<code>storedPermits</code> 是现在桶中的令牌个数。可以看到<code>maxPermits</code> 始终等于 <code>permitsPerSecond</code>，是不能乘上时间系数的，并且在重新设置 <code>maxPermits</code> 后会按照比例缩放之前的桶中令牌数量。</p>
<h2 id="MongoSpark-save"><a href="#MongoSpark-save" class="headerlink" title="MongoSpark.save"></a>MongoSpark.save</h2><p><code>save()</code> 方法是我们需要修改的主要方法，但是在 MongoSpark 中又存在多种的 save 方法，我们需要分别为这些 save 方法加上限流功能，或者你已经很明确将使用的函数。</p>
<p>在这之前，我们需要做一些准备工作，既然要限流，那我们肯定需要一个参数来控制流速，而在 MongoSpark 中是有一个配置类供我们设置参数的，我们需要修改一下 <code>WriteConfig</code> 这个类。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Write Configuration for writes to MongoDB</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param databaseName       the database name</span></span><br><span class="line"><span class="comment"> * @param collectionName     the collection name</span></span><br><span class="line"><span class="comment"> * @param connectionString   the optional connection string used in the creation of this configuration.</span></span><br><span class="line"><span class="comment"> * @param replaceDocument    replaces the whole document, when saving a Dataset that contains an `_id` field.</span></span><br><span class="line"><span class="comment"> *                           If false only updates / sets the fields declared in the Dataset.</span></span><br><span class="line"><span class="comment"> * @param maxBatchSize       the maxBatchSize when performing a bulk update/insert. Defaults to 512.</span></span><br><span class="line"><span class="comment"> * @param localThreshold     the local threshold in milliseconds used when choosing among multiple MongoDB servers to send a request.</span></span><br><span class="line"><span class="comment"> *                           Only servers whose ping time is less than or equal to the server with the fastest ping time plus the local</span></span><br><span class="line"><span class="comment"> *                           threshold will be chosen.</span></span><br><span class="line"><span class="comment"> * @param writeConcernConfig the write concern configuration</span></span><br><span class="line"><span class="comment"> * @param shardKey           an optional shardKey in extended json form: `"&#123;key: 1, key2: 1&#125;"`. Used when upserting DataSets in sharded clusters.</span></span><br><span class="line"><span class="comment"> * @param forceInsert        if true forces the writes to be inserts, even if a Dataset contains an `_id` field. Default `false`.</span></span><br><span class="line"><span class="comment"> * @param ordered            configures the bulk operation ordered property. Defaults to true.</span></span><br><span class="line"><span class="comment"> * @param secondLatch        the maxBatchSize when performing a bulk update/insert per second per partition.</span></span><br><span class="line"><span class="comment"> * @since 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">WriteConfig</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    databaseName:       <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    collectionName:     <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    connectionString:   <span class="type">Option</span>[<span class="type">String</span>]     = <span class="type">None</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    replaceDocument:    <span class="type">Boolean</span>            = <span class="type">WriteConfig</span>.<span class="type">DefaultReplaceDocument</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    maxBatchSize:       <span class="type">Int</span>                = <span class="type">WriteConfig</span>.<span class="type">DefaultMaxBatchSize</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    localThreshold:     <span class="type">Int</span>                = <span class="type">MongoSharedConfig</span>.<span class="type">DefaultLocalThreshold</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    writeConcernConfig: <span class="type">WriteConcernConfig</span> = <span class="type">WriteConcernConfig</span>.<span class="type">Default</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    shardKey:           <span class="type">Option</span>[<span class="type">String</span>]     = <span class="type">None</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    forceInsert:        <span class="type">Boolean</span>            = <span class="type">WriteConfig</span>.<span class="type">DefaultForceInsert</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    ordered:            <span class="type">Boolean</span>            = <span class="type">WriteConfig</span>.<span class="type">DefautOrdered</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    secondLatch:        <span class="type">Option</span>[<span class="type">Int</span>]        = <span class="type">None</span></span></span></span><br><span class="line"><span class="class"><span class="params"></span>) <span class="keyword">extends</span> <span class="title">MongoCollectionConfig</span> <span class="keyword">with</span> <span class="title">MongoClassConfig</span> </span>&#123;</span><br><span class="line">  require(maxBatchSize &gt;= <span class="number">1</span>, <span class="string">s"maxBatchSize (<span class="subst">$maxBatchSize</span>) must be greater or equal to 1"</span>)</span><br><span class="line">  require(localThreshold &gt;= <span class="number">0</span>, <span class="string">s"localThreshold (<span class="subst">$localThreshold</span>) must be greater or equal to 0"</span>)</span><br><span class="line">  require(<span class="type">Try</span>(connectionString.map(uri =&gt; <span class="keyword">new</span> <span class="type">ConnectionString</span>(uri))).isSuccess, <span class="string">s"Invalid uri: '<span class="subst">$&#123;connectionString.get&#125;</span>'"</span>)</span><br><span class="line">  require(<span class="type">Try</span>(shardKey.map(json =&gt; <span class="type">BsonDocument</span>.parse(json))).isSuccess, <span class="string">s"Invalid shardKey: '<span class="subst">$&#123;shardKey.get&#125;</span>'"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">Self</span> </span>= <span class="type">WriteConfig</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">withOption</span></span>(key: <span class="type">String</span>, value: <span class="type">String</span>): <span class="type">WriteConfig</span> = <span class="type">WriteConfig</span>(<span class="keyword">this</span>.asOptions + (key -&gt; value))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">withOptions</span></span>(options: collection.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">WriteConfig</span> = <span class="type">WriteConfig</span>(options, <span class="type">Some</span>(<span class="keyword">this</span>))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">asOptions</span></span>: collection.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> options = mutable.<span class="type">Map</span>(<span class="string">"database"</span> -&gt; databaseName, <span class="string">"collection"</span> -&gt; collectionName,</span><br><span class="line">      <span class="type">WriteConfig</span>.replaceDocumentProperty -&gt; replaceDocument.toString,</span><br><span class="line">      <span class="type">WriteConfig</span>.localThresholdProperty -&gt; localThreshold.toString,</span><br><span class="line">      <span class="type">WriteConfig</span>.forceInsertProperty -&gt; forceInsert.toString) ++ writeConcernConfig.asOptions</span><br><span class="line">    connectionString.map(uri =&gt; options += (<span class="type">WriteConfig</span>.mongoURIProperty -&gt; uri))</span><br><span class="line">    shardKey.map(json =&gt; options += (<span class="type">WriteConfig</span>.shardKeyProperty -&gt; json))</span><br><span class="line">    secondLatch.map(number =&gt; options += (<span class="type">WriteConfig</span>.secondLatchProperty -&gt; number.toString))</span><br><span class="line">    options.toMap</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">withOptions</span></span>(options: util.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]): <span class="type">WriteConfig</span> = withOptions(options.asScala)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">asJavaOptions</span></span>: util.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = asOptions.asJava</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * The `WriteConcern` that this config represents</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @return the WriteConcern</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">writeConcern</span></span>: <span class="type">WriteConcern</span> = writeConcernConfig.writeConcern</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这是修改以后的 <code>WriteConfig</code> 类代码，我们添加上了一个 <code>secondLatch</code> 的参数作为流速控制参数。在使用的时候可以：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> writeConfig = <span class="keyword">new</span> <span class="type">WriteConfig</span>(conf.mongoDatabase, conf.mongoCollection)</span><br><span class="line">  .withOption(<span class="type">WriteConfig</span>.replaceDocumentProperty, conf.replaceDocument.toString)</span><br><span class="line">  .withOption(<span class="type">WriteConfig</span>.mongoURIProperty, conf.mongoUri)</span><br><span class="line">  .withOption(<span class="type">WriteConfig</span>.secondLatchProperty, conf.secondLatch.toString)</span><br></pre></td></tr></table></figure>

<p>通过 <code>withOption()</code> 的方法设定 <code>secondLatch</code> 参数，然后我们跟踪一下上面的 <code>withOption()</code> 方法的实现，是通过一个 <code>WriteConfig(options: util.Map[String, String])</code> 的构造函数进行了构造。所以也需要修改这个函数的实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(options: collection.<span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>], <span class="keyword">default</span>: <span class="type">Option</span>[<span class="type">WriteConfig</span>]): <span class="type">WriteConfig</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanedOptions = stripPrefix(options)</span><br><span class="line">  <span class="keyword">val</span> cachedConnectionString = connectionString(cleanedOptions)</span><br><span class="line">  <span class="keyword">val</span> defaultDatabase = <span class="keyword">default</span>.map(conf =&gt; conf.databaseName).orElse(<span class="type">Option</span>(cachedConnectionString.getDatabase))</span><br><span class="line">  <span class="keyword">val</span> defaultCollection = <span class="keyword">default</span>.map(conf =&gt; conf.collectionName).orElse(<span class="type">Option</span>(cachedConnectionString.getCollection))</span><br><span class="line"></span><br><span class="line">  <span class="type">WriteConfig</span>(</span><br><span class="line">    databaseName = databaseName(databaseNameProperty, cleanedOptions, defaultDatabase),</span><br><span class="line">    collectionName = collectionName(collectionNameProperty, cleanedOptions, defaultCollection),</span><br><span class="line">    connectionString = cleanedOptions.get(mongoURIProperty).orElse(<span class="keyword">default</span>.flatMap(conf =&gt; conf.connectionString)),</span><br><span class="line">    replaceDocument = getBoolean(cleanedOptions.get(replaceDocumentProperty), <span class="keyword">default</span>.map(conf =&gt; conf.replaceDocument),</span><br><span class="line">      defaultValue = <span class="type">DefaultReplaceDocument</span>),</span><br><span class="line">    maxBatchSize = getInt(cleanedOptions.get(maxBatchSizeProperty), <span class="keyword">default</span>.map(conf =&gt; conf.maxBatchSize),</span><br><span class="line">      <span class="type">DefaultMaxBatchSize</span>),</span><br><span class="line">    localThreshold = getInt(cleanedOptions.get(localThresholdProperty), <span class="keyword">default</span>.map(conf =&gt; conf.localThreshold),</span><br><span class="line">      <span class="type">MongoSharedConfig</span>.<span class="type">DefaultLocalThreshold</span>),</span><br><span class="line">    writeConcernConfig = <span class="type">WriteConcernConfig</span>(cleanedOptions, <span class="keyword">default</span>.map(writeConf =&gt; writeConf.writeConcernConfig)),</span><br><span class="line">    shardKey = cleanedOptions.get(shardKeyProperty).orElse(<span class="keyword">default</span>.flatMap(conf =&gt; conf.shardKey).orElse(<span class="type">None</span>)),</span><br><span class="line">    forceInsert = getBoolean(cleanedOptions.get(forceInsertProperty), <span class="keyword">default</span>.map(conf =&gt; conf.forceInsert),</span><br><span class="line">      defaultValue = <span class="type">DefaultForceInsert</span>),</span><br><span class="line">    ordered = getBoolean(cleanedOptions.get(orderedProperty), <span class="keyword">default</span>.map(conf =&gt; conf.ordered), <span class="type">DefautOrdered</span>),</span><br><span class="line">	  <span class="comment">// 流速控制参数</span></span><br><span class="line">    secondLatch = cleanedOptions</span><br><span class="line">      .get(secondLatchProperty).orElse(<span class="keyword">default</span>.flatMap(conf =&gt; <span class="type">Try</span>(conf.secondLatch.toString).toOption).orElse(<span class="type">None</span>))</span><br><span class="line">      .flatMap(s =&gt; <span class="type">Try</span>(s.toInt).toOption)</span><br><span class="line">  )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到这个构造函数调用的是一个要传递所有参数的构造函数进行构造的，所以我们还需要实现这样一个传递所有参数的构造函数，然后加上：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">secondLatch = cleanedOptions</span><br><span class="line">      .get(secondLatchProperty).orElse(<span class="keyword">default</span>.flatMap(conf =&gt; <span class="type">Try</span>(conf.secondLatch.toString).toOption).orElse(<span class="type">None</span>))</span><br><span class="line">      .flatMap(s =&gt; <span class="type">Try</span>(s.toInt).toOption)</span><br></pre></td></tr></table></figure>

<p>由于 <code>options</code> 的 value 都是字符串，所以这边需要转一下 <code>Int</code>，传递所有参数的构造函数如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Creates a WriteConfig</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * @param databaseName      the database name</span></span><br><span class="line"><span class="comment">  * @param collectionName    the collection name</span></span><br><span class="line"><span class="comment">  * @param connectionString  the optional connection string used in the creation of this configuration</span></span><br><span class="line"><span class="comment">  * @param replaceDocument   replaces the whole document, when saving a Dataset that contains an `_id` field.</span></span><br><span class="line"><span class="comment">  *                          If false only updates / sets the fields declared in the Dataset.</span></span><br><span class="line"><span class="comment">  * @param maxBatchSize      the maxBatchSize when performing a bulk update/insert. Defaults to 512.</span></span><br><span class="line"><span class="comment">  * @param localThreshold    the local threshold in milliseconds used when choosing among multiple MongoDB servers to send a request.</span></span><br><span class="line"><span class="comment">  *                          Only servers whose ping time is less than or equal to the server with the fastest ping time plus the local</span></span><br><span class="line"><span class="comment">  *                          threshold will be chosen.</span></span><br><span class="line"><span class="comment">  * @param writeConcern      the WriteConcern to use</span></span><br><span class="line"><span class="comment">  * @param shardKey          an optional shardKey in extended form: `"&#123;key: 1, key2: 1&#125;"`. Used when upserting DataSets in sharded clusters.</span></span><br><span class="line"><span class="comment">  * @param forceInsert       if true forces the writes to be inserts, even if a Dataset contains an `_id` field. Default `false`.</span></span><br><span class="line"><span class="comment">  * @param ordered           configures if the bulk operation is ordered property.</span></span><br><span class="line"><span class="comment">  * @param secondLatch       the maxBatchSize when performing a bulk update/insert per second per partition.</span></span><br><span class="line"><span class="comment">  * @return the write config</span></span><br><span class="line"><span class="comment">  * @since jike-1.0.0</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(databaseName: <span class="type">String</span>, collectionName: <span class="type">String</span>, connectionString: <span class="type">Option</span>[<span class="type">String</span>], replaceDocument: <span class="type">Boolean</span>, maxBatchSize: <span class="type">Int</span>,</span><br><span class="line">          localThreshold: <span class="type">Int</span>, writeConcern: <span class="type">WriteConcern</span>, shardKey: <span class="type">Option</span>[<span class="type">String</span>], forceInsert: <span class="type">Boolean</span>, ordered: <span class="type">Boolean</span>, secondLatch: <span class="type">Option</span>[<span class="type">Int</span>]): <span class="type">WriteConfig</span> = &#123;</span><br><span class="line">  apply(databaseName, collectionName, connectionString, replaceDocument, maxBatchSize, localThreshold, <span class="type">WriteConcernConfig</span>(writeConcern),</span><br><span class="line">    shardKey, forceInsert, ordered, secondLatch)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用 <code>case class</code> 提供的默认构造函数进行构造，至此我们就能愉快的对包含 <code>secondLatch</code> 字段的 <code>WriteConfig</code> 进行构造了。</p>
<h3 id="Save-Method"><a href="#Save-Method" class="headerlink" title="Save Method"></a>Save Method</h3><p>然后我们就需要分别对多个 <code>save()</code> 添加限速器，原理都大同小异，就是在 <code>foreachPartition</code> 的函数中构建令牌桶，然后在 <code>foreach</code> 的写Mongodb 函数之前进行阻塞的令牌获取，这里就展示常用的 Datasets 和 RDD 类型 save 方法的修改：</p>
<p><strong>save[D] (dataset: Dataset[D]): Unit</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Save data to MongoDB</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * '''Note:''' If the dataFrame contains an `_id` field the data will upserted and replace any existing documents in the collection.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param dataset the dataset to save to MongoDB</span></span><br><span class="line"><span class="comment"> * @param writeConfig the writeConfig</span></span><br><span class="line"><span class="comment"> * @tparam D</span></span><br><span class="line"><span class="comment"> * @since 1.1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span></span>[<span class="type">D</span>](dataset: <span class="type">Dataset</span>[<span class="type">D</span>], writeConfig: <span class="type">WriteConfig</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> mongoConnector = <span class="type">MongoConnector</span>(writeConfig.asOptions)</span><br><span class="line">  <span class="keyword">val</span> dataSet = dataset.toDF()</span><br><span class="line">  <span class="keyword">val</span> mapper = rowToDocumentMapper(dataSet.schema)</span><br><span class="line">  <span class="keyword">val</span> documentRdd: <span class="type">RDD</span>[<span class="type">BsonDocument</span>] = dataSet.rdd.map(row =&gt; mapper(row))</span><br><span class="line">  <span class="keyword">val</span> fieldNames = dataset.schema.fieldNames.toList</span><br><span class="line">  <span class="keyword">val</span> queryKeyList = <span class="type">BsonDocument</span>.parse(writeConfig.shardKey.getOrElse(<span class="string">"&#123;_id: 1&#125;"</span>)).keySet().asScala.toList</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (writeConfig.forceInsert || !queryKeyList.forall(fieldNames.contains(_))) &#123;</span><br><span class="line">    <span class="type">MongoSpark</span>.save(documentRdd, writeConfig)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    documentRdd.foreachPartition(iter =&gt; <span class="keyword">if</span> (iter.nonEmpty) &#123;</span><br><span class="line">		<span class="comment">// **INIT RateLimiter</span></span><br><span class="line">      <span class="keyword">var</span> rateLimiter: <span class="type">Option</span>[<span class="type">RateLimiter</span>] = <span class="type">None</span></span><br><span class="line">      <span class="keyword">if</span> (writeConfig.secondLatch.isDefined) &#123;</span><br><span class="line">        <span class="comment">// If secondLatch &lt; maxBatchSize, it will destroy rate limit rule.</span></span><br><span class="line">        <span class="keyword">val</span> permitSize = <span class="keyword">if</span> (writeConfig.secondLatch.get &gt;= writeConfig.maxBatchSize) (writeConfig.secondLatch.get / writeConfig.maxBatchSize).floor <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        rateLimiter = <span class="type">Option</span>.apply(<span class="type">RateLimiter</span>.create(permitSize))</span><br><span class="line">      &#125;</span><br><span class="line">      mongoConnector.withCollectionDo(writeConfig, &#123; collection: <span class="type">MongoCollection</span>[<span class="type">BsonDocument</span>] =&gt;</span><br><span class="line">        iter.grouped(writeConfig.maxBatchSize).foreach(batch =&gt; &#123;</span><br><span class="line">			<span class="comment">// **Acquire</span></span><br><span class="line">          <span class="keyword">if</span> (rateLimiter.isDefined) &#123;</span><br><span class="line">            rateLimiter.get.acquire(<span class="number">1</span>)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">val</span> requests = batch.map(doc =&gt;</span><br><span class="line">            <span class="keyword">if</span> (queryKeyList.forall(doc.containsKey(_))) &#123;</span><br><span class="line">              <span class="keyword">val</span> queryDocument = <span class="keyword">new</span> <span class="type">BsonDocument</span>()</span><br><span class="line">              queryKeyList.foreach(key =&gt; queryDocument.append(key, doc.get(key)))</span><br><span class="line">              <span class="keyword">if</span> (writeConfig.replaceDocument) &#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="type">ReplaceOneModel</span>[<span class="type">BsonDocument</span>](queryDocument, doc, <span class="keyword">new</span> <span class="type">ReplaceOptions</span>().upsert(<span class="literal">true</span>))</span><br><span class="line">              &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                queryDocument.keySet().asScala.foreach(doc.remove(_))</span><br><span class="line">                <span class="keyword">new</span> <span class="type">UpdateOneModel</span>[<span class="type">BsonDocument</span>](queryDocument, <span class="keyword">new</span> <span class="type">BsonDocument</span>(<span class="string">"$set"</span>, doc), <span class="keyword">new</span> <span class="type">UpdateOptions</span>().upsert(<span class="literal">true</span>))</span><br><span class="line">              &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              <span class="keyword">new</span> <span class="type">InsertOneModel</span>[<span class="type">BsonDocument</span>](doc)</span><br><span class="line">            &#125;)</span><br><span class="line">          collection.bulkWrite(requests.toList.asJava, <span class="keyword">new</span> <span class="type">BulkWriteOptions</span>().ordered(writeConfig.ordered))</span><br><span class="line">        &#125;)</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>save[D: ClassTag] (rdd: RDD[D]): Unit</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Save data to MongoDB</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param rdd the RDD data to save to MongoDB</span></span><br><span class="line"><span class="comment"> * @param writeConfig the writeConfig</span></span><br><span class="line"><span class="comment"> * @tparam D the type of the data in the RDD</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span></span>[<span class="type">D</span>: <span class="type">ClassTag</span>](rdd: <span class="type">RDD</span>[<span class="type">D</span>], writeConfig: <span class="type">WriteConfig</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> mongoConnector = <span class="type">MongoConnector</span>(writeConfig.asOptions)</span><br><span class="line">  rdd.foreachPartition(iter =&gt; <span class="keyword">if</span> (iter.nonEmpty) &#123;</span><br><span class="line">    <span class="comment">// **INIT RateLimiter</span></span><br><span class="line">    <span class="keyword">var</span> rateLimiter: <span class="type">Option</span>[<span class="type">RateLimiter</span>] = <span class="type">None</span></span><br><span class="line">    <span class="keyword">if</span> (writeConfig.secondLatch.isDefined) &#123;</span><br><span class="line">      <span class="comment">// If secondLatch &lt; maxBatchSize, it will destroy rate limit rule.</span></span><br><span class="line">      <span class="keyword">val</span> permitSize = <span class="keyword">if</span> (writeConfig.secondLatch.get &gt;= writeConfig.maxBatchSize) (writeConfig.secondLatch.get / writeConfig.maxBatchSize).floor <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">      rateLimiter = <span class="type">Option</span>.apply(<span class="type">RateLimiter</span>.create(permitSize))</span><br><span class="line">    &#125;</span><br><span class="line">    mongoConnector.withCollectionDo(writeConfig, &#123; collection: <span class="type">MongoCollection</span>[<span class="type">D</span>] =&gt;</span><br><span class="line">      iter.grouped(writeConfig.maxBatchSize).foreach(batch =&gt; &#123;</span><br><span class="line">		  <span class="comment">// **Acquire</span></span><br><span class="line">        <span class="keyword">if</span> (rateLimiter.isDefined) &#123;</span><br><span class="line">          rateLimiter.get.acquire(<span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        collection.insertMany(</span><br><span class="line">          batch.toList.asJava,</span><br><span class="line">          <span class="keyword">new</span> <span class="type">InsertManyOptions</span>().ordered(writeConfig.ordered)</span><br><span class="line">        )</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>需要注意的是不要在 Driver 上去初始化 <code>RateLimiter</code>，还要注意与 WriteConfig 中已存在的 <code>maxBatchSize</code> 参数的关系。</p>
<p>到这里就能愉快的进行限速了。</p>

	
	</div>
  <a type="button" href="/2019/05/11/a5/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/04/06/a13/" >FROM BIGTABLE TO DRUID</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-04-06  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>最近在学习 <code>Druid</code>，索性整理了一下从 Google 的 BigTable 论文衍生出的这一系列数据产品架构思路。该文章中通过对 BigTable 文章的介绍到 Hbase 再到 Druid，读者会发现这三者非常的相似，但是又由于不同的使用场景而做了其他的优化。由于作者也是初学者，所以多是对网上文章的整理汇总，也算初有脉络，但是总的来说还是一篇纸上谈兵的文章，仅作为对学习的记录。之后应该会在分布式系统上有更多的实战文章。</p>
<h1 id="BigTable"><a href="#BigTable" class="headerlink" title="BigTable"></a>BigTable</h1><p><code>Bigtable</code> 是一个分布式的结构化数据存储系统，它被设计用来处理海量数据。</p>
<p>这是论文开篇的概括，也作为这篇博客的开始吧。</p>
<h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(row: string, column: string, time: int64) -&gt; string</span><br></pre></td></tr></table></figure>

<p><img src="/images/a-13-1.png" alt="a-13-1"></p>
<p>整个 <code>BigTable</code> 的数据模型可以看作是一个很简单的映射，分别是 row，cloumn，time 到一个具体数据的映射。如上图是一个简单的例子，行名是一个反向 URL。contents 列族存放的是网页的内容，anchor 列族存放引用该网页的锚链接文本。 CNN 的主页被 Sports Illustrator 和 MY-look 的主页引用，因此该行包含了名为 <code>anchor:cnnsi.com</code> 和 <code>anchhor:my.look.ca</code> 的列。每个锚链接只有一个版本，而 contents 列则有三个版本，分别由时间戳 t3，t5 和 t6 标识，最新的时间戳会放在最前面。</p>
<h2 id="架构组件"><a href="#架构组件" class="headerlink" title="架构组件"></a>架构组件</h2><p>这整个系统当中主要有三部分的组件，分别是 Master 服务器，Tablet 服务器和 Chubby 服务器构成。在后面对其他框架的介绍当中，会发现基础架构有很高的相似性。</p>
<h3 id="Master-服务器（控制者）"><a href="#Master-服务器（控制者）" class="headerlink" title="Master 服务器（控制者）"></a>Master 服务器（控制者）</h3><p>主要工作：</p>
<ul>
<li>为 Tablet 服务器分配 Tablets。</li>
<li>检测新加入的或者过期失效的 Tablet 服务器。</li>
<li>对 Tablet 服务器进行负载均衡、以及对保存在 GFS 上的文件进行垃圾收集。</li>
<li>除此之外，它还处理对模 式的相关修改操作，例如建立表和列族。</li>
</ul>
<h3 id="Tablet-服务器（工作者）"><a href="#Tablet-服务器（工作者）" class="headerlink" title="Tablet 服务器（工作者）"></a>Tablet 服务器（工作者）</h3><p>主要工作：管理一个 Tablet 的集合（通常每个服务器有大约数十个至上千个 Tablet）。每个 Tablet 服务器负责处理它所加载的 Tablet 的读写操作，以及在 Tablets 过大时，对其进行分割。</p>
<h3 id="Chubby（协调者）"><a href="#Chubby（协调者）" class="headerlink" title="Chubby（协调者）"></a>Chubby（协调者）</h3><p>在说 <code>Chubby</code> 之前想插入一个小话题，到底是什么是 <code>分布式一致性问题(Distributed consensus problem)</code> 。其实在接触分布式系统开始这个问题基本上在每一篇分布式系统的文章中都会被提及，但是在感性的认识下，我发现自己很难用简洁的语言进行概括，所以去查阅了一些文章，有一段是我很认同的简介描述：</p>
<p>在一个分布式系统中，有一组的 Process，他们需要确定一个 Value。于是每个 Process 都提出一个 Value， 一致性就是指只有其中的一个 Value 能够被选中作为最后确定的值，并且当这个值被选出来后，所有的 Process 都需要被通知到。</p>
<p>表面上看，这个问题很容易解决。比如设置一个server，所有的process都 向这个server提交一个Value，这个server可以通过一个简单的规则来挑选出一个Value（例如最先到达的Value被选中），然后由这个 server通知所有的Process。但是在分布式系统中，就会有各种的问题发生，例如，这个server崩溃了怎么办，所以我们可能需要有几台 server共同决定。还有，Process提交Value的时间都不一样，网络传输过程中由于延迟这些Value到达server的顺序也都没有保证。</p>
<p>有一个很具象的例子：</p>
<p>在Google File System(GFS) 中，有很多的server，这些server需要选举其中的一台作为master server。这其实是一个很典型的consensus问题，Value就是master server的地址。GFS就是用Chubby来解决的这个问题，所有的server通过Chubby提供的通信协议到Chubby server上创建同一个文件，当然，最终只有一个server能够获准创建这个文件，这个server就成为了master，它会在这个文件中写入自己 的地址，这样其它的server通过读取这个文件就能知道被选出的master的地址。</p>
<p>对应于 <code>Chubby</code> 就会有一个众所周知的开源项目 <code>Zookeeper</code>，两者从作用到架构上都非常的相似。但是又存在一些差别，文章后面会简单叙述一下两者的不同，不过可以类比 <code>Zookeeper</code> 来理解 <code>Chubby</code>。</p>
<p>前面说了这么多，那 <code>Chubby</code> 到底是一个什么服务。首先它是一个分布式的文件系统，可以提供机制使得 client 可以在 Chubby service 上创建文件和执行一些文件的基本操作。从更高一点的语义层面上。Chubby 是一个分布式的锁系统，“锁” 就是文件，加锁操作就是创建文件成功的那个 server 抢占到了 “锁”。用户通过打开、关闭和读取文件，获取共享锁或者独占锁；并且通过通信机制，向用户发送更新信息。</p>
<h3 id="Tablet（数据聚合单位）"><a href="#Tablet（数据聚合单位）" class="headerlink" title="Tablet（数据聚合单位）"></a>Tablet（数据聚合单位）</h3><h4 id="INDEX"><a href="#INDEX" class="headerlink" title="INDEX"></a>INDEX</h4><p><img src="/images/a-13-2.png" alt="a-13-2"></p>
<p>Index 是一个三层的B树，由于 Root tablet 不会分裂，所以永远是三层。真正的 Tablet 位置信息存储在第三层每一个行关键字下，而第二层只是对第三层的索引。Root tablet 储存在 Chubby 中。在客户端会缓存 Tablet 的位置信息，如果客户端没有缓存或者发现它的缓存地址不正确，就在树状的存储结构中递归的查询 Tablet 位置信息。如果客户端缓存是空的，那么需要三次寻址。如果是过期了则需要6次，3次是在缓存中寻找，3次是更新缓存。</p>
<h4 id="分配"><a href="#分配" class="headerlink" title="分配"></a>分配</h4><p>在任何一个时刻，一个Tablet 只能分配给一个Tablet服务器。Master服务器记录了当前有哪些活跃的 Tablet 服务器、哪些 Tablet 分配给了哪些 Tablet 服务器、哪些 Tablet 还没有被分配。当一个 Tablet 还没有被分配、 并且刚好有一个 Tablet 服务器有足够的空闲空间装载该 Tablet 时，Master 服务器会给这个 Tablet 服务器发送一个装载请求，把 Tablet 分配给这个服务器。</p>
<p>BigTable 使用 Chubby 跟踪记录 Tablet 服务器的状态。当一个 Tablet 服务器启动时，它在 Chubby 的一个 指定目录下建立一个有唯一性名字的文件，并且获取该文件的独占锁。Master 服务器实时监控着这个目录（服务器目录），因此 Master 服务器能够知道有新的 Tablet 服务器加入了。如果 Tablet 服务器丢失了 Chubby 上的独占锁，比如由于网络断开导致 Tablet 服务器和 Chubby 的会话丢失 — 它就停止对 Tablet 提供服务。（Chubby 提供了一种高效的机制，利用这种机制，Tablet 服务器能够在不增加网络负担的情况下知道它是否 还持有锁）。只要文件还存在，Tablet 服务器就会试图重新获得对该文件的独占锁；如果文件不存在了，那么 Tablet 服务器就不能再提供服务了，它会自行退出。</p>
<h4 id="冲写"><a href="#冲写" class="headerlink" title="冲写"></a>冲写</h4><p>在 BigTable 中一次写操作会先被记录在日志文件当中，然后被记入 <code>memtable</code> 中。这里 <code>memtable</code> 实际上就是一个写缓存，随着写操作的执行，<code>memtable</code> 的大小不断增加。当 <code>memtable</code> 的尺寸到达一个门限值的时候，这个 <code>memtable</code> 就会被冻结，然后创建一个新的 <code>memtable</code>；被冻结住 <code>memtable</code> 会被转换成 SSTable，然后写入 GFS。这个过程被称为 <code>Minor Compaction</code>， 它有两个目的：收缩 Tablet 服务器使用的内存，以及在服务器灾难恢复过程中，减少必须从 提交日志里读取的数据量。在 Compaction 过程中，正在进行的读写操作仍能继续。</p>
<p>而每一次 Minor Compaction 都会创建一个新的 SSTable。如果 Minor Compaction 过程不停滞的持续进行下去，读操作可能需要合并来自多个 SSTable 的更新。通过定期在后台执行 Tablet 的合并，来限制这类文件的数量，加速存储使用率和读速度，这个过程被称为 <code>Merging Compaction</code>。</p>
<p>这两个步骤在 BIGTABLE 系统中非常的重要，这也是在读写分离架构中，得以优化读写效率的根本，在后面其他系统的设计当中能也能看到类似的优化设计。</p>
<h4 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h4><p>Tablet 是逻辑层面的存储单元，而实际的存储单元是 SSTable，SSTable 是一个持久化的、排序的、不可更改的 Map 结构，而 Map 是一个 key-value 映射的数据结构，key 和 value 的值都是任意的 Byte 串。可以对 SSTable 进行如下的操作：查询与一个 key 值相关的 value，或者遍历某个 key 值范围内的所有的 key-value 对。从内 部看，SSTable 是一系列的数据块（通常每个块的大小是 64KB，这个大小是可以配置的）。SSTable 使用块索 引（通常存储在 SSTable 的最后）来定位数据块；在打开 SSTable 的时候，索引被加载到内存，来提高查询、读取效率。</p>
<h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><h2 id="HMaster"><a href="#HMaster" class="headerlink" title="HMaster"></a>HMaster</h2><p>没有单点故障问题，启动多个 HMaster，通过 Zookeeper 的 Master Election 机制保证同时只有一个 HMaster 处于 Active，其他处于热备份的状态，定期从 Active 的 Master 同步其最新状态。</p>
<p>主要作用：</p>
<ul>
<li>管理 HReigonServer，实现其负载均衡<ul>
<li>启动时HRegion的分配，以及负载均衡和修复时 HRegion 的重新分配</li>
<li>监控集群中所有 HRegionServer 的状态（通过 Heartbeat 和监听 Zookeeper 中的状态）</li>
</ul>
</li>
<li>管理和分配 HRegion</li>
<li>实现 DDL 操作 (Data Defintion Language, namespace 和 table 的增删改，column family的增删改等)</li>
<li>管理 namespace 和 table 的元数据</li>
<li>权限控制</li>
</ul>
<h2 id="HRegionServer（工作者"><a href="#HRegionServer（工作者" class="headerlink" title="HRegionServer（工作者)"></a>HRegionServer（工作者)</h2><p>HRegionServer一般和DataNode在同一台机器上运行，实现数据的本地性。</p>
<p>存放和管理本地HRegion。<br>读写HDFS，管理Table中的数据。<br>Client直接通过HRegionServer读写数据<br>可以发现 HRegionServer 的作用与 BigTable 中 Tablet 服务器的作用几乎一摸一样，下面介绍更多它内部的机制：</p>
<h3 id="WAL（WRITE-AHEAD-LOG）"><a href="#WAL（WRITE-AHEAD-LOG）" class="headerlink" title="WAL（WRITE AHEAD LOG）"></a>WAL（WRITE AHEAD LOG）</h3><p>所有的写操作都会保证将数据写入 LOG 文件以后，才会真正更新 MemStore（写缓存），最后写入 HFile 中。采用这种模式，可以保证HRegionServer宕机后，我们依然可以从该Log文件中读取数据，Replay所有的操作，而不至于数据丢失。这个Log文件会定期Roll出新的文件而删除旧的文件(那些已持久化到HFile中的Log可以删除)。</p>
<h3 id="BLOCKCACHE（读缓存）"><a href="#BLOCKCACHE（读缓存）" class="headerlink" title="BLOCKCACHE（读缓存）"></a>BLOCKCACHE（读缓存）</h3><p>基于分空间局部性和时间局部性原理，将数据预读取到内存中，以提升读性能。HBase 提供了两种 BlockCache 的实现，默认是 on-heap LRUBlockCache 和 BucketCache(off-heap)。通常BucketCache的性能要差于LruBlockCache，然而由于GC的影响，LruBlockCache的延迟会变的不稳定，而BucketCache由于是自己管理BlockCache，而不需要GC，因而它的延迟通常比较稳定，这也是有些时候需要选用BucketCache的原因。在 BlockCache 101 - Nick Dimiduk 中更加详细的对比。</p>
<h3 id="HSTORE（最小单位）"><a href="#HSTORE（最小单位）" class="headerlink" title="HSTORE（最小单位）"></a>HSTORE（最小单位）</h3><p><img src="/images/a-13-3.png" alt="a-13-3"></p>
<p>一个Table可以有一个或多个Region，他们可以在一个相同的HRegionServer上，也可以分布在不同的HRegionServer上，一个HRegionServer可以有多个HRegion，他们分别属于不同的Table。HRegion由多个Store(HStore)构成，每个HStore对应了一个Table在这个HRegion中的一个Column Family，即每个Column Family就是一个集中的存储单元，因而最好将具有相近IO特性的Column存储在一个Column Famil。</p>
<h4 id="MEMSTORE（写缓存）"><a href="#MEMSTORE（写缓存）" class="headerlink" title="MEMSTORE（写缓存）"></a>MEMSTORE（写缓存）</h4><p>所有数据的写在完成WAL日志写后，会 写入MemStore中，由MemStore根据一定的算法将数据Flush到地层HDFS文件中(HFile)，通常每个HRegion中的每个 Column Family有一个自己的MemStore。</p>
<ul>
<li>每一次Put/Delete请求都是先写入到MemStore中，当MemStore满后会Flush成一个新的StoreFile(底层实现是HFile)，即一个HStore(Column Family)可以有0个或多个StoreFile(HFile)。有以下三种情况可以触发MemStore的Flush动作，需要注意的是MEMSTORE的最小FLUSH单元是HREGION而不是单个MEMSTORE。</li>
<li>当一个HRegion中的所有MemStore的大小总和超过了size。当前 HRegion 下的所有 MemStore 进行 flush。</li>
<li>当全局MemStore的大小总和超过了size，当前 HRegionServer 下的所有 MemStore 进行 flush.</li>
<li>当前HRegionServer中WAL的大小超过了size，当前 HRegionServer 下的所有 MemStore 进行 flush。依照时间先后顺序，直到 WAL 少于 size。</li>
</ul>
<h3 id="HFILE"><a href="#HFILE" class="headerlink" title="HFILE"></a>HFILE</h3><p>用于存储HBase的数据。</p>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><p>在产品定位上，Zookeeper 是一个 <code>Distributed process coordinator</code> 而 Chubby 是一个 <code>Distributed lock service</code>。而高一致性与它的使用场景密切相关，由于 Chubby 主要处理少量的写更多的读操作的场景，提供粗力度的锁，所以是需要缓存的。而如果需要进行一次数据更新，Chubby 会先保证所有的缓存都进行更新以后才宣布这次更新完成。而这样的缓存机制在 Zookeeper 中是不存在的，所以当你在 Zookeeper 中进行数据更新，更新作用到 A 副本上，但是没来得及同步到 B 副本上是，就会出现 AB 副本数据不一致的情况。</p>
<p>而开源有开源的好处，在 Zookeeper 客户端上有 Apache 项目 <code>Curator</code> 进行了高度的封装，提供了这样的缓存机制，提升了 Zookeeper 的一致性等级。所以使用 Zookeeper 加上 Curator 的话是等于 Chubby 的。</p>
<p>下面再介绍一下它是如何在 HBase 中的作用：</p>
<ul>
<li>在HMaster和HRegionServer连接到ZooKeeper后创建Ephemeral节点，并使用Heartbeat机制维持这个节点的存活状态，如果某个Ephemeral节点实效，则HMaster会收到通知，并做相应的处理。<br>协调多个热备份的 HMaster 节点，通过监听 <code>/hbase/master</code> 来确认 Active Master 节点的状态，如果节点消失，则得到通知，并将自己转为 Activer HMaster。</li>
<li>Hbase 使用 RowKey 将表水平切割成多个 HRegion，每个 HRegion 都记录了它的 StartKey 和 EndKey，且有序。HRegion 由 HMaster 分配到相应的 HRegionServer 中，然后由 HRegionServer 复杂 HRegion 的启动和管理，和 Client 的通信，负责数据的读（使用 HDFS）。每个 HRegionServer 可以同时管理1000个左右的 HRegion。现在很多的分布式存储都使用这种横向切割，列式存储的方式。</li>
</ul>
<h2 id="HRegion（数据聚合单位"><a href="#HRegion（数据聚合单位" class="headerlink" title="HRegion（数据聚合单位)"></a>HRegion（数据聚合单位)</h2><p>Hbase 使用 RowKey 将表水平切割成多个 HRegion，每个 HRegion 都记录了它的 StartKey 和 EndKey，且有序。HRegion 由 HMaster 分配到相应的 HRegionServer 中，然后由 HRegionServer 复杂 HRegion 的启动和管理，和 Client 的通信，负责数据的读（使用 HDFS）。每个 HRegionServer 可以同时管理1000个左右的 HRegion。现在很多的分布式存储都使用这种横向切割，列式存储的方式。</p>
<p>INDEX</p>
<p><img src="/images/a-13-4.jpg" alt="a-13-4"></p>
<p>可以发现这张图和 BigTable 的 Tablet 索引图几乎一摸一样，不过有趣的是在 0.96 以后，HBase 觉得自己不需要这么大的地址空间，并以每次查询多一次寻址的代价。所以改为了两层结构，并且也保证了 <code>META Table</code> 像之前的 Root table 一样是不可切割的，保证这棵 B 树永远只有两层结构。同样提供客户端缓存。</p>
<h1 id="Druid"><a href="#Druid" class="headerlink" title="Druid"></a>Druid</h1><h2 id="底层模型的演进"><a href="#底层模型的演进" class="headerlink" title="底层模型的演进"></a>底层模型的演进</h2><p>在中插一个小话题，说说数据存储系统底层模型的一个演进之路。从最开始的平衡树到 B+ 树再到 LSM树：</p>
<ul>
<li><p>平衡树缺点：树高为 log2(N)，对于索引树来说树高越高，意味着查找所要的花费的访问次数越多，查询效率越低。（常数代价高）况且主存从磁盘读数据一般以页为单位，每次访问磁盘读取多个扇区的数据（大约4kb），远大于单个二叉树节点的值，造成了不必要的查询浪费。</p>
</li>
<li><p>B+ tree 缺点：叶子节点慢慢分裂，可能导致逻辑上原本连续的数据实际上存放在不同的物理磁盘块位置上，在做范围查询的时候会导致较高的 IO，影响性能。</p>
</li>
<li><p>LSM-tree 特点：在磁盘的访问中，顺序访问的速度是远大于随机访问的速度。而 LSM-tree 正是顺应了这个特点，保证数据的有序性以将一个请求转化为顺序的磁盘访问。在 LSM-tree 中同时使用两部分类树的结构来存储数据，并同时提供查询。其中一部分数据存放在内存中，负责接受新的数据插入更新以及读请求，并直接在内存中对数据进行排序。另外一部分存放在硬盘上，它们是由存放在内存中的 c0 树冲写到磁盘而成，主要提供读，特点是有序且不可别更改。再通过 WAL 原则来容灾恢复，使用 bloom filter 来快速判断数据的存在性。而其更适合插入操作远多于数据更新删除操作与读操作的场景。</p>
</li>
</ul>
<p>Druid 在架构上借鉴了 LSM-tree 的思想，但是也因为使用场景的关系有一些取舍。由于不支持数据修改，所以直接去掉了 WAL 原则。数据直接进入内存的堆区，到达条件后冲写到硬盘上形成一个数据块，同时实时节点又会立即将新生成的数据块加载到非堆区。会周期性的堆 Segment split 进行合并，合并好的会立即被实时节点上传到数据文件存储库中，随后协调节点会指导一个历史节点去文件存储库，将新生成的 Segment 下载到其本地磁盘中。当历史节点成功加载到 Segment 后，会通过协调服务在集群中声明其从此刻开始负责提供该 Segment 的查询。实时节点收到该声明后就不再提供 Segment 的查询服务。</p>
<h2 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h2><h3 id="实时节点（工作者-内存读写）"><a href="#实时节点（工作者-内存读写）" class="headerlink" title="实时节点（工作者 内存读写）"></a>实时节点（工作者 内存读写）</h3><p>主要负责即时摄入实时数据，以及生成 Segment 数据文件。如 Kafka 的消费，可以开多个节点对多个 Partition 进行同时消费，在 Zookeeper 上记录 partition offset，保证 at least one。</p>
<p><img src="/images/a-13-5.png" alt="a-13-5"></p>
<p>上图是实时节点的数据流图，可以看到实时数据会先被写入堆内存当中。在写到一定数量以后，会形成一个 <code>Segement split</code> 持久化保存到硬盘中，且堆内存能保证 <code>Segement split</code> 内部的有序性。而一个 <code>Segement split</code> 马上会被从硬盘里读取到非堆内存中，而此时堆内存中相同的数据会被清理掉。一个查询请求会同时到堆内存和非堆内存里查询数据再进行拼接以后进行返回。</p>
<h3 id="协调节点（历史节点的控制者）"><a href="#协调节点（历史节点的控制者）" class="headerlink" title="协调节点（历史节点的控制者）"></a>协调节点（历史节点的控制者）</h3><p>负责历史节点的数据负载均衡，以及通过规则管理数据的生命周期。Druid 通过对每个 DataSource 设置的规则来加载或丢弃具体的数据文件，以管理数据生命周期。在历史节点推出系统的时候，协调节点还没有把其身上携带的 Segment 负载到其他节点身上的时候，会出现短暂的数据无法访问。而Druid 允许通过 创建 Segment 的副本来解决该问题。</p>
<h3 id="历史节点（工作者-读）"><a href="#历史节点（工作者-读）" class="headerlink" title="历史节点（工作者 读）"></a>历史节点（工作者 读）</h3><p>历史节点负责加载已经生成好的数据文件以提供查询，并且由协调节点来进行负载均衡。历史节点在启动的时候，首先检查自己的本地缓存中已经存在的 Segment 数据文件，然后从 DeepStorage 中下载属于自己但目前不在自己本地磁盘的 Segment 数据。无论是何种查询，历史节点都会将相关的 Segment 先加入到自己的内存中，然后提供查询服务。</p>
<p>历史节点的查询速度与其内存空间大小和所负责的Segment 数据文件大小之比成正比。Druid 对历史节点进行分层，可以根据数据温度来协调数据的存储位置。</p>
<p>通过 Zookeeper 来协调高可用和高拓展性，新的历史节点被添加后，会通过 Zookeeper 被协调节点发现，然后协调节点将会自动分配相关的 Segment 给它。原有的历史节点被移除的时候，同样会被协调节点发现。</p>
<h3 id="查询节点（工作者）"><a href="#查询节点（工作者）" class="headerlink" title="查询节点（工作者）"></a>查询节点（工作者）</h3><p>对外提供查询服务，从历史节点和事实节点查询数据，合并后回传。提供缓存机制，使用多个查询节点来防止单点故障，使用 Nginx 来做负载均衡。保证每个查询节点在对同一个请求相应的时候返回相同的结果。</p>
<h3 id="Segment（数据聚合单位）"><a href="#Segment（数据聚合单位）" class="headerlink" title="Segment（数据聚合单位）"></a>Segment（数据聚合单位）</h3><p><img src="/images/a-13-6.jpeg" alt="a-13-6"></p>
<h3 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h3><p><img src="/images/a-13-7.png" alt="a-13-7"></p>
<p>实线是数据请求的流向，虚线是实时数据的流向。</p>
<p>实时数据会先进入实时节点的堆内存，在堆内存的大小达到一定的数量以后，会形成 <code>Segment split</code> 冲写到硬盘里，同时这个 <code>Segement split</code> 会被加载到非堆内存中以供访问。并且会提供周期性的 <code>Merging Compaction</code>，由几个小的 <code>Segment split</code> 合成一个 Segement，并存入到存储节点中。存储完成以后会告之协调节点，由协调节点进行负载均衡，决定把这个 Segement 交给一个历史节点，之后这个历史节点会声明对这个 Segement 的查询提供服务，而实时节点收到这个消息以后就不再对这个 Segement 的查询提供服务了，并清理掉相关数据。</p>
<p>一个请求进入系统以后会先到查询节点，查询节点再通过现在各节点对数据的负责情况，分别到实时节点和历史节点上进行查询，最后将结果合并进行返回。并且在查询节点上会提供各等级的缓存，历史节点则提供 Block cache。</p>
<h2 id="End"><a href="#End" class="headerlink" title="End"></a>End</h2><p>相信你在阅读以后能明显的感受到三个系统的相似与区别，并对这种分布式架构有个大体上的理解。本篇博客大部分内容都是对现有文章的整理，汇总。所以最后感谢这些文章及其作者：</p>
<ul>
<li><a href="http://blog.bizcloudsoft.com/wp-content/uploads/Google-Bigtable%E4%B8%AD%E6%96%87%E7%89%88_1.0.pdf" target="_blank" rel="noopener">BigTable 翻译版</a> </li>
<li><a href="http://static.usenix.org/event/osdi06/tech/chang/chang.pdf" target="_blank" rel="noopener">BigTable 原版</a> </li>
<li><a href="https://www.microsoft.com/en-us/research/uploads/prod/2016/12/paxos-simple-Copy.pdf" target="_blank" rel="noopener">Paxos Made Simple</a> </li>
<li><a href="https://blog.csdn.net/historyasamirror/article/details/3870168" target="_blank" rel="noopener">Google利器之Chubby</a> </li>
<li><a href="http://www.blogjava.net/DLevin/archive/2015/08/22/426877.html?opt=admin" target="_blank" rel="noopener">深入HBase架构解析（一） - 上善若水</a> </li>
</ul>
<ul>
<li><a href="http://www.n10k.com/blog/blockcache-101/" target="_blank" rel="noopener">BlockCache 101 - Nick Dimiduk</a> </li>
<li><a href="http://xudifsd.org/blog/2016/06/chubby-zookeeper-different-consistency-level/" target="_blank" rel="noopener">chubby &amp; zookeeper: different consistency level</a> </li>
<li><a href="http://www.cnblogs.com/yangecnu/p/Introduction-CQRS.html" target="_blank" rel="noopener">浅谈命令查询职责分离(CQRS)模式 - yangecnu</a> </li>
</ul>

	
	</div>
  <a type="button" href="/2019/04/06/a13/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/03/17/a4/" >STORM中OOM引发的思考</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-03-17  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>最近一次在实现需求的时候发现 Storm 中的一个 Bolt 出现了 OOM 导致的长时间 GC 问题。最后虽然通过 review 新更新的代码找到了问题，但是深究其中还是有一些别的收获，所以在这里进行记录。</p>
<p>在 review 新更新的代码之后发现，我将 <code>JedisPool</code> 的实例化写到了 <code>execute</code> 中而不是 <code>prepare</code> 中，所以 Storm 每次执行 <code>execute</code> 的时候都会重新实例化 <code>JedisPool</code> 并且也没有显式的进行 <code>close</code>。</p>
<p>虽然这个问题只是因为疏忽导致的，但是也让我对两个大问题进行了思考。一个是对于 Storm 中资源冲突的问题应该如何去发现、定位、处理，第二个是 Storm 中 Component 的生命周期。下面会讨论这两个问题。</p>
<h2 id="Storm中的资源冲突"><a href="#Storm中的资源冲突" class="headerlink" title="Storm中的资源冲突"></a>Storm中的资源冲突</h2><p><img src="/images/a4-1.png" alt="a4-1"></p>
<p>要解决 Storm 中的资源冲突，那么需要先了解 Storm 中的资源分配。一个集群由一个 nimbus 节点和多个工作节点组成，每个工作节点由一个 <code>Supervisor</code> 管理着多个 <code>Worker process</code>，每个 <code>Worker process</code> 对应着一个 <code>JVM</code>，在其中有多个 <code>Executor thread</code>。每个 <code>Executor thread</code> 中可能存在多个 <code>Task</code>。而 <code>Task</code> 则是一个 bolt 或者 spout 的实例。</p>
<p>在此基础上，可以把资源竞争从所属结构从小到大划分为：</p>
<ul>
<li><code>Worker process</code> 中的内存冲突</li>
<li><code>Worker process</code> 的冲突</li>
<li>工作节点上的内存冲突</li>
<li>工作节点上的 CPU 冲突</li>
<li>工作节点上的网络 I/O 冲突</li>
<li>工作节点上的磁盘 I/O 冲突</li>
</ul>
<h3 id="Worker-process-中的内存冲突"><a href="#Worker-process-中的内存冲突" class="headerlink" title="Worker process 中的内存冲突"></a>Worker process 中的内存冲突</h3><p>首先这类冲突实际上是 JVM 中的内存占用过多，表现为 <code>out-of-memory</code> 或者进入长时间的垃圾回收，并且这类冲突会在 UI 上暴露出来。而解决办法无非是：</p>
<ul>
<li>减少一个 <code>Worker process</code> 中的 <code>Executor thread</code> 个数<ul>
<li>保证 <code>Executor thread</code> 数量不变的情况下加大 <code>Worker process</code> 数量</li>
<li>保证 <code>Worker process</code> 数量不变的情况下减少 <code>Executor thread</code> 数量</li>
</ul>
</li>
<li>提高给 JVM 分配的内存：在 <code>storm.yaml</code> 中 <code>worker.childopts</code> 属性是 JVM 相关的参数，可以通过设定 <code>-Xms</code> 和 <code>-Xmx</code> 来进行修改。</li>
</ul>
<p>而观察任务的 GC 日志是最直接也是最长用到来解决问题的途径，在 <code>storm.yaml</code> 的 <code>worker.childopts</code> 中可以对 JVM 的 GC 日志进行配置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">worker.childopts: &quot;&quot;-XX +PrintGCTimeStamps  </span><br><span class="line">-XX: +PrintGCDetails</span><br><span class="line">-Xloggc: /opt/storm/worker-%ID%-jvm-gc.log</span><br><span class="line">-XX: +UseGCLogFileRotation</span><br><span class="line">-XX: NumberOfGCLogFiles=5</span><br><span class="line">-XX: GCLogFileSize=1M</span><br><span class="line">-XX: +PrintGCDateStamps</span><br><span class="line">-XX: +PrintGCApplicationStoppedTime</span><br><span class="line">-XX: +PrintGCApplicationConsurrentTime&quot;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>-XX +PrintGCTimeStamps</code>: 打印垃圾回收的时间戳</li>
<li><code>-XX: +PrintGCDetails</code>: 打印额外的 GC 细节</li>
<li><code>-Xloggc: /opt/storm/worker-%ID%-jvm-gc.log</code>: 为每个工作进程分别创建日志文件</li>
<li><code>-XX: +UseGCLogFileRotation</code>: 对 GC 日志文件使用日志转储</li>
<li><code>-XX: NumberOfGCLogFiles=5</code>: 设置日志的分割个数</li>
<li><code>-XX: GCLogFileSize=1M</code>: 设置日志的分割大小</li>
<li><code>-XX: +PrintGCDateStamps</code>: 打印垃圾回收的日期和时间信息</li>
<li><code>-XX: +PrintGCApplicationStoppedTime</code>: 打印应用程序停止时 GC 启动时间（时间在安全点内）</li>
<li><code>-XX: +PrintGCApplicationConsurrentTime</code>: 打印 GC 执行期间程序启动的时间（时间不在安全点内）</li>
</ul>
<h3 id="Worker-process-的冲突"><a href="#Worker-process-的冲突" class="headerlink" title="Worker process 的冲突"></a>Worker process 的冲突</h3><p>这是由于需要的 Worker process 数量超过了集群中的数量，可以通过扩展集群，或者增加每个工作节点的 Worker process 数量来解决。也可以对减少集群里一些任务的 Worker process 占用来解决。</p>
<p>在 <code>storm.yaml</code> 的 <code>supervisor.slots.ports</code> 配置项可以配置一个工作节点的 Worker process 数量，每一个端口对应一个进程。添加添加、删除端口就能进行控制。</p>
<h3 id="工作节点上的内存冲突"><a href="#工作节点上的内存冲突" class="headerlink" title="工作节点上的内存冲突"></a>工作节点上的内存冲突</h3><p>因为工作节点的内存需要支撑 <code>Supervisor process</code>， 操作系统，多个 <code>Worker process</code> 和其他的一些进程。如果工作节点在内存上发生了使用冲突，工作节点将开启进程间的内存调度（swapping），会造成有较高的延时发生。可以通过 <code>sar</code> 命令来进行监控：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> sar -S 1 3</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">表示每隔1秒输出3条内存的活动信息，主要需要关注 `kbswpused` 和 `%swpused` 数据。`kbswpused` 是使用中的交换空间内存(KB) ，`%swpused` 是使用中的交换空间内存百分比。如果这两个值大于0则说明系统中存在内存交换。</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>## 工作节点上的 CPU 冲突</span><br><span class="line">和上一个情况类似，也是因为对 CPU 的使用超过了节点所能提供的而造成的。也可以使用 `sar` 命令来进行监控：</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line"><span class="meta">$</span> sar -u 1 3</span><br></pre></td></tr></table></figure>

<p>主要需要关注 <code>%idle</code>，即在系统没有任何磁盘 I/O 请求空闲CPU时间百分比，如果值偏低。再到 <code>%user</code>，<code>%nice</code>， <code>%system</code> 中去找事应用层面上的问题还是系统层面的问题。</p>
<h3 id="工作节点上的-I-O-冲突"><a href="#工作节点上的-I-O-冲突" class="headerlink" title="工作节点上的 I/O 冲突"></a>工作节点上的 I/O 冲突</h3><p>同样可以使用 <code>sar</code> 命令来进行监控：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> sar -u 1 3</span><br></pre></td></tr></table></figure>

<p>只是现在需要关注的值是 <code>%iowait</code>，CPU 时间空闲的百分比，在此期间系统将执行 I/O 请求。如果这个值约为 10.00，那么大概率出现因 I/O 冲突导致的性能问题，如果大于 25.00，一定面临比较严重的 I/O 冲突。</p>
<p>然后要做的就是定位问题是在网络 I/O 还是磁盘 I/O，可以先通过下面的方法检查网络 I/O。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// 获取进程id</span><br><span class="line"><span class="meta">$</span> ps aux | grep MY_TOPOLOGY_NAME</span><br><span class="line">stormuser 12345 .....</span><br><span class="line"></span><br><span class="line">// 获取端口</span><br><span class="line"><span class="meta">$</span> netstat -antup | grep "12345/"</span><br><span class="line">tcp6       0      0 xx.xx.xx.xx: 12345        xx.xx.xx.xx:42474       ESTABLISHED 4576/java</span><br><span class="line"></span><br><span class="line">// 查看限制</span><br><span class="line"><span class="meta">$</span> cat /proc/12345/limits</span><br><span class="line"></span><br><span class="line">// 查看该端口的稳定的连接tcp连接</span><br><span class="line"><span class="meta">$</span> netstat -na | grep "tcp6" | grep "4576" | grep "ESTABLISHED" | wc -l</span><br></pre></td></tr></table></figure>

<p>检查 <code>Max open files</code> 一行， soft limit 和 hard limit 的值，如果已经到达设置的极限值，那么就会发生网络 I/O 冲突。然后可以使用 iotop 来观察是否发生了磁盘 I/O。</p>
<p>主要观察 USER 为 storm 的进程， <code>DISK READ</code> ，<code>DISK WRITE</code>，<code>IO&gt;</code> 即每秒该进程读取的字节数，每秒该进程写入的字节数，每秒 I/O 调用百分比。如果其中一个值较高就说明相关的任务出现了磁盘 I/O 冲突。</p>
<p><strong>该章节主要参考《Storm应用实践》</strong></p>
<h2 id="Component-生命周期"><a href="#Component-生命周期" class="headerlink" title="Component 生命周期"></a>Component 生命周期</h2><p>这里可以先参考一下 Nathan on 自己的回答： <a href="https://groups.google.com/forum/#!msg/storm-user/com4JfU9aJ4/zImseAoiH2IJ" target="_blank" rel="noopener">The lifecycle of a bolt or spout</a></p>
<p>可以看到 <code>prepare</code> 仅仅只会被 worker 在开始的时候执行一次，但是 <code>execute</code> 会在每次有 tuple 进入的时候都被调用。也就是说如果我有一个 Bolt 定义了3个 worker，每个 worker 都有3个 executer。那么总共是有9个 task，也就是说 <code>prepare</code> 会被调用9次，而 <code>execute</code> 就会被无限调用。</p>
<p>所以我们一些连接和静态变量的初始化工作放到 <code>prepare</code> 中去完成会更加的实惠。但是由于每个 worker 对应一个单独的 JVM 进程，一个 JVM 进程中会有多个 executor 线程，所以就会有多个 task 同时执行 <code>prepare</code> 的操作。<br>那么一些连接的创建是需要线程安全的环境，线程安全的单例写法这里不赘述。</p>

	
	</div>
  <a type="button" href="/2019/03/17/a4/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2018/11/16/a3/" >分布式轮询系统</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2018-11-16  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<p>最近需要实现的一个场景是对于社区里的每条动态进行多次的检测和评估，暂且不论检测和评估的具体功能，统称为「计算」。</p>
<p>而这些计算由其他同事提供现成的接口，但是由于其具体功能的差异这些计算有些依赖了外部接口，并且可能依赖外部的长延时接口，例如视频分析。所以这里从计算的实现上将其划分为「瞬时计算」和「长时计算」，而对于上层使用方来说是需要构造出一种使用协议来同时兼容两种类型。而这样的三层结构中是有两次网络传输过程，更需要一种足够健壮的重试策略。并且在动态流量基数较大，峰值与谷值差异较大的情况下，横向扩容能力也非常的重要。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>第一次讨论的方案是 「push模型」，多方使用我暴露的接口，在完成数据消费计算之后推送到我的服务中进行下游逻辑。这种方案有几个弊端，第一是多方需要实现消费 Kafka 的逻辑并且需要管理 Kafka offset，保证在事故不会导致数据丢失。第二是网络传输导致的重试逻辑复杂，需要接入第二个重试队列，或者提供重试接口，这样数据流的流向就从单向变为双向，增加了之后的维护和排查成本。但是这种方案还是有一个好处，因为计算方是接触数据的第一层，所以在计算方内部出现错误引起的重试或者报错机制实现其他非常简单。</p>
<p>在否定以后转换为 「pull模型」，多方暴露接口让我进行统一的调用，仅由我方消费 Kafka 并统一维护状态和提供重试策略。但是在实现细节上还是有两种方案可供选择，一种是以「动态为单位」，一种是以「计算为单位」。动态为单位是说，主线程消费 Kafka，然后交由下游异步或多线程方式调用多个接口，全部成功后算作一个动态计算完成。计算为单位是说，多个线程各自使用独立的 group id 消费 Kafka 并维护重试队列，然后在线程内进行接口调用。两种方式的区别是一个计算失败之后的 block 代价不同，第一种方案会 block 整个动态，第二种方案只会 block 动态的一个计算。并且由于计算之间的效率差，第一种的效率取决于最慢的一个计算，第二种在动态为单位的角度来看，也是以最慢的一个计算决定，但是由于计算之间不会互相影响，所以之后想对「慢计算」进行降级的话能很方便的完成。</p>
<h2 id="三个问题"><a href="#三个问题" class="headerlink" title="三个问题"></a>三个问题</h2><p>在决定模型以后，需要考虑第一个问题，「构造出一个通用的协议兼容同步计算和异步计算的调用」。一种是同步轮询，一种是异步调用。由于底层依赖的外部长时计算有请求的次数限制，所以同步轮询需要记录请求时间来控制轮询的时间间隔，但是没有性能问题的风险。而对于异步调用，如果下游系统被某些原因 block 住的时候会无限的建立连接，在超过线程池的上限以后会 block 住调用方。所以比较下来还是使用轮询的方式简单实用，只需要维护一个调用队列，每个请求带上「上一次请求的时间戳」和「重试次数」，如果在消费到一个还没有超过调用间隔的请求，不累加重试次数，直接放入队列末尾；如果一个请求失败则直接修改时间戳，累加重试次数放入队列末尾；如果超过了重试次数，直接抛出系统记为一个 bad case。</p>
<p>在确定轮询的方式以后，第二个重试问题也迎刃而解，仅由顶部调用方来控制请求状态，并且提供重试，这样单向的数据流在后期的问题排查和维护过程中是非常重要的。而第三个问题，横向扩展能力，由于使用了「以计算为单位的pull模型」，扩展新的计算可见是非常方便的，只需要添加独立的线程。并且扩展每个计算调用系统本身也是非常方便的，需要对「分发任务逻辑」和「调用逻辑」进行解耦，扩展时只扩展「调用逻辑」部分，不然的话还需要保证每个线程之间分发任务的队列的一致性，是很冗余的设计。那么整个轮询系统内部也被划分为了两个部分，第一个部分消费 Kafka，维护调用队列，第二个部分消费调用队列进行底层接口调用，并且会反馈调用结果给第一个部分，使其进行调用队列的状态维护。</p>
<p><img src="/images/a3-1.png" alt="a3-1"></p>
<p>而上面也提到了单向数据流的好处，所以这里为了规避掉双向数据流，将请求完成后的队列维护工作也放在接口调用部分。所以就变成了「状态维护」部分只管往调用队列里放请求，「接口调用」部分负责调用接口并且使用 response 来维护调用队列里的请求状态，例如请求次数加一之后放入队列末尾。</p>
<p><img src="/images/a3-2.png" alt="a3-2"></p>
<h2 id="复用Storm"><a href="#复用Storm" class="headerlink" title="复用Storm"></a>复用Storm</h2><p>上面的结构一看非常像 Storm 的流式结构了，并且 Storm 能保证一条 Kafka message 在轮询系统中一定会被成功消费并且是顺序消费，还能帮我们管理 Kafka offset 状态，还不需要写多线程，扩容起来也非常方便。那么何乐为不为呢？</p>
<p><img src="/images/a3-3.png" alt="a3-3"></p>
<p>将设计图一改，瞬间转变成一个 Storm 架构，其实上面单向数据流的设计也规避了 Storm 中不能由下游 Bolt 给上游 Bolt 传递消息的情况。而 Storm 本身也提供重试机制，在该重试机制下我们可以重新考虑之前数据结构的设计。</p>
<p>因为我们需要考虑的是两类重试情况，一种是通过重试能解决的网络问题，一种是通过重试不能解决的系统问题。而当我们在遇到超过重试次数没有解决的问题时，之前的解决方案是抛出系统持久化到一个地方，之后再想办法解决，但是这样又增添了该系统的复杂程度，需要通过自动化的方案能区分这个 case 到底是网络问题还是系统问题，之后再通过一套方案将它解决掉再写入系统。</p>
<p>试想最简单的处理方案是遇到网络问题通过重试自然的解决它，而遇到系统问题直接 block 整个系统，等待计算提供方解决问题后再继续。而 Storm 的机制刚好提供了这种方案的解决策略，如果遇到重试的请求都进行无限次的重试，因为短暂的问题肯定是会在有限次重试的过程中恢复，而系统问题是无限次重试都不能解决的，那么遇到很多的系统问题 case 不是会浪费IO，并且也没有 block 整个系统吗？</p>
<p>其实并不会，Storm 内部设计的时候一次会从 Kafka 中拿出多个 message 形成多个 tuple，只有在这些 tuple 全部 ack 掉以后才会继续向后面拿数据。所以如果在一批数据中出现了一些系统问题的 case，他们通过无限的 fail 重试是会 block 整个 topology 的，并且他们的个数不会很多，所以不会对下游造成 IO 的压力。对 Kafka 的 offset 进行检测接上警报以后，很快消费能力就跟不上生产能力，就能知道出现了这样的系统问题，在下游的服务修好以后，再接着进行消费，也不会丢失数据。</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>系统的设计中每一部分一定要简单纯粹，不要想让一个部分做多件事情。</p>

	
	</div>
  <a type="button" href="/2018/11/16/a3/#more" class="btn btn-default more">Read More</a>
</div>

		

		</div>

		<!-- pagination -->
		<div>
  		<center>
		<div class="pagination">

   
    
           <a type="button" class="btn btn-default disabled"><i class="fa fa-arrow-circle-o-left"></i>Prev</a>
        

        <a href="/" type="button" class="btn btn-default"><i class="fa fa-home"></i>Home</a>
 
       <a href="/page/2/" type="button" class="btn btn-default ">Next<i class="fa fa-arrow-circle-o-right"></i></a>     
        

  
</div>

  		</center>
		</div>

		
		
	</div> <!-- col-md-9 -->

	
		<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
		
			
	<div class="widget">
		<h4>Tag Cloud</h4>
		<ul class="tag_box inline list-unstyled">		
		
			<li><a href="/tags/druid/">druid<span>1</span></a></li>
		
			<li><a href="/tags/front-end/">front-end<span>1</span></a></li>
		
			<li><a href="/tags/database/">database<span>2</span></a></li>
		
			<li><a href="/tags/monogdb/">monogdb<span>1</span></a></li>
		
			<li><a href="/tags/hbase/">hbase<span>1</span></a></li>
		
			<li><a href="/tags/flink/">flink<span>1</span></a></li>
		
			<li><a href="/tags/react/">react<span>1</span></a></li>
		
			<li><a href="/tags/mongodb/">mongodb<span>2</span></a></li>
		
			<li><a href="/tags/spark/">spark<span>2</span></a></li>
		
			<li><a href="/tags/redux/">redux<span>1</span></a></li>
		
			<li><a href="/tags/elasticsearch/">elasticsearch<span>1</span></a></li>
		
			<li><a href="/tags/docker/">docker<span>1</span></a></li>
		
			<li><a href="/tags/kafka/">kafka<span>1</span></a></li>
		
			<li><a href="/tags/distributed-system/">distributed-system<span>7</span></a></li>
		
			<li><a href="/tags/java/">java<span>2</span></a></li>
		
			<li><a href="/tags/storm/">storm<span>2</span></a></li>
		
			<li><a href="/tags/typescript/">typescript<span>1</span></a></li>
		
			<li><a href="/tags/c/">c++<span>1</span></a></li>
		
		 
		</ul>
	</div>


		
			
<div class="widget">
  <h4>Recent Posts</h4>
  <ul class="entry list-unstyled">
    
      <li>
        <a href="/2020/09/10/a18/" ><i class="fa fa-file-o"></i>Spark Memory Management</a>
      </li>
    
      <li>
        <a href="/2020/03/22/a17/" ><i class="fa fa-file-o"></i>Mongodb CDC链路中的有序性</a>
      </li>
    
      <li>
        <a href="/2020/01/20/a16/" ><i class="fa fa-file-o"></i>URLEncoder in JAVA</a>
      </li>
    
      <li>
        <a href="/2019/11/08/a15/" ><i class="fa fa-file-o"></i>KV分布式事务</a>
      </li>
    
      <li>
        <a href="/2019/10/18/a14/" ><i class="fa fa-file-o"></i>锁</a>
      </li>
    
  </ul>
</div>

		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/TalkWIthKeyboard" title="TalkWIthKeyboard's Github repository." target="_blank"]);">TalkWIthKeyboard</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->

	
	
</div> <!-- row-fluid -->
	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2020 TalkWithKeyboard
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a>,<a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>,<a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a> and <a href="http://getbootstrap.com/" target="_blank">BOOTSTRA.386</a>. 
     <br> Theme by <a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind.386</a>.    
</p>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>⬆︎TOP</span>
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>

</body>
   </html>
